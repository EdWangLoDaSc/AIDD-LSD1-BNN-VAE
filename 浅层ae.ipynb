{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdWangLoDaSc/Dropout-as-a-Grid-Search_Representing-Model-Uncertainty-in-Deep-Learning/blob/main/%E6%B5%85%E5%B1%82ae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCENnU2LwLgv"
      },
      "source": [
        "It is necessary to use tensorflow 1.14.0 under the environment of Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuOaKZc14cYf",
        "outputId": "aeb858db-7b89-4098-b202-2464252c968e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 51 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 34.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.47.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgeK7ykvkcDP",
        "outputId": "8ed3bc8f-e6ee-40cf-8f88-0feca8cf7b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBSl6GNhl_Gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1da746-a230-4316-ae29-26c92931dedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "## TensorFlow\n",
        "import tensorflow as tf\n",
        "#tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/content/MyDrive/2048_final.csv')\n"
      ],
      "metadata": {
        "id": "dZPoUthYTwoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.values"
      ],
      "metadata": {
        "id": "8I93WiXxT8pE",
        "outputId": "f2ab0bf6-ca0f-46af-c4a6-f033aa6ea82a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyVnITvXlvKW"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/content/MyDrive/CGAN_Regression/CGAN_code/Datasets/Datasets.csv')\n",
        "df = df.drop(['Calculated-pChEMBL'], axis = 1).values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2048-384-384-384"
      ],
      "metadata": {
        "id": "ajr39Q8VUjHJ",
        "outputId": "49094065-ff13-4325-dfc2-94bef5228a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "896"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RykJLy-m5hk"
      },
      "outputs": [],
      "source": [
        "num_inputs = 2048\n",
        "\n",
        "## Encoder section\n",
        "hidden_1 = 1664     ## 256 (Number of nodes)\n",
        "hidden_2 = 1280  ## 128\n",
        "hidden_3 = 896  ## 64\n",
        "\n",
        "## Latent Space\n",
        "hidden_4 = 512  ## 32\n",
        "\n",
        "## Decoder \n",
        "hidden_5 = hidden_3      ## 64\n",
        "hidden_6 = hidden_2      ## 128\n",
        "hidden_7 = hidden_1      ## 256\n",
        "\n",
        "num_outputs = num_inputs ## 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCfc-5Lfnt8d"
      },
      "outputs": [],
      "source": [
        "## Hyper Parameters: \n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "## Activation function\n",
        "\n",
        "\"\"\"\n",
        "Here we are using Rectified Linear Unit( ReLu). It is at the left for the user to test and experiment \n",
        "with other activation functions and learning rate\n",
        "\"\"\"\n",
        "\n",
        "activ_fn = tf.nn.relu\n",
        "\n",
        "## Input Layer\n",
        "\n",
        "\"\"\"\n",
        "Defining Input data\n",
        "\"\"\"\n",
        "\n",
        "X = tf.compat.v1.placeholder(tf.float32,shape = [None,num_inputs])\n",
        "\n",
        "## scaling keras.initializers.\n",
        "#initializer = tf.keras.initializers.variance_scaling_initializer()\n",
        "initializer = tf.contrib.layers.variance_scaling_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWii3KL_ovTv"
      },
      "outputs": [],
      "source": [
        "## Weights(Parameters)\n",
        "\"\"\"\n",
        "Here we are randomly initializing the weights which are later updated based on the gradient descent and learning rate \n",
        "such that it minimizes the cost function\n",
        "\"\"\"\n",
        "\n",
        "w1 = tf.Variable(initializer([num_inputs,hidden_1]),dtype=tf.float32)\n",
        "w2 = tf.Variable(initializer([hidden_1,hidden_2]),dtype=tf.float32)\n",
        "w3 = tf.Variable(initializer([hidden_2,hidden_3]),dtype=tf.float32)\n",
        "w4 = tf.Variable(initializer([hidden_3,hidden_4]),dtype=tf.float32)\n",
        "w5 = tf.transpose(w4)\n",
        "w6 = tf.transpose(w3)\n",
        "w7 = tf.transpose(w2)\n",
        "w8 = tf.transpose(w1)\n",
        "\n",
        "b1 = tf.Variable(tf.zeros(hidden_1))\n",
        "b2 = tf.Variable(tf.zeros(hidden_2))\n",
        "b3 = tf.Variable(tf.zeros(hidden_3))\n",
        "b4 = tf.Variable(tf.zeros(hidden_4))\n",
        "b5 = b3\n",
        "b6 = b2\n",
        "b7 = b1\n",
        "b8 = tf.Variable(tf.zeros(num_outputs))\n",
        "\n",
        "hid_layer1 = activ_fn(tf.matmul(X,w1)+b1)\n",
        "hid_layer2 = activ_fn(tf.matmul(hid_layer1,w2)+b2)\n",
        "hid_layer3 = activ_fn(tf.matmul(hid_layer2,w3)+b3)\n",
        "hid_layer4 = activ_fn(tf.matmul(hid_layer3,w4)+b4)\n",
        "hid_layer5 = activ_fn(tf.matmul(hid_layer4,w5)+b5)\n",
        "hid_layer6 = activ_fn(tf.matmul(hid_layer5,w6)+b6)\n",
        "hid_layer7 = activ_fn(tf.matmul(hid_layer6,w7)+b7)\n",
        "output_layer = activ_fn(tf.matmul(hid_layer7,w8)+b8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT9Rmwnawl22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "f8d8513d-b181-44ec-dadf-869637e11dd9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-8022c797d210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m    823\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m    824\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m    873\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m           build_restore=build_restore)\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     saveables = saveable_object_util.validate_and_slice_inputs(\n\u001b[0;32m--> 482\u001b[0;31m         names_to_saveables)\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mvalidate_and_slice_inputs\u001b[0;34m(names_to_saveables)\u001b[0m\n\u001b[1;32m    333\u001b[0m   \"\"\"\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_list_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mop_list_to_dict\u001b[0;34m(op_list, convert_variable_to_tensor)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m           raise ValueError(\"At least two variables have the same name: %s\" %\n\u001b[0;32m--> 292\u001b[0;31m                            name)\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: At least two variables have the same name: Variable/Adam"
          ]
        }
      ],
      "source": [
        "## Loss Function(Cost function)\n",
        "\n",
        "\"\"\"\n",
        "Here we are defining the cost function, Minimizing loss between input and output layers\n",
        "\"\"\"\n",
        "\n",
        "loss = tf.reduce_mean(tf.square(output_layer - X))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "## Optimizer\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "\n",
        "## Initialzing\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "saver = tf.train.Saver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb54nOZ-w_d4",
        "outputId": "f18d049b-ed2c-400b-e310-a5bd35716188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 0.0348101407289505\n",
            "Epoch: 1 Loss: 0.025294966995716095\n",
            "Epoch: 2 Loss: 0.019386904314160347\n",
            "Epoch: 3 Loss: 0.015595512464642525\n",
            "Epoch: 4 Loss: 0.012776345014572144\n",
            "Epoch: 5 Loss: 0.010544106364250183\n",
            "Epoch: 6 Loss: 0.008895527571439743\n",
            "Epoch: 7 Loss: 0.007548058405518532\n",
            "Epoch: 8 Loss: 0.006376582197844982\n",
            "Epoch: 9 Loss: 0.005406704731285572\n",
            "Epoch: 10 Loss: 0.00449917558580637\n",
            "Epoch: 11 Loss: 0.0037445935886353254\n",
            "Epoch: 12 Loss: 0.0031029880046844482\n",
            "Epoch: 13 Loss: 0.0025870301760733128\n",
            "Epoch: 14 Loss: 0.002132870489731431\n",
            "Epoch: 15 Loss: 0.0017832103185355663\n",
            "Epoch: 16 Loss: 0.0015067054191604257\n",
            "Epoch: 17 Loss: 0.0012712394818663597\n",
            "Epoch: 18 Loss: 0.0010943023953586817\n",
            "Epoch: 19 Loss: 0.0009575627045705914\n",
            "Epoch: 20 Loss: 0.000828029471449554\n",
            "Epoch: 21 Loss: 0.0007412500563077629\n",
            "Epoch: 22 Loss: 0.000632345792837441\n",
            "Epoch: 23 Loss: 0.0005631514941342175\n",
            "Epoch: 24 Loss: 0.0005074926884844899\n",
            "Epoch: 25 Loss: 0.0004418271128088236\n",
            "Epoch: 26 Loss: 0.00037984034861437976\n",
            "Epoch: 27 Loss: 0.0003361592534929514\n",
            "Epoch: 28 Loss: 0.0003331834450364113\n",
            "Epoch: 29 Loss: 0.0003015405382029712\n",
            "Epoch: 30 Loss: 0.0002573523670434952\n",
            "Epoch: 31 Loss: 0.00023468610015697777\n",
            "Epoch: 32 Loss: 0.00021345281857065856\n",
            "Epoch: 33 Loss: 0.00020423164824023843\n",
            "Epoch: 34 Loss: 0.00020357394532766193\n",
            "Epoch: 35 Loss: 0.0001741815503919497\n",
            "Epoch: 36 Loss: 0.0001892428263090551\n",
            "Epoch: 37 Loss: 0.00015212582366075367\n",
            "Epoch: 38 Loss: 0.00017863282118923962\n",
            "Epoch: 39 Loss: 0.00016474822768941522\n",
            "Epoch: 40 Loss: 0.00018811192421708256\n",
            "Epoch: 41 Loss: 0.00014387919509317726\n",
            "Epoch: 42 Loss: 0.0001800123427528888\n",
            "Epoch: 43 Loss: 0.0001298068673349917\n",
            "Epoch: 44 Loss: 0.00016169215086847544\n",
            "Epoch: 45 Loss: 0.00012988132948521525\n",
            "Epoch: 46 Loss: 0.00015200316556729376\n",
            "Epoch: 47 Loss: 0.0001108469587052241\n",
            "Epoch: 48 Loss: 0.00013887244858779013\n",
            "Epoch: 49 Loss: 0.0001127659561461769\n",
            "Epoch: 50 Loss: 0.00015544101188424975\n",
            "Epoch: 51 Loss: 0.0001378481392748654\n",
            "Epoch: 52 Loss: 0.00013927838881500065\n",
            "Epoch: 53 Loss: 0.00011738533794414252\n",
            "Epoch: 54 Loss: 0.00010667894093785435\n",
            "Epoch: 55 Loss: 0.00010722172737587243\n",
            "Epoch: 56 Loss: 0.00013270479394122958\n",
            "Epoch: 57 Loss: 0.00012287123536225408\n",
            "Epoch: 58 Loss: 9.384768782183528e-05\n",
            "Epoch: 59 Loss: 0.00010482138895895332\n",
            "Epoch: 60 Loss: 0.00011734625149983913\n",
            "Epoch: 61 Loss: 0.00010757417476270348\n",
            "Epoch: 62 Loss: 8.163500751834363e-05\n",
            "Epoch: 63 Loss: 0.00010932401346508414\n",
            "Epoch: 64 Loss: 9.35466232476756e-05\n",
            "Epoch: 65 Loss: 0.00010082031803904101\n",
            "Epoch: 66 Loss: 8.795567555353045e-05\n",
            "Epoch: 67 Loss: 0.00010515178291825578\n",
            "Epoch: 68 Loss: 0.00010674789518816397\n",
            "Epoch: 69 Loss: 0.00010164327977690846\n",
            "Epoch: 70 Loss: 0.00011023288971045986\n",
            "Epoch: 71 Loss: 8.54346581036225e-05\n",
            "Epoch: 72 Loss: 9.003088052850217e-05\n",
            "Epoch: 73 Loss: 0.00010202096018474549\n",
            "Epoch: 74 Loss: 9.156221494777128e-05\n",
            "Epoch: 75 Loss: 0.00010957047197734937\n",
            "Epoch: 76 Loss: 0.0001100142762879841\n",
            "Epoch: 77 Loss: 0.00011987802281510085\n",
            "Epoch: 78 Loss: 0.00010367574577685446\n",
            "Epoch: 79 Loss: 0.00011098729737568647\n",
            "Epoch: 80 Loss: 9.68812164501287e-05\n",
            "Epoch: 81 Loss: 9.972669067792594e-05\n",
            "Epoch: 82 Loss: 9.840315760811791e-05\n",
            "Epoch: 83 Loss: 0.00011079291289206594\n",
            "Epoch: 84 Loss: 0.00011329180415486917\n",
            "Epoch: 85 Loss: 0.00010593986371532083\n",
            "Epoch: 86 Loss: 0.00015490062651224434\n",
            "Epoch: 87 Loss: 0.00010453732829773799\n",
            "Epoch: 88 Loss: 9.318214142695069e-05\n",
            "Epoch: 89 Loss: 0.00011361804354237393\n",
            "Epoch: 90 Loss: 9.790875628823414e-05\n",
            "Epoch: 91 Loss: 0.0001051568760885857\n",
            "Epoch: 92 Loss: 6.839402340119705e-05\n",
            "Epoch: 93 Loss: 0.00010024929360952228\n",
            "Epoch: 94 Loss: 7.120936788851395e-05\n",
            "Epoch: 95 Loss: 8.669489761814475e-05\n",
            "Epoch: 96 Loss: 8.731190609978512e-05\n",
            "Epoch: 97 Loss: 0.00012067798525094986\n",
            "Epoch: 98 Loss: 8.386558329220861e-05\n",
            "Epoch: 99 Loss: 0.00010444159852340817\n",
            "Epoch: 100 Loss: 8.294303552247584e-05\n",
            "Epoch: 101 Loss: 0.00011749824625439942\n",
            "Epoch: 102 Loss: 8.721865015104413e-05\n",
            "Epoch: 103 Loss: 9.687714918982238e-05\n",
            "Epoch: 104 Loss: 7.607571023982018e-05\n",
            "Epoch: 105 Loss: 6.287270662141964e-05\n",
            "Epoch: 106 Loss: 0.00010240236588288099\n",
            "Epoch: 107 Loss: 6.562439375557005e-05\n",
            "Epoch: 108 Loss: 0.00011664896737784147\n",
            "Epoch: 109 Loss: 7.95753876445815e-05\n",
            "Epoch: 110 Loss: 0.0001141403045039624\n",
            "Epoch: 111 Loss: 8.571620128350332e-05\n",
            "Epoch: 112 Loss: 0.0001202561252284795\n",
            "Epoch: 113 Loss: 8.111945498967543e-05\n",
            "Epoch: 114 Loss: 0.00013822612527292222\n",
            "Epoch: 115 Loss: 7.567138527520001e-05\n",
            "Epoch: 116 Loss: 0.00011918654490727931\n",
            "Epoch: 117 Loss: 8.461157267447561e-05\n",
            "Epoch: 118 Loss: 0.00015951393288560212\n",
            "Epoch: 119 Loss: 0.00010578825458651409\n",
            "Epoch: 120 Loss: 9.74525828496553e-05\n",
            "Epoch: 121 Loss: 0.00011390257714083418\n",
            "Epoch: 122 Loss: 9.888775821309537e-05\n",
            "Epoch: 123 Loss: 0.00011529718176461756\n",
            "Epoch: 124 Loss: 0.00011426224955357611\n",
            "Epoch: 125 Loss: 8.897183579392731e-05\n",
            "Epoch: 126 Loss: 9.130505350185558e-05\n",
            "Epoch: 127 Loss: 8.642952161608264e-05\n",
            "Epoch: 128 Loss: 8.559534035157412e-05\n",
            "Epoch: 129 Loss: 7.696992543060333e-05\n",
            "Epoch: 130 Loss: 0.00014043919509276748\n",
            "Epoch: 131 Loss: 7.007140811765566e-05\n",
            "Epoch: 132 Loss: 8.697765588294715e-05\n",
            "Epoch: 133 Loss: 9.393608343089e-05\n",
            "Epoch: 134 Loss: 0.00010045292583527043\n",
            "Epoch: 135 Loss: 7.970962178660557e-05\n",
            "Epoch: 136 Loss: 7.043567893560976e-05\n",
            "Epoch: 137 Loss: 0.00010186384315602481\n",
            "Epoch: 138 Loss: 6.53823371976614e-05\n",
            "Epoch: 139 Loss: 9.718893852550536e-05\n",
            "Epoch: 140 Loss: 9.459935245104134e-05\n",
            "Epoch: 141 Loss: 8.44670066726394e-05\n",
            "Epoch: 142 Loss: 0.00010718573321355507\n",
            "Epoch: 143 Loss: 0.0001163230772363022\n",
            "Epoch: 144 Loss: 7.669691694900393e-05\n",
            "Epoch: 145 Loss: 0.00011126359459012747\n",
            "Epoch: 146 Loss: 9.495814447291195e-05\n",
            "Epoch: 147 Loss: 9.818233229452744e-05\n",
            "Epoch: 148 Loss: 0.000123306002933532\n",
            "Epoch: 149 Loss: 0.00010732298687798902\n",
            "Epoch: 150 Loss: 0.00011710235412465408\n",
            "Epoch: 151 Loss: 0.00010222819400951266\n",
            "Epoch: 152 Loss: 0.0001110045486711897\n",
            "Epoch: 153 Loss: 0.0001339260779786855\n",
            "Epoch: 154 Loss: 7.15269852662459e-05\n",
            "Epoch: 155 Loss: 0.0001299300347454846\n",
            "Epoch: 156 Loss: 0.00010914380254689604\n",
            "Epoch: 157 Loss: 0.00010637115337885916\n",
            "Epoch: 158 Loss: 0.0001028625265462324\n",
            "Epoch: 159 Loss: 0.00013019096513744444\n",
            "Epoch: 160 Loss: 0.00013470297562889755\n",
            "Epoch: 161 Loss: 0.00013228767784312367\n",
            "Epoch: 162 Loss: 0.00010243132419418544\n",
            "Epoch: 163 Loss: 0.0001224556181114167\n",
            "Epoch: 164 Loss: 0.00012987139052711427\n",
            "Epoch: 165 Loss: 0.0001100147856050171\n",
            "Epoch: 166 Loss: 0.00011014283518306911\n",
            "Epoch: 167 Loss: 0.00010962832311633974\n",
            "Epoch: 168 Loss: 9.545587818138301e-05\n",
            "Epoch: 169 Loss: 7.653240027138963e-05\n",
            "Epoch: 170 Loss: 8.838862413540483e-05\n",
            "Epoch: 171 Loss: 0.00011007228749804199\n",
            "Epoch: 172 Loss: 9.655416943132877e-05\n",
            "Epoch: 173 Loss: 0.00010617224324960262\n",
            "Epoch: 174 Loss: 9.8882541351486e-05\n",
            "Epoch: 175 Loss: 0.0001162856788141653\n",
            "Epoch: 176 Loss: 0.00010718697740230709\n",
            "Epoch: 177 Loss: 6.380466220434755e-05\n",
            "Epoch: 178 Loss: 8.730911940801889e-05\n",
            "Epoch: 179 Loss: 9.156848682323471e-05\n",
            "Epoch: 180 Loss: 8.49868229124695e-05\n",
            "Epoch: 181 Loss: 0.00010164872219320387\n",
            "Epoch: 182 Loss: 0.00010995791672030464\n",
            "Epoch: 183 Loss: 7.663259748369455e-05\n",
            "Epoch: 184 Loss: 8.763514779275283e-05\n",
            "Epoch: 185 Loss: 0.00012253965542186052\n",
            "Epoch: 186 Loss: 8.657060971017927e-05\n",
            "Epoch: 187 Loss: 9.485647751716897e-05\n",
            "Epoch: 188 Loss: 0.00012456117838155478\n",
            "Epoch: 189 Loss: 9.433378727408126e-05\n",
            "Epoch: 190 Loss: 0.00010109737195307389\n",
            "Epoch: 191 Loss: 0.00012934970436617732\n",
            "Epoch: 192 Loss: 0.00010139698861166835\n",
            "Epoch: 193 Loss: 0.00010048400872619823\n",
            "Epoch: 194 Loss: 8.953777432907373e-05\n",
            "Epoch: 195 Loss: 0.0001175020297523588\n",
            "Epoch: 196 Loss: 0.00012293473992031068\n",
            "Epoch: 197 Loss: 0.00011521576379891485\n",
            "Epoch: 198 Loss: 0.00016797779244370759\n",
            "Epoch: 199 Loss: 0.00015799119137227535\n",
            "Epoch: 200 Loss: 0.00013393208791967481\n",
            "Epoch: 201 Loss: 0.0001668930781306699\n",
            "Epoch: 202 Loss: 0.0001262164587387815\n",
            "Epoch: 203 Loss: 0.00014635334082413465\n",
            "Epoch: 204 Loss: 8.460655226372182e-05\n",
            "Epoch: 205 Loss: 0.00012011533544864506\n",
            "Epoch: 206 Loss: 0.00010923377703875303\n",
            "Epoch: 207 Loss: 0.00016067890101112425\n",
            "Epoch: 208 Loss: 9.652449080022052e-05\n",
            "Epoch: 209 Loss: 0.00015160278417170048\n",
            "Epoch: 210 Loss: 0.0001281740260310471\n",
            "Epoch: 211 Loss: 0.00018205642118118703\n",
            "Epoch: 212 Loss: 0.00012845409219153225\n",
            "Epoch: 213 Loss: 0.0001456583122489974\n",
            "Epoch: 214 Loss: 0.0001129072334151715\n",
            "Epoch: 215 Loss: 0.00011710906983353198\n",
            "Epoch: 216 Loss: 0.00017266564827878028\n",
            "Epoch: 217 Loss: 0.0001047740297508426\n",
            "Epoch: 218 Loss: 0.00013520964421331882\n",
            "Epoch: 219 Loss: 0.00013408689119387418\n",
            "Epoch: 220 Loss: 0.0001392916456097737\n",
            "Epoch: 221 Loss: 0.00011227840150240809\n",
            "Epoch: 222 Loss: 9.137950110016391e-05\n",
            "Epoch: 223 Loss: 9.59933822741732e-05\n",
            "Epoch: 224 Loss: 0.00011416480992920697\n",
            "Epoch: 225 Loss: 0.00010280557762598619\n",
            "Epoch: 226 Loss: 0.00015758645895402879\n",
            "Epoch: 227 Loss: 0.00010797663708217442\n",
            "Epoch: 228 Loss: 0.00012784675345756114\n",
            "Epoch: 229 Loss: 0.00013091572327539325\n",
            "Epoch: 230 Loss: 0.00012161825725343078\n",
            "Epoch: 231 Loss: 0.00010041051427833736\n",
            "Epoch: 232 Loss: 0.00012274182518012822\n",
            "Epoch: 233 Loss: 0.0001053762825904414\n",
            "Epoch: 234 Loss: 9.62750636972487e-05\n",
            "Epoch: 235 Loss: 0.00010713409574236721\n",
            "Epoch: 236 Loss: 8.892085315892473e-05\n",
            "Epoch: 237 Loss: 0.00010470327106304467\n",
            "Epoch: 238 Loss: 0.00013310722715687007\n",
            "Epoch: 239 Loss: 0.00011251249816268682\n",
            "Epoch: 240 Loss: 8.038477972149849e-05\n",
            "Epoch: 241 Loss: 0.0001033848020597361\n",
            "Epoch: 242 Loss: 9.690177103038877e-05\n",
            "Epoch: 243 Loss: 9.660303476266563e-05\n",
            "Epoch: 244 Loss: 8.858742512529716e-05\n",
            "Epoch: 245 Loss: 0.00010271118662785739\n",
            "Epoch: 246 Loss: 8.010440797079355e-05\n",
            "Epoch: 247 Loss: 9.807366586755961e-05\n",
            "Epoch: 248 Loss: 0.00010368416405981407\n",
            "Epoch: 249 Loss: 0.0001161475302069448\n",
            "Epoch: 250 Loss: 0.00012957907165400684\n",
            "Epoch: 251 Loss: 9.799363760976121e-05\n",
            "Epoch: 252 Loss: 0.0001370228419546038\n",
            "Epoch: 253 Loss: 0.00011918180098291487\n",
            "Epoch: 254 Loss: 0.00014127448957879096\n",
            "Epoch: 255 Loss: 9.254858014173806e-05\n",
            "Epoch: 256 Loss: 0.00013853533891960979\n",
            "Epoch: 257 Loss: 8.043109846767038e-05\n",
            "Epoch: 258 Loss: 0.0001223639992531389\n",
            "Epoch: 259 Loss: 0.00011642846948234364\n",
            "Epoch: 260 Loss: 0.00010864112118724734\n",
            "Epoch: 261 Loss: 0.00010838444723049179\n",
            "Epoch: 262 Loss: 9.26959328353405e-05\n",
            "Epoch: 263 Loss: 0.0001420027983840555\n",
            "Epoch: 264 Loss: 0.00010876152373384684\n",
            "Epoch: 265 Loss: 0.00012715790944639593\n",
            "Epoch: 266 Loss: 0.00013046254753135145\n",
            "Epoch: 267 Loss: 0.0001052037114277482\n",
            "Epoch: 268 Loss: 0.00010464116348885\n",
            "Epoch: 269 Loss: 0.00010337804269511253\n",
            "Epoch: 270 Loss: 0.00013229320757091045\n",
            "Epoch: 271 Loss: 0.00013356059207580984\n",
            "Epoch: 272 Loss: 9.799675899557769e-05\n",
            "Epoch: 273 Loss: 0.00010817148722708225\n",
            "Epoch: 274 Loss: 0.00011558293044799939\n",
            "Epoch: 275 Loss: 0.00012167225941084325\n",
            "Epoch: 276 Loss: 0.00010219262185273692\n",
            "Epoch: 277 Loss: 7.017124153207988e-05\n",
            "Epoch: 278 Loss: 8.729117689654231e-05\n",
            "Epoch: 279 Loss: 0.0001152979675680399\n",
            "Epoch: 280 Loss: 6.944299093447626e-05\n",
            "Epoch: 281 Loss: 0.00010301951260771602\n",
            "Epoch: 282 Loss: 9.364007564727217e-05\n",
            "Epoch: 283 Loss: 0.00010313160601072013\n",
            "Epoch: 284 Loss: 7.77301611378789e-05\n",
            "Epoch: 285 Loss: 0.00012110346142435446\n",
            "Epoch: 286 Loss: 0.00011558458209037781\n",
            "Epoch: 287 Loss: 0.00010193424532189965\n",
            "Epoch: 288 Loss: 0.00011702370102284476\n",
            "Epoch: 289 Loss: 0.00012230814900249243\n",
            "Epoch: 290 Loss: 0.00011193657701369375\n",
            "Epoch: 291 Loss: 0.00014686203212477267\n",
            "Epoch: 292 Loss: 0.0001212032075272873\n",
            "Epoch: 293 Loss: 0.0001332848914898932\n",
            "Epoch: 294 Loss: 0.00011656247079372406\n",
            "Epoch: 295 Loss: 0.0001472148287575692\n",
            "Epoch: 296 Loss: 0.00012497318675741553\n",
            "Epoch: 297 Loss: 0.00012778745440300554\n",
            "Epoch: 298 Loss: 0.000159711780725047\n",
            "Epoch: 299 Loss: 0.000128978441352956\n",
            "Epoch: 300 Loss: 0.00012897240230813622\n",
            "Epoch: 301 Loss: 0.0001327576901530847\n",
            "Epoch: 302 Loss: 0.00016601794050075114\n",
            "Epoch: 303 Loss: 0.0001835494040278718\n",
            "Epoch: 304 Loss: 0.00019715010421350598\n",
            "Epoch: 305 Loss: 0.00015358399832621217\n",
            "Epoch: 306 Loss: 0.0001388288219459355\n",
            "Epoch: 307 Loss: 0.00013167900033295155\n",
            "Epoch: 308 Loss: 0.00010749502689577639\n",
            "Epoch: 309 Loss: 0.00010739081335486844\n",
            "Epoch: 310 Loss: 0.00011856005585286766\n",
            "Epoch: 311 Loss: 0.00011475467181298882\n",
            "Epoch: 312 Loss: 8.570948557462543e-05\n",
            "Epoch: 313 Loss: 0.00010392260446678847\n",
            "Epoch: 314 Loss: 8.108798647299409e-05\n",
            "Epoch: 315 Loss: 0.00016043319192249328\n",
            "Epoch: 316 Loss: 9.529013914288953e-05\n",
            "Epoch: 317 Loss: 9.241614316124469e-05\n",
            "Epoch: 318 Loss: 9.5680050435476e-05\n",
            "Epoch: 319 Loss: 8.032501500565559e-05\n",
            "Epoch: 320 Loss: 0.00010778831347124651\n",
            "Epoch: 321 Loss: 6.691124872304499e-05\n",
            "Epoch: 322 Loss: 0.0001171232433989644\n",
            "Epoch: 323 Loss: 8.336940663866699e-05\n",
            "Epoch: 324 Loss: 9.038241114467382e-05\n",
            "Epoch: 325 Loss: 7.352078682743013e-05\n",
            "Epoch: 326 Loss: 9.859878628049046e-05\n",
            "Epoch: 327 Loss: 7.464250666089356e-05\n",
            "Epoch: 328 Loss: 0.00011319025361444801\n",
            "Epoch: 329 Loss: 8.657239959575236e-05\n",
            "Epoch: 330 Loss: 9.750176104716957e-05\n",
            "Epoch: 331 Loss: 0.00010357181599829346\n",
            "Epoch: 332 Loss: 9.307228901889175e-05\n",
            "Epoch: 333 Loss: 7.092677697073668e-05\n",
            "Epoch: 334 Loss: 8.17974068922922e-05\n",
            "Epoch: 335 Loss: 8.593003440182656e-05\n",
            "Epoch: 336 Loss: 0.00010110611765412614\n",
            "Epoch: 337 Loss: 0.00010511293658055365\n",
            "Epoch: 338 Loss: 9.637380571803078e-05\n",
            "Epoch: 339 Loss: 0.00010780330921988934\n",
            "Epoch: 340 Loss: 0.00010820011812029406\n",
            "Epoch: 341 Loss: 0.00011604039900703356\n",
            "Epoch: 342 Loss: 0.00011139858543174341\n",
            "Epoch: 343 Loss: 0.00010573754843790084\n",
            "Epoch: 344 Loss: 0.00010965660476358607\n",
            "Epoch: 345 Loss: 0.0001141722168540582\n",
            "Epoch: 346 Loss: 8.661216998007149e-05\n",
            "Epoch: 347 Loss: 0.00011073459609178826\n",
            "Epoch: 348 Loss: 0.00010185818973695859\n",
            "Epoch: 349 Loss: 0.00011660488235065714\n",
            "Epoch: 350 Loss: 9.570343536324799e-05\n",
            "Epoch: 351 Loss: 0.00011826996342279017\n",
            "Epoch: 352 Loss: 0.00010695634409785271\n",
            "Epoch: 353 Loss: 9.700455848360434e-05\n",
            "Epoch: 354 Loss: 9.393146319780499e-05\n",
            "Epoch: 355 Loss: 9.715287887956947e-05\n",
            "Epoch: 356 Loss: 8.076104859355837e-05\n",
            "Epoch: 357 Loss: 0.00012395413068588823\n",
            "Epoch: 358 Loss: 9.940775635186583e-05\n",
            "Epoch: 359 Loss: 9.854539530351758e-05\n",
            "Epoch: 360 Loss: 8.91932868398726e-05\n",
            "Epoch: 361 Loss: 0.00010167805885430425\n",
            "Epoch: 362 Loss: 0.00013288423360791057\n",
            "Epoch: 363 Loss: 6.870267679914832e-05\n",
            "Epoch: 364 Loss: 9.832147043198347e-05\n",
            "Epoch: 365 Loss: 0.00010355632548453286\n",
            "Epoch: 366 Loss: 9.77351883193478e-05\n",
            "Epoch: 367 Loss: 7.876041490817443e-05\n",
            "Epoch: 368 Loss: 0.00012130642426200211\n",
            "Epoch: 369 Loss: 8.633438847027719e-05\n",
            "Epoch: 370 Loss: 7.492805161746219e-05\n",
            "Epoch: 371 Loss: 8.412152237724513e-05\n",
            "Epoch: 372 Loss: 7.894638110883534e-05\n",
            "Epoch: 373 Loss: 8.68461502250284e-05\n",
            "Epoch: 374 Loss: 6.627101538470015e-05\n",
            "Epoch: 375 Loss: 0.00011487597657833248\n",
            "Epoch: 376 Loss: 9.141506598098204e-05\n",
            "Epoch: 377 Loss: 8.761142089497298e-05\n",
            "Epoch: 378 Loss: 9.55926370806992e-05\n",
            "Epoch: 379 Loss: 8.260820322902873e-05\n",
            "Epoch: 380 Loss: 7.873392314650118e-05\n",
            "Epoch: 381 Loss: 9.895991388475522e-05\n",
            "Epoch: 382 Loss: 9.361855336464942e-05\n",
            "Epoch: 383 Loss: 7.642238779226318e-05\n",
            "Epoch: 384 Loss: 8.338507905136794e-05\n",
            "Epoch: 385 Loss: 7.914820162113756e-05\n",
            "Epoch: 386 Loss: 9.943048644345254e-05\n",
            "Epoch: 387 Loss: 8.286441152449697e-05\n",
            "Epoch: 388 Loss: 6.857774133095518e-05\n",
            "Epoch: 389 Loss: 8.311566489282995e-05\n",
            "Epoch: 390 Loss: 7.448327960446477e-05\n",
            "Epoch: 391 Loss: 8.27728581498377e-05\n",
            "Epoch: 392 Loss: 5.116411921335384e-05\n",
            "Epoch: 393 Loss: 7.441643538186327e-05\n",
            "Epoch: 394 Loss: 6.769946776330471e-05\n",
            "Epoch: 395 Loss: 9.163193317363039e-05\n",
            "Epoch: 396 Loss: 5.974562373012304e-05\n",
            "Epoch: 397 Loss: 9.191986464429647e-05\n",
            "Epoch: 398 Loss: 0.00010291746002621949\n",
            "Epoch: 399 Loss: 9.449958452023566e-05\n",
            "Epoch: 400 Loss: 0.0001050168284564279\n",
            "Epoch: 401 Loss: 9.688336285762489e-05\n",
            "Epoch: 402 Loss: 0.00011777118925238028\n",
            "Epoch: 403 Loss: 0.00010057030158350244\n",
            "Epoch: 404 Loss: 0.00011635937698883936\n",
            "Epoch: 405 Loss: 0.00012022408191114664\n",
            "Epoch: 406 Loss: 8.97724021342583e-05\n",
            "Epoch: 407 Loss: 0.00013035532901994884\n",
            "Epoch: 408 Loss: 8.869524754118174e-05\n",
            "Epoch: 409 Loss: 0.00011491141049191356\n",
            "Epoch: 410 Loss: 0.00010595290223136544\n",
            "Epoch: 411 Loss: 0.0001118019426940009\n",
            "Epoch: 412 Loss: 0.00011248068040004\n",
            "Epoch: 413 Loss: 8.47268383949995e-05\n",
            "Epoch: 414 Loss: 9.211588621838018e-05\n",
            "Epoch: 415 Loss: 0.00011315313167870045\n",
            "Epoch: 416 Loss: 9.432363003725186e-05\n",
            "Epoch: 417 Loss: 0.00010900833876803517\n",
            "Epoch: 418 Loss: 9.380570554640144e-05\n",
            "Epoch: 419 Loss: 0.000103041558759287\n",
            "Epoch: 420 Loss: 0.00011618042481131852\n",
            "Epoch: 421 Loss: 0.0001216268865391612\n",
            "Epoch: 422 Loss: 0.00012387863534968346\n",
            "Epoch: 423 Loss: 0.00011170358629897237\n",
            "Epoch: 424 Loss: 0.00012101349420845509\n",
            "Epoch: 425 Loss: 8.579721907153726e-05\n",
            "Epoch: 426 Loss: 9.193430014420301e-05\n",
            "Epoch: 427 Loss: 8.254882413893938e-05\n",
            "Epoch: 428 Loss: 9.634049638407305e-05\n",
            "Epoch: 429 Loss: 7.795656711095944e-05\n",
            "Epoch: 430 Loss: 7.353055843850598e-05\n",
            "Epoch: 431 Loss: 9.604225488146767e-05\n",
            "Epoch: 432 Loss: 8.404986874666065e-05\n",
            "Epoch: 433 Loss: 8.559606794733554e-05\n",
            "Epoch: 434 Loss: 9.448270429857075e-05\n",
            "Epoch: 435 Loss: 8.478695235680789e-05\n",
            "Epoch: 436 Loss: 0.00010732414375524968\n",
            "Epoch: 437 Loss: 9.084863995667547e-05\n",
            "Epoch: 438 Loss: 8.291425183415413e-05\n",
            "Epoch: 439 Loss: 8.664502820465714e-05\n",
            "Epoch: 440 Loss: 0.00011529624316608533\n",
            "Epoch: 441 Loss: 6.973184645175934e-05\n",
            "Epoch: 442 Loss: 0.00011726889351848513\n",
            "Epoch: 443 Loss: 6.698448851238936e-05\n",
            "Epoch: 444 Loss: 0.00010048069816548377\n",
            "Epoch: 445 Loss: 0.00010159547673538327\n",
            "Epoch: 446 Loss: 0.00012017950211884454\n",
            "Epoch: 447 Loss: 8.575222454965115e-05\n",
            "Epoch: 448 Loss: 9.98212635749951e-05\n",
            "Epoch: 449 Loss: 0.00010900726192630827\n",
            "Epoch: 450 Loss: 0.00010272461804561317\n",
            "Epoch: 451 Loss: 0.00010633515194058418\n",
            "Epoch: 452 Loss: 0.00012381337000988424\n",
            "Epoch: 453 Loss: 0.00011557797552086413\n",
            "Epoch: 454 Loss: 0.00016272399807348847\n",
            "Epoch: 455 Loss: 0.00011933626956306398\n",
            "Epoch: 456 Loss: 0.0001632243802305311\n",
            "Epoch: 457 Loss: 0.00011879105295520276\n",
            "Epoch: 458 Loss: 0.0001340944872936234\n",
            "Epoch: 459 Loss: 0.00014156545512378216\n",
            "Epoch: 460 Loss: 0.00014521607954520732\n",
            "Epoch: 461 Loss: 9.547153604216874e-05\n",
            "Epoch: 462 Loss: 0.00011557672405615449\n",
            "Epoch: 463 Loss: 0.0001291255175601691\n",
            "Epoch: 464 Loss: 0.00012336773215793073\n",
            "Epoch: 465 Loss: 0.00010060964268632233\n",
            "Epoch: 466 Loss: 0.00012237067858222872\n",
            "Epoch: 467 Loss: 0.00010404160275356844\n",
            "Epoch: 468 Loss: 0.00010712251241784543\n",
            "Epoch: 469 Loss: 0.00010116007615579292\n",
            "Epoch: 470 Loss: 9.782690176507458e-05\n",
            "Epoch: 471 Loss: 0.00010361929889768362\n",
            "Epoch: 472 Loss: 0.00011533294309629127\n",
            "Epoch: 473 Loss: 0.00011914657079614699\n",
            "Epoch: 474 Loss: 0.00010311044025002047\n",
            "Epoch: 475 Loss: 0.00012297880311962217\n",
            "Epoch: 476 Loss: 0.00011200589506188408\n",
            "Epoch: 477 Loss: 0.00011522534623509273\n",
            "Epoch: 478 Loss: 0.00010226937592960894\n",
            "Epoch: 479 Loss: 0.00014158501289784908\n",
            "Epoch: 480 Loss: 0.00011150735372211784\n",
            "Epoch: 481 Loss: 0.00014132520300336182\n",
            "Epoch: 482 Loss: 0.00014137965627014637\n",
            "Epoch: 483 Loss: 0.0001255397219210863\n",
            "Epoch: 484 Loss: 9.974712156690657e-05\n",
            "Epoch: 485 Loss: 0.00011637634452199563\n",
            "Epoch: 486 Loss: 0.00011451195314293727\n",
            "Epoch: 487 Loss: 0.00010536637273617089\n",
            "Epoch: 488 Loss: 0.0001279144053114578\n",
            "Epoch: 489 Loss: 0.000114311849756632\n",
            "Epoch: 490 Loss: 0.00011123299918835983\n",
            "Epoch: 491 Loss: 0.00014434872718993574\n",
            "Epoch: 492 Loss: 0.00016202250844798982\n",
            "Epoch: 493 Loss: 0.00013699138071388006\n",
            "Epoch: 494 Loss: 0.00016494840383529663\n",
            "Epoch: 495 Loss: 0.00015063049795571715\n",
            "Epoch: 496 Loss: 0.00011542450374690816\n",
            "Epoch: 497 Loss: 0.00011719103349605575\n",
            "Epoch: 498 Loss: 0.00011812527372967452\n",
            "Epoch: 499 Loss: 0.00014364789240062237\n"
          ]
        }
      ],
      "source": [
        "## Training the model\n",
        "\n",
        "\"\"\"\n",
        "Epoch: Number of training steps/iterations\n",
        "Batch Size: Number of obseravtions that are used during each iterations to update weights. \n",
        "\"\"\"\n",
        "num_epochs =300\n",
        "batch_size = 8\n",
        "\n",
        "to_plot_220 = []\n",
        "from sklearn.utils import shuffle\n",
        "#df = shuffle(df) \n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver = tf.train.import_meta_graph('./content/MyDrive/checkpoint_dir/my_model.meta')\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('/content/content/MyDrive/checkpoint_dir'))# 加载变量值\n",
        "    for epoch in range(num_epochs):\n",
        "        for index, offset in enumerate(range(0, lsd1.shape[0], batch_size)):\n",
        "            xs = lsd1[offset: offset + batch_size]\n",
        "            #print(offset)\n",
        "            sess.run(train, feed_dict={X: xs})\n",
        "        training_loss = loss.eval(feed_dict={X: xs})\n",
        "        to_plot_220.append(training_loss)\n",
        "        print(\"Epoch: {} Loss: {}\".format(epoch,training_loss))\n",
        "        \n",
        "        \n",
        "    \"\"\"\n",
        "    Saving the trained model\n",
        "    \"\"\"\n",
        "    saver.save(sess,'./checkpoint_/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## With the weights obtained from training earlier, lets obtains the feature vectors at the latent space\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess,'./checkpoint_/my_model')\n",
        "    res = hid_layer1.eval(feed_dict={X: df})"
      ],
      "metadata": {
        "id": "CP7Jlv_mtZWI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LcqAYrH3u7-",
        "outputId": "ee7a9506-509f-4139-f53a-d70b1427dc9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04372333, 0.        , 0.        , ..., 0.50340813, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.26928365,\n",
              "        0.52944446],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.9195694 ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 1.5030838 , 0.        ,\n",
              "        0.60063064],\n",
              "       [0.7530319 , 0.        , 0.61504674, ..., 0.85989213, 0.        ,\n",
              "        0.89250267],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lGvlQ-tByw54",
        "outputId": "d04a14f9-ea1b-46d2-c13b-5a657cebdf89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## Visualizing\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(to_plot_220)\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Vs number epochs for latent space of 384 Dimensions\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEqCkHsQybSk",
        "outputId": "75de0288-c47c-4f15-da10-02d2896e3946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5         6    \\\n",
            "0    0.043723  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.075856   \n",
            "2    0.000000  0.000000  0.000000  0.000000  0.562848  0.227398  0.977232   \n",
            "3    0.000000  0.620710  0.015127  0.313432  0.000000  0.000000  0.000000   \n",
            "4    0.000000  0.000000  0.006820  0.743159  0.000000  0.000000  0.373046   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "926  0.000000  0.205347  0.000000  0.000000  0.191108  0.357335  0.000000   \n",
            "927  0.000000  0.000000  0.000000  0.000000  0.646334  0.639531  0.297859   \n",
            "928  0.000000  0.000000  0.000000  0.000000  0.961703  1.272657  0.110852   \n",
            "929  0.753032  0.000000  0.615047  0.055410  0.000000  0.118663  0.463131   \n",
            "930  0.000000  0.000000  0.000000  0.083836  0.324445  0.000000  0.000000   \n",
            "\n",
            "          7         8         9    ...       374       375       376  \\\n",
            "0    0.000000  0.000000  0.795234  ...  0.000000  0.028108  0.000000   \n",
            "1    0.000000  0.000000  0.086171  ...  0.393647  0.038902  0.000000   \n",
            "2    0.000000  0.232765  0.384671  ...  0.000000  0.177679  0.000000   \n",
            "3    0.000000  0.000000  0.000000  ...  0.693227  0.330949  0.549048   \n",
            "4    0.000000  0.000000  0.076272  ...  0.000000  0.240999  0.105254   \n",
            "..        ...       ...       ...  ...       ...       ...       ...   \n",
            "926  0.467242  0.000000  0.652131  ...  0.000000  0.000000  0.915551   \n",
            "927  0.601522  1.410557  0.000000  ...  0.000000  0.000000  1.318822   \n",
            "928  1.438215  0.435879  0.000000  ...  0.327411  0.000000  1.025209   \n",
            "929  0.325672  0.000000  0.000000  ...  0.000000  0.000000  0.229460   \n",
            "930  0.000000  0.974440  0.000000  ...  0.000000  0.000000  0.000000   \n",
            "\n",
            "          377       378       379       380       381       382       383  \n",
            "0    0.569079  0.000000  0.000000  0.000000  0.503408  0.000000  0.000000  \n",
            "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.269284  0.529444  \n",
            "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.919569  \n",
            "3    0.000000  0.000000  0.000000  0.000000  0.124954  0.128109  0.449335  \n",
            "4    0.412252  0.000000  0.056270  0.000000  0.000000  0.310122  0.000000  \n",
            "..        ...       ...       ...       ...       ...       ...       ...  \n",
            "926  0.000000  0.000000  0.450572  0.000000  0.403763  0.000000  0.000000  \n",
            "927  0.000000  0.000000  0.594119  1.083617  1.583192  0.000000  0.744038  \n",
            "928  0.000000  0.000000  0.373397  0.898557  1.503084  0.000000  0.600631  \n",
            "929  0.000000  0.581102  0.292110  0.000000  0.859892  0.000000  0.892503  \n",
            "930  0.664639  0.905751  0.084959  0.469112  0.000000  0.000000  0.000000  \n",
            "\n",
            "[931 rows x 384 columns]\n"
          ]
        }
      ],
      "source": [
        "res.shape\n",
        "dr = pd.DataFrame(res)\n",
        "print(dr)\n",
        "dr.to_csv('384.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61CtakHyzeYb"
      },
      "source": [
        "# More larger Dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ5U160AUnLR",
        "outputId": "d32dee0c-1d65-4b30-ad73-b40eeba24fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 0.10121292620897293\n",
            "Epoch: 20 Loss: 0.012367009185254574\n",
            "Epoch: 40 Loss: 0.01190527155995369\n",
            "Epoch: 60 Loss: 0.009825997985899448\n",
            "Epoch: 80 Loss: 0.012089080177247524\n",
            "Epoch: 100 Loss: 0.012143723666667938\n",
            "Epoch: 120 Loss: 0.008897398598492146\n",
            "Epoch: 140 Loss: 0.00812164694070816\n",
            "Epoch: 160 Loss: 0.010212169960141182\n",
            "Epoch: 180 Loss: 0.008470087312161922\n",
            "Epoch: 200 Loss: 0.010004487819969654\n",
            "Epoch: 220 Loss: 0.008345128037035465\n",
            "Epoch: 240 Loss: 0.008415118791162968\n",
            "Epoch: 260 Loss: 0.008509389124810696\n",
            "Epoch: 280 Loss: 0.00817402359098196\n",
            "Epoch: 300 Loss: 0.0077760168351233006\n",
            "Epoch: 320 Loss: 0.007885734550654888\n",
            "Epoch: 340 Loss: 0.008110381662845612\n",
            "Epoch: 360 Loss: 0.006951645016670227\n",
            "Epoch: 380 Loss: 0.007551573216915131\n",
            "Epoch: 400 Loss: 0.0071871024556458\n",
            "Epoch: 420 Loss: 0.007503820117563009\n",
            "Epoch: 440 Loss: 0.009221826680004597\n",
            "Epoch: 460 Loss: 0.007303739432245493\n",
            "Epoch: 480 Loss: 0.007328186649829149\n"
          ]
        }
      ],
      "source": [
        "num_inputs = 512\n",
        "\n",
        "hidden_1 = 512//2       ## 256\n",
        "hidden_2 = hidden_1 //2  ## 128\n",
        "hidden_3 = hidden_2 //2  ## 64\n",
        "hidden_4 = hidden_2\n",
        "hidden_5 = hidden_1\n",
        "\n",
        "num_outputs = num_inputs ## 512\n",
        "\n",
        "learning_rate = 0.001\n",
        "activ_fn = tf.nn.relu\n",
        "#norm = tf.nn.batch_normalization()\n",
        "\n",
        "X = tf.placeholder(tf.float32,shape = [None,num_inputs])\n",
        "\n",
        "## scaling \n",
        "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
        "\n",
        "## Weights\n",
        "\n",
        "w1 = tf.Variable(initializer([num_inputs,hidden_1]),dtype=tf.float32)\n",
        "w2 = tf.Variable(initializer([hidden_1,hidden_2]),dtype=tf.float32)\n",
        "w3 = tf.Variable(initializer([hidden_2,hidden_3]),dtype=tf.float32)\n",
        "w4 = tf.transpose(w3)\n",
        "w5 = tf.transpose(w2)\n",
        "w6 = tf.transpose(w1)\n",
        "\n",
        "\n",
        "\n",
        "## Biases\n",
        "\n",
        "b1 = tf.Variable(tf.zeros(hidden_1))\n",
        "b2 = tf.Variable(tf.zeros(hidden_2))\n",
        "b3 = tf.Variable(tf.zeros(hidden_3))\n",
        "\n",
        "b4 = b2\n",
        "b5 = b1\n",
        "\n",
        "b6 = tf.Variable(tf.zeros(num_outputs))\n",
        "\n",
        "\n",
        "hid_layer1 = activ_fn(tf.matmul(X,w1)+b1)\n",
        "hid_layer2 = activ_fn(tf.matmul(hid_layer1,w2)+b2)\n",
        "hid_layer3 = activ_fn(tf.matmul(hid_layer2,w3)+b3)\n",
        "hid_layer4 = activ_fn(tf.matmul(hid_layer3,w4)+b4)\n",
        "hid_layer5 = activ_fn(tf.matmul(hid_layer4,w5)+b5)\n",
        "output_layer = activ_fn(tf.matmul(hid_layer5,w6)+b6)\n",
        "\n",
        "## Loss Function\n",
        "\n",
        "loss = tf.reduce_mean(tf.square(output_layer - X))\n",
        "\n",
        "## Optimzer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "## Initialzing\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "num_epochs = 500\n",
        "batch_size = 8\n",
        "to_plot = []\n",
        "from sklearn.utils import shuffle\n",
        "#X = shuffle(X) \n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        for index, offset in enumerate(range(0, df.shape[0], batch_size)):\n",
        "            xs = df[offset: offset + batch_size]\n",
        "            #print(offset)\n",
        "            sess.run(train, feed_dict={X: xs})\n",
        "        training_loss = loss.eval(feed_dict={X: xs})\n",
        "        to_plot.append(training_loss)\n",
        "        if epoch % 20 == 0:\n",
        "          print(\"Epoch: {} Loss: {}\".format(epoch,training_loss))\n",
        "    \n",
        "    saver.save(sess,'./stacked_autoencoder_32_50D_tanh.ckpt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPJDGHFJdIp4"
      },
      "outputs": [],
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess,'./stacked_autoencoder_32_50D_tanh.ckpt')\n",
        "    d50 = hid_layer3.eval(feed_dict={X: df})  \n",
        "\n",
        "np.savetxt('Dim_64.tsv',d50,delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgD_uW2tdRyg",
        "outputId": "a34f8279-1126-4cfd-edde-3418b54b49f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.60872406, 0.        , 0.        , ..., 0.01195174, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 1.5955508 , 0.        , ..., 0.        , 0.        ,\n",
              "        1.7521322 ],\n",
              "       [0.        , 2.2621021 , 0.        , ..., 0.        , 0.        ,\n",
              "        2.5632324 ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.000032  ],\n",
              "       [0.        , 0.        , 0.        , ..., 1.340622  , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.56723374, 0.        ,\n",
              "        0.0072813 ]], dtype=float32)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "v9gM0WKMdT6F",
        "outputId": "e89a1752-6538-47e7-bfb8-e1a856d0a2b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Dim_51,= plt.plot(to_plot, label=\"Dimension 51\")\n",
        "Dim_220, =  plt.plot(to_plot_220, label=\"Dimension 220\")\n",
        "plt.legend(handles=[Dim_51, Dim_220])\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Vs number epochs for different latent space\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JcuxAkntsrKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6p_zlz9psrVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iz6RHa56srXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FltyGhPbsrZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bXMhWFoEsrcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "54B6kWA8sreK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eqii8Fsasrgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g0Q0cLiDsri7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yxDz-uaksrk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gQKbJAo2srnT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "“Untitled8.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13CA2fuoXESKGJTteevSjMCORxzUkc1I6",
      "authorship_tag": "ABX9TyOQTHTNy6u1iWaUeG47nmGd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}