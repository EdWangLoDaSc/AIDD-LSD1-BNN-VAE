{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgRt2j7BGDT6wQXMiuuH3D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdWangLoDaSc/Dropout-as-a-Grid-Search_Representing-Model-Uncertainty-in-Deep-Learning/blob/main/BNN_ense_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOFT1uAJe-k2",
        "outputId": "43c48c68-1ae0-4436-d3ad-950bf3be4bab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install edward2\n",
        "!pip install tensorflow_probability \n",
        "!pip install edward"
      ],
      "metadata": {
        "id": "xVjeMCllpf84",
        "outputId": "1102164a-5316-4488-bf75-4b9c2d53286b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting edward2\n",
            "  Downloading edward2-0.0.2-py2.py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 7.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: edward2\n",
            "Successfully installed edward2-0.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_probability in /usr/local/lib/python3.7/dist-packages (0.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (4.4.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (0.5.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting edward\n",
            "  Downloading edward-1.3.5.tar.gz (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from edward) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from edward) (1.15.0)\n",
            "Building wheels for collected packages: edward\n",
            "  Building wheel for edward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for edward: filename=edward-1.3.5-py3-none-any.whl size=90385 sha256=b9c57436e83669f9a96c57f43d1b3c6befa85256b294d464b3604d5c0252af4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/d0/6f/298c809cc8db6573b8642d1473c668868a67b9ad297c2e8b65\n",
            "Successfully built edward\n",
            "Installing collected packages: edward\n",
            "Successfully installed edward-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS_tz-IYe6Z4",
        "outputId": "7d76960c-e8e6-45b9-90ca-31cbeada647f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['script_methods.py',\n",
              " 'DataGen.py',\n",
              " 'module_HMC_orig.py',\n",
              " 'module_last_layer.py',\n",
              " 'main_converge.py',\n",
              " 'hyperparams.py',\n",
              " 'module_NN_ens.py',\n",
              " 'main_exp.py',\n",
              " 'utils.py',\n",
              " 'module_VI.py',\n",
              " 'module_gp.py',\n",
              " 'pymc_HMC_VI.py',\n",
              " 'get-pip.py',\n",
              " 'Untitled.ipynb',\n",
              " '01_data',\n",
              " '.ipynb_checkpoints',\n",
              " '__pycache__',\n",
              " 'module_HMC.py',\n",
              " 'script_anch_need.py']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "path=\"/content/drive/MyDrive/Bayesian_NN_Ensembles-master/regression\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import importlib\n",
        "#import DataGen\n",
        "import utils\n",
        "import module_gp\n",
        "import module_NN_ens\n",
        "import module_HMC\n",
        "#import module_VI"
      ],
      "metadata": {
        "id": "GHGHFkZXfolP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "8ZYaozS13uSW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = datetime.datetime.now()\n",
        "print('started')\n",
        "\n",
        "# avoid the dreaded type 3 fonts...\n",
        "plt.rcParams['pdf.fonttype'] = 42\n",
        "plt.rcParams['ps.fonttype'] = 42\n",
        "plt.rcParams.update({'font.size': 10})\n",
        "# plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.rcParams['text.usetex'] = True\n",
        "\n",
        "np.random.seed(101)\n"
      ],
      "metadata": {
        "id": "jhvaMPB1359v",
        "outputId": "e4f2424a-760e-454f-e406-68b9d8648ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "started\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = pd.read_csv('/content/drive/MyDrive/Bayesian_NN_Ensembles-master/Datasets/Datasets.csv') \n",
        "n_samples = 12\n",
        "activation_fn = 'relu' \t\t# activation type - relu, erf, rbf, softplus, Lrelu (Leaky ReLu)\n",
        "data_noise = 0.08 \t\t\t# data noise variance\n",
        "b_0_var = 10.\t\t\t\t# var of b_0\n",
        "w_0_var = b_0_var\t\t\t# var of w_0\n",
        "# w_0_var = 4\t\t\t\n",
        "u_var = 1.0\t\t\t\t\t# var for rbf params as -> inf, goes to stationary cov dist\n",
        "g_var = 1\t\t\t\t\t# var for rbf params\n",
        "n_runs = 1\n",
        "\n",
        "# -- NN model inputs --\n",
        "optimiser_in = 'adam' \t\t# optimiser: adam, SGD\n",
        "learning_rate = 0.003\t\t# learning rate\n",
        "hidden_size = 1000\t\t\t# no. hidden neurons\n",
        "n_epochs = 2000\t\t\t\t# no. epochs to train for\n",
        "cycle_print = n_epochs/5 \t# print info every cycle no. of epochs\n",
        "batch_size = 64\n",
        "n_ensembles = 5\t\t\t\t# no. NNs in ensemble\n",
        "\n",
        "\n",
        "# -- NN model inputs --\n",
        "optimiser_in = 'adam' \t\t# optimiser: adam, SGD\n",
        "learning_rate = 0.003\t\t# learning rate\n",
        "hidden_size = 1000\t\t\t# no. hidden neurons\n",
        "n_epochs = 2000\t\t\t\t# no. epochs to train for\n",
        "cycle_print = n_epochs/5 \t# print info every cycle no. of epochs\n",
        "batch_size = 64\n",
        "n_ensembles = 5\t\t\t\t# no. NNs in ensemble\n",
        "\n",
        "# -- NN model inputs --\n",
        "optimiser_in = 'adam' \t\t# optimiser: adam, SGD\n",
        "learning_rate = 0.003\t\t# learning rate\n",
        "hidden_size = 1000\t\t\t# no. hidden neurons\n",
        "n_epochs = 2000\t\t\t\t# no. epochs to train for\n",
        "cycle_print = n_epochs/5 \t# print info every cycle no. of epochs\n",
        "batch_size = 64\n",
        "n_ensembles = 5\t\t\t\t# no. NNs in ensemble\n",
        "\n",
        "# -- NN model inputs --\n",
        "optimiser_in = 'adam' \t\t# optimiser: adam, SGD\n",
        "learning_rate = 0.003\t\t# learning rate\n",
        "hidden_size = 1000\t\t\t# no. hidden neurons\n",
        "n_epochs = 2000\t\t\t\t# no. epochs to train for\n",
        "cycle_print = n_epochs/5 \t# print info every cycle no. of epochs\n",
        "batch_size = 64\n",
        "n_ensembles = 5\t\t\t\t# no. NNs in ensemble\n",
        "\n",
        "# which to run\n",
        "is_gp_run = 1\n",
        "is_ens_run = 1\n",
        "is_mc_run = 0\n",
        "is_hmc_run = 0\n",
        "is_unconstrained_run = 1\n",
        "is_reg_run = 1\n",
        "\n",
        "is_single_run = 0\n",
        "is_sk_run = 0\n",
        "\n",
        "gp_results=[]; ens_results=[]; single_results=[]; mc_results=[]; \n",
        "hmc_results=[]; sk_results=[]; unc_ens_results=[]; \n",
        "run_kls=[]"
      ],
      "metadata": {
        "id": "fRkLdQwz35_y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for run_ in range(n_runs):\n",
        "\tprint('\\n\\n  ====== run:',run_, '======\\n')\n",
        "\n",
        "\t# -- create data --\n",
        "\tdata_set = pd.read_csv('/content/drive/MyDrive/Bayesian_NN_Ensembles-master/Datasets/Datasets.csv') \n",
        "\tX=data_set.drop(['Calculated pChEMBL'],axis = 1)\n",
        "\tY=data_set['Calculated pChEMBL']\n",
        "\tX_train, y_train, X_val, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\tn_samples = X_train.shape[0]\n",
        "\tX_dim = X_train.shape[1]\n",
        "\ty_dim = 1\n",
        "\n",
        "\t# mesh the input space for evaluations\n",
        "\tif X_dim == 1:\n",
        "\t\tX_grid = np.atleast_2d(np.linspace(-4, 4, 150)).T\n",
        "\t\tX_val = X_grid\n",
        "\t\ty_val = np.expand_dims(X_grid[:,0],1)\n",
        "\telif X_dim == 2:\n",
        "\t\tx_s = np.atleast_2d(np.linspace(-3, 3, 20)).T\n",
        "\t\tX_grid = np.array(np.meshgrid(x_s,x_s))\n",
        "\t\tX_grid = np.stack((X_grid[1].ravel(), X_grid[0].ravel()),axis=-1)\n",
        "\t\tX_val = X_grid\n",
        "\t\ty_val = np.expand_dims(X_grid[:,0],1)\n",
        "\telse:\n",
        "\t\tX_grid = X_val\n",
        "\n",
        "\n",
        "\t#if is_gp_run:\n",
        "\t\t# -- gp model --\n",
        "\t#\tgp = module_gp.gp_model(kernel_type=activation_fn, data_noise=data_noise, \n",
        "\t#\t\tb_0_var=b_0_var, w_0_var=w_0_var, u_var=5., g_var=1.)\n",
        "\t#\ty_pred_mu, y_pred_std = gp.run_inference(x_train=X_train, y_train=y_train, x_predict=X_val, print=False)\n",
        "#\n",
        "\t#\tmetrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, gp, is_print=True)\n",
        "\t#\tgp_results.append(np.array((gp.mse_unnorm, gp.rmse, gp.nll)))\n",
        "\t#\tif is_try_plot: try_plot(X_dim, X_grid, y_pred_mu, y_pred_std, X_train, y_train, gp, save=is_save_graphs)\n",
        "\n",
        "\n",
        "\t#if is_vi_run:\n",
        "\t\t# -- BNN with variational inference model --\n",
        "\t#\tvi = module_VI.vi_model(activation_fn=activation_fn, data_noise=data_noise, \n",
        "\t#\t\tb_0_var=b_0_var, w_0_var=w_0_var, u_var=5., g_var=1., hidden_size = hidden_size,\n",
        "\t#\t\tn_predict=n_predict_vi, n_iter=n_iter_vi, n_samples_vi=n_samples_vi)\n",
        "\n",
        "\t#\tvi.train(X_train=X_train, y_train=y_train, X_val=X_val,is_print=False)\n",
        "\n",
        "\t#\ty_preds, y_pred_mu, y_pred_std = vi.predict(X_val)\n",
        "\n",
        "\t#\tmetrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, vi, is_print=True)\n",
        "\t#\thmc_results.append(np.array((vi.mse_unnorm, vi.rmse, vi.nll)))\n",
        "\t\t#if is_try_plot: try_plot(X_dim, X_grid, y_pred_mu, y_pred_std, X_train, y_train, vi, save=is_save_graphs)#, y_preds)\n",
        "#\n",
        "\n",
        "\tif is_hmc_run:\n",
        "\t\t# -- hmc model --\n",
        "\t\thmc = module_HMC.hmc_model(activation_fn=activation_fn, data_noise=data_noise, \n",
        "\t\t\tb_0_var=b_0_var, w_0_var=w_0_var, u_var=5., g_var=1., hidden_size = hidden_size,\n",
        "\t\t\tstep_size=step_size, n_steps=n_steps, burn_in=burn_in, n_samples=n_samples_hmc, n_predict=n_predict_hmc)\n",
        "\n",
        "\t\thmc.train(X_train=X_train, y_train=y_train, X_val=X_val,is_print=False)\n",
        "\n",
        "\t\ty_preds, y_pred_mu, y_pred_std = hmc.predict(X_val)\n",
        "\n",
        "\t\tmetrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, hmc, is_print=True)\n",
        "\t\thmc_results.append(np.array((hmc.mse_unnorm, hmc.rmse, hmc.nll)))\n",
        "\t\tif is_try_plot: try_plot(X_dim, X_grid, y_pred_mu, y_pred_std, X_train, y_train, hmc, save=is_save_graphs)#, y_preds)\n",
        "\n",
        "\n",
        "\tif is_ens_run:\n",
        "\t\t# -- NN ensemble model --\n",
        "\t\ttotal_ens_run = 0; y_preds_list=[]\n",
        "\t\twhile total_ens_run < n_ensembles:\n",
        "\t\t\tprint('\\n\\ntotal_ens_run:',total_ens_run)\n",
        "\t\t\tn_ensembles_in = np.min((n_ensembles-total_ens_run,5))\n",
        "\t\t\tens = module_NN_ens.NN_ens(activation_fn=activation_fn, \n",
        "\t\t\t\tdata_noise=data_noise,\n",
        "\t\t\t\tb_0_var=b_0_var, w_0_var=w_0_var, u_var=u_var, g_var=g_var,\n",
        "\t\t\t\toptimiser_in = optimiser_in, \n",
        "\t\t\t\tlearning_rate = learning_rate, \n",
        "\t\t\t\thidden_size = hidden_size, \n",
        "\t\t\t\tn_epochs = n_epochs, \n",
        "\t\t\t\tcycle_print = cycle_print, \n",
        "\t\t\t\tn_ensembles = n_ensembles_in,\n",
        "\t\t\t\ttotal_trained=total_ens_run,\n",
        "\t\t\t\tbatch_size = batch_size\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\ty_priors, y_prior_mu, y_prior_std = ens.train(X_train, y_train, X_val, y_val, is_print=True)\n",
        "\t\t\t# plot priors\n",
        "\t\t\tif False:\n",
        "\t\t\t\tif is_try_plot: try_plot(X_dim, X_grid, y_prior_mu, y_prior_std, X_train, y_train, ens, y_priors)\n",
        "\t\t\ty_preds_temp, _mu, _std = ens.predict(X_val)\n",
        "\t\t\ttotal_ens_run += n_ensembles_in\n",
        "\t\t\ty_preds_list.append(y_preds_temp)\n",
        "\t\t\t# y_predsnp.concatenate((y_preds[0],y_preds[1]))\n",
        "\n",
        "\t\ty_preds = y_preds_list[0].copy()\n",
        "\t\tfor i in range(1,len(y_preds_list)):\n",
        "\t\t\ty_preds = np.concatenate((y_preds,np.atleast_2d(y_preds_list[i])))\n",
        "\t\t# y_preds = np.array(y_preds).T\n",
        "\t\ty_pred_mu = np.atleast_2d(np.mean(y_preds,axis=0)).T\n",
        "\t\ty_pred_std = np.atleast_2d(np.std(y_preds,axis=0, ddof=1)).T\n",
        "\t\ty_pred_std = np.sqrt(np.square(y_pred_std) + data_noise)\n",
        "\n",
        "\t\tmetrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, ens, is_print=True)\n",
        "\t\tens_results.append(np.array((ens.mse_unnorm, ens.rmse, ens.nll)))\n",
        "\t\tif is_try_plot: try_plot(X_dim, X_grid, y_pred_mu, y_pred_std, X_train, y_train, ens, y_preds, save=is_save_graphs)\n",
        "\t\t\n",
        "\n",
        "\tif is_gp_run and is_ens_run:\n",
        "\t\tkl_avg = compare_dist(gp.y_pred_mu, gp.y_pred_std, y_pred_mu, y_pred_std)\n",
        "\t\tprint('\\n\\nkl(gp,NN_ens)',np.round(kl_avg,4))\n",
        "\t\trun_kls.append(kl_avg)\n",
        "\n",
        "\tif is_gp_run and is_hmc_run:\n",
        "\t\tkl_avg = compare_dist(gp.y_pred_mu, gp.y_pred_std, hmc.y_pred_mu, hmc.y_pred_std)\n",
        "\t\tprint('\\n\\nkl(gp,hmc)',np.round(kl_avg,4))\n",
        "\t\t# run_kls.append(kl_avg)\n",
        "\n",
        "\tif is_hmc_run and is_ens_run:\n",
        "\t\tkl_avg = compare_dist(hmc.y_pred_mu, hmc.y_pred_std, y_pred_mu, y_pred_std)\n",
        "\t\tprint('\\n\\nkl(hmc,NN_ens)',np.round(kl_avg,4))\n",
        "\t\t# run_kls.append(kl_avg)\n",
        "\n",
        "\tif is_mc_run:\n",
        "\t\tmc_NN = module_NN_ens.NN_ens(activation_fn=activation_fn, \n",
        "\t\t\tdata_noise=data_noise*single_lambda_mod, #!!!\n",
        "\t\t\tb_0_var=b_0_var, w_0_var=w_0_var, u_var=u_var, g_var=g_var,\n",
        "\t\t\toptimiser_in = optimiser_in, \n",
        "\t\t\tlearning_rate = learning_rate, \n",
        "\t\t\thidden_size = hidden_size, \n",
        "\t\t\tn_epochs = n_epochs, \n",
        "\t\t\tcycle_print = cycle_print, \n",
        "\t\t\tn_ensembles = 1,\n",
        "\t\t\tregularise=True,\n",
        "\t\t\tbatch_size = batch_size,\n",
        "\t\t\tdrop_out=True\n",
        "\t\t\t)\n",
        "\t\tmc_NN.train(X_train, y_train, X_val, y_val, is_print=True)\n",
        "\n",
        "\t\ty_preds=[]\n",
        "\t\tfor i in range(200):\n",
        "\t\t\ty_preds_temp, y_pred_mu, y_pred_std = mc_NN.predict(X_val)\n",
        "\t\t\ty_preds.append(y_preds_temp)\n",
        "\t\ty_preds = np.array(y_preds).squeeze()\n",
        "\t\ty_pred_mu = np.mean(y_preds,axis=0)\n",
        "\t\ty_pred_std = np.std(y_preds,axis=0, ddof=1)\n",
        "\n",
        "\t\t# add on data noise\n",
        "\t\ty_pred_std = np.sqrt(np.square(y_pred_std) + data_noise)\n",
        "\t\ty_pred_mu = np.atleast_2d(y_pred_mu).T\n",
        "\t\ty_pred_std = np.atleast_2d(y_pred_std).T\n",
        "\n",
        "\t\tmetrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, mc_NN, is_print=True)\n",
        "\t\tmc_results.append(np.array((mc_NN.mse_unnorm, mc_NN.rmse, mc_NN.nll)))\n",
        "\t\tif is_try_plot: try_plot(X_dim, X_grid, y_pred_mu, y_pred_std, X_train, y_train, mc_NN, save=is_save_graphs)\n",
        "\n",
        "\tif is_unconstrained_run:\n",
        "\t\t# -- NN ensemble model, unconstrained --\n",
        "\t\ttotal_ens_run = 0; y_preds_list=[]\n",
        "\t\twhile total_ens_run < n_ensembles:\n",
        "\t\t\tprint('\\n\\ntotal_ens_run:',total_ens_run)\n",
        "\t\t\tn_ensembles_in = np.min((n_ensembles-total_ens_run,5))\n",
        "\t\t\tunc_ens = module_NN_ens.NN_ens(activation_fn=activation_fn, \n",
        "\t\t\t\tdata_noise=data_noise,\n",
        "\t\t\t\tb_0_var=b_0_var, w_0_var=w_0_var, u_var=u_var, g_var=g_var,\n",
        "\t\t\t\toptimiser_in = optimiser_in, \n",
        "\t\t\t\tlearning_rate = learning_rate, \n",
        "\t\t\t\thidden_size = hidden_size, \n",
        "\t\t\t\tn_epochs = n_epochs, \n",
        "\t\t\t\tcycle_print = cycle_print, \n",
        "\t\t\t\tn_ensembles = n_ensembles_in,\n",
        "\t\t\t\ttotal_trained=total_ens_run,\n",
        "\t\t\t\tbatch_size = batch_size,\n",
        "\t\t\t\tunconstrain = True\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\ty_priors, y_prior_mu, y_prior_std = unc_ens.train(X_train, y_train, X_val, y_val, is_print=True)\n",
        "\t\t\ty_preds_temp, _mu, _std = unc_ens.predict(X_val)\n",
        "\t\t\ttotal_ens_run += n_ensembles_in\n",
        "\t\t\ty_preds_list.append(y_preds_temp)\n",
        "\t\t\t# y_predsnp.concatenate((y_preds[0],y_preds[1]))\n",
        "\n",
        "\t\ty_preds = y_preds_list[0].copy()\n",
        "\t\tfor i in range(1,len(y_preds_list)):\n",
        "\t\t\ty_preds = np.concatenate((y_preds,np.atleast_2d(y_preds_list[i])))\n",
        "\t\t# y_preds = np.array(y_preds).T\n",
        "\t\ty_pred_mu = np.atleast_2d(np.mean(y_preds,axis=0)).T\n",
        "\t\ty_pred_std = np.atleast_2d(np.std(y_preds,axis=0, ddof=1)).T\n",
        "\t\ty_pred_std = np.sqrt(np.square(y_pred_std) + data_noise)\n",
        "\n",
        "\t\tmetrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, unc_ens, is_print=True)\n",
        "\t\tunc_ens_results.append(np.array((unc_ens.mse_unnorm, unc_ens.rmse, unc_ens.nll)))\n",
        "\t\tif is_try_plot: try_plot(X_dim, X_grid, y_pred_mu, y_pred_std, X_train, y_train, unc_ens, y_preds, save=is_save_graphs)\n",
        "\t\t\n",
        "\tif is_reg_run:\n",
        "\t\t# -- NN ensemble model, regularised --\n",
        "\t\ttotal_ens_run = 0; y_preds_list=[]\n",
        "\t\twhile total_ens_run < n_ensembles:\n",
        "\t\t\tprint('\\n\\ntotal_ens_run:',total_ens_run)\n",
        "\t\t\tn_ensembles_in = np.min((n_ensembles-total_ens_run,5))\n",
        "\t\t\treg_ens = module_NN_ens.NN_ens(activation_fn=activation_fn, \n",
        "\t\t\t\tdata_noise=data_noise,\n",
        "\t\t\t\tb_0_var=b_0_var, w_0_var=w_0_var, u_var=u_var, g_var=g_var,\n",
        "\t\t\t\toptimiser_in = optimiser_in, \n",
        "\t\t\t\tlearning_rate = learning_rate, \n",
        "\t\t\t\thidden_size = hidden_size, \n",
        "\t\t\t\tn_epochs = n_epochs, \n",
        "\t\t\t\tcycle_print = cycle_print, \n",
        "\t\t\t\tn_ensembles = n_ensembles_in,\n",
        "\t\t\t\ttotal_trained=total_ens_run,\n",
        "\t\t\t\tbatch_size = batch_size,\n",
        "\t\t\t\tregularise=True\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\ty_priors, y_prior_mu, y_prior_std = reg_ens.train(X_train, y_train, X_val, y_val, is_print=True)\n",
        "\t\t\ty_preds_temp, _mu, _std = reg_ens.predict(X_val)\n",
        "\t\t\ttotal_ens_run += n_ensembles_in\n",
        "\t\t\ty_preds_list.append(y_preds_temp)\n",
        "\t\t\t# y_predsnp.concatenate((y_preds[0],y_preds[1]))\n",
        "\n",
        "\t\ty_preds = y_preds_list[0].copy()\n",
        "\t\tfor i in range(1,len(y_preds_list)):\n",
        "\t\t\ty_preds = np.concatenate((y_preds,np.atleast_2d(y_preds_list[i])))\n",
        "\t\t# y_preds = np.array(y_preds).T\n",
        "\t\ty_pred_mu = np.atleast_2d(np.mean(y_preds,axis=0)).T\n",
        "\t\ty_pred_std = np.atleast_2d(np.std(y_preds,axis=0, ddof=1)).T\n",
        "\t\ty_pred_std = np.sqrt(np.square(y_pred_std) + data_noise)\n",
        "\n",
        "\t\t# metrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, unc_ens, is_print=True)\n",
        "\t\t# unc_ens_results.append(np.array((unc_ens.mse_unnorm, unc_ens.rmse, unc_ens.nll)))\n",
        "\t\tif is_try_plot: try_plot(X_dim, X_grid, y_pred_mu, y_pred_std, X_train, y_train, reg_ens, y_preds, save=is_save_graphs)\n",
        "\t\t\n",
        "\n",
        "\tif is_single_run:\n",
        "\t\tsingle_NN = module_NN_ens.NN_ens(activation_fn=activation_fn, \n",
        "\t\t\tdata_noise=data_noise*single_lambda_mod, #!!!\n",
        "\t\t\tb_0_var=b_0_var, w_0_var=w_0_var, u_var=u_var, g_var=g_var,\n",
        "\t\t\toptimiser_in = optimiser_in, \n",
        "\t\t\tlearning_rate = learning_rate, \n",
        "\t\t\thidden_size = hidden_size, \n",
        "\t\t\tn_epochs = n_epochs, \n",
        "\t\t\tcycle_print = cycle_print, \n",
        "\t\t\tn_ensembles = 1,\n",
        "\t\t\tregularise=True,\n",
        "\t\t\tbatch_size = batch_size\n",
        "\t\t\t)\n",
        "\t\tsingle_NN.train(X_train, y_train, X_val, y_val, is_print=True)\n",
        "\t\t# y_preds_temp, y_pred_mu, y_pred_std = single_NN.predict(X_train)\n",
        "\t\t# single_data_noise = np.mean(np.square(y_train - np.atleast_2d(y_pred_mu).T))\n",
        "\t\ty_preds_temp, y_pred_mu, y_pred_std = single_NN.predict(X_val)\n",
        "\t\t# manually add constant noise here\n",
        "\t\t# y_pred_std = np.zeros_like(y_pred_std) + np.sqrt(data_noise)\n",
        "\t\t# print('\\nsingle_data_noise:',np.round(single_data_noise,4),'\\n')\n",
        "\t\t# y_pred_std = np.zeros_like(y_pred_std) + np.sqrt(single_data_noise)\n",
        "\t\ty_pred_std = np.zeros_like(y_pred_std) + single_data_n_std\n",
        "\t\ty_pred_mu = np.atleast_2d(y_pred_mu).T\n",
        "\t\ty_pred_std = np.atleast_2d(y_pred_std).T\n",
        "\n",
        "\t\tmetrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, single_NN, is_print=True)\n",
        "\t\tsingle_results.append(np.array((single_NN.mse_unnorm, single_NN.rmse, single_NN.nll)))\n",
        "\t\tif is_try_plot: try_plot(X_dim, X_grid, y_pred_mu, y_pred_std, X_train, y_train, single_NN, save=is_save_graphs)\n",
        "\n",
        "\tif is_sk_run:\n",
        "\t\tfrom sklearn import linear_model\n",
        "\t\t# sk_model = linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True)\n",
        "\n",
        "\t\tfrom sklearn.neighbors import KNeighborsRegressor\n",
        "\t\tsk_model = KNeighborsRegressor(n_neighbors=1, weights='uniform', algorithm='brute', leaf_size=30, p=2, metric='minkowski')\n",
        "\n",
        "\t\tsk_model.fit(X_train,y_train)\n",
        "\t\ty_pred_train = sk_model.predict(X_train)\n",
        "\t\tsk_data_noise = np.mean(np.square(y_train - y_pred_train))\n",
        "\t\ty_pred_mu = sk_model.predict(X_val)\n",
        "\t\t# y_pred_std = np.zeros_like(y_pred_mu) +  np.sqrt(sk_data_noise)*1.1 # add for overfit\n",
        "\t\ty_pred_std = np.zeros_like(y_pred_mu) +  0.2 # add for overfit\n",
        "\t\t\t\n",
        "\t\t# for completely naive\n",
        "\t\t# y_pred_mu = np.zeros_like(y_pred_mu)\n",
        "\t\t# y_pred_std = np.zeros_like(y_pred_mu) + 1.\n",
        "\n",
        "\t\tmse_unnorm, rmse, nll = metrics_calc(y_val, y_pred_mu, y_pred_std, Gen.scale_c, b_0_var, w_0_var, data_noise, is_print=True)\n",
        "\t\tsk_results.append(np.array((mse_unnorm, rmse, nll)))\n",
        "\n",
        "\n",
        "if is_gp_run:\n",
        "\tgp_results = np.array(gp_results)\n",
        "\tprint('\\n\\n___ GP RESULTS ___')\n",
        "\tprint('data', data_set, ', act_fn', activation_fn, ', b_0_var', b_0_var, 'd_noise',data_noise)\n",
        "\tmetric_names= ['MSE_un','RMSE', 'NLL']\n",
        "\tprint('runs\\tensemb')\n",
        "\tprint(n_runs, '\\t', n_ensembles)\n",
        "\tprint('\\tavg\\tstd_err\\tstd_dev')\n",
        "\tfor i in range(0,len(metric_names)): \n",
        "\t\tavg = np.mean(gp_results[:,i])\n",
        "\t\tstd_dev = np.std(gp_results[:,i], ddof=1)\n",
        "\t\tstd_err = std_dev/np.sqrt(n_runs)\n",
        "\t\tprint(metric_names[i], '\\t', round(avg,3), \n",
        "\t\t\t'\\t', round(std_err,3),\n",
        "\t\t\t'\\t', round(std_dev,3))\n",
        "\n",
        "\n",
        "if is_ens_run:\n",
        "\tens_results = np.array(ens_results)\n",
        "\tprint('\\n\\n___ NN ens RESULTS ___')\n",
        "\tprint('data', data_set, ', act_fn', activation_fn, ', b_0_var', b_0_var, 'd_noise',data_noise)\n",
        "\tmetric_names= ['MSE_un','RMSE', 'NLL']\n",
        "\tprint('runs\\tensemb')\n",
        "\tprint(n_runs, '\\t', n_ensembles)\n",
        "\tprint('\\tavg\\tstd_err\\tstd_dev')\n",
        "\tfor i in range(0,len(metric_names)): \n",
        "\t\tavg = np.mean(ens_results[:,i])\n",
        "\t\tstd_dev = np.std(ens_results[:,i], ddof=1)\n",
        "\t\tstd_err = std_dev/np.sqrt(n_runs)\n",
        "\t\tprint(metric_names[i], '\\t', round(avg,3), \n",
        "\t\t\t'\\t', round(std_err,3),\n",
        "\t\t\t'\\t', round(std_dev,3))\n",
        "\n",
        "\n",
        "if is_gp_run and is_ens_run:\n",
        "\tprint('\\n\\nKL avg:',np.round(np.mean(run_kls),4), ', std err:',np.round(np.std(run_kls,ddof=1)/np.sqrt(n_runs),5))\n",
        "\n",
        "\n",
        "if is_single_run:\n",
        "\tsingle_results = np.array(single_results)\n",
        "\tprint('\\n\\n___ single NN RESULTS ___')\n",
        "\tprint('data', data_set, ', act_fn', activation_fn, ', b_0_var', b_0_var, 'd_noise',data_noise)\n",
        "\tmetric_names= ['MSE_un','RMSE', 'NLL']\n",
        "\tprint('runs\\tensemb')\n",
        "\tprint(n_runs, '\\t', n_ensembles)\n",
        "\tprint('\\tavg\\tstd_err\\tstd_dev')\n",
        "\tfor i in range(0,len(metric_names)): \n",
        "\t\tavg = np.mean(single_results[:,i])\n",
        "\t\tstd_dev = np.std(single_results[:,i], ddof=1)\n",
        "\t\tstd_err = std_dev/np.sqrt(n_runs)\n",
        "\t\tprint(metric_names[i], '\\t', round(avg,3), \n",
        "\t\t\t'\\t', round(std_err,3),\n",
        "\t\t\t'\\t', round(std_dev,3))\n",
        "\n",
        "if is_mc_run:\n",
        "\tmc_results = np.array(mc_results)\n",
        "\tprint('\\n\\n___ mc drop out NN RESULTS ___')\n",
        "\tprint('data', data_set, ', act_fn', activation_fn, ', b_0_var', b_0_var, 'd_noise',data_noise)\n",
        "\tmetric_names= ['MSE_un','RMSE', 'NLL']\n",
        "\tprint('runs\\tensemb')\n",
        "\tprint(n_runs, '\\t', n_ensembles)\n",
        "\tprint('\\tavg\\tstd_err\\tstd_dev')\n",
        "\tfor i in range(0,len(metric_names)): \n",
        "\t\tavg = np.mean(mc_results[:,i])\n",
        "\t\tstd_dev = np.std(mc_results[:,i], ddof=1)\n",
        "\t\tstd_err = std_dev/np.sqrt(n_runs)\n",
        "\t\tprint(metric_names[i], '\\t', round(avg,3), \n",
        "\t\t\t'\\t', round(std_err,3),\n",
        "\t\t\t'\\t', round(std_dev,3))\n",
        "\n",
        "if is_unconstrained_run:\n",
        "\tunc_ens_results = np.array(unc_ens_results)\n",
        "\tprint('\\n\\n___ unconstrained NN RESULTS ___')\n",
        "\tprint('data', data_set, ', act_fn', activation_fn, ', b_0_var', b_0_var, 'd_noise',data_noise)\n",
        "\tmetric_names= ['MSE_un','RMSE', 'NLL']\n",
        "\tprint('runs\\tensemb')\n",
        "\tprint(n_runs, '\\t', n_ensembles)\n",
        "\tprint('\\tavg\\tstd_err\\tstd_dev')\n",
        "\tfor i in range(0,len(metric_names)): \n",
        "\t\tavg = np.mean(unc_ens_results[:,i])\n",
        "\t\tstd_dev = np.std(unc_ens_results[:,i], ddof=1)\n",
        "\t\tstd_err = std_dev/np.sqrt(n_runs)\n",
        "\t\tprint(metric_names[i], '\\t', round(avg,3), \n",
        "\t\t\t'\\t', round(std_err,3),\n",
        "\t\t\t'\\t', round(std_dev,3))\n",
        "\n",
        "if is_sk_run:\n",
        "\tsk_results = np.array(sk_results)\n",
        "\tprint('\\n\\n___ sk learn RESULTS ___')\n",
        "\tprint('data', data_set, ', act_fn', activation_fn, ', b_0_var', b_0_var, 'd_noise',data_noise)\n",
        "\tmetric_names= ['MSE_un','RMSE', 'NLL']\n",
        "\tprint('runs\\tensemb')\n",
        "\tprint(n_runs, '\\t', n_ensembles)\n",
        "\tprint('\\tavg\\tstd_err\\tstd_dev')\n",
        "\tfor i in range(0,len(metric_names)): \n",
        "\t\tavg = np.mean(sk_results[:,i])\n",
        "\t\tstd_dev = np.std(sk_results[:,i], ddof=1)\n",
        "\t\tstd_err = std_dev/np.sqrt(n_runs)\n",
        "\t\tprint(metric_names[i], '\\t', round(avg,3), \n",
        "\t\t\t'\\t', round(std_err,3),\n",
        "\t\t\t'\\t', round(std_dev,3))\n",
        "\n",
        "\n",
        "if False:\n",
        "\tw1, b1, w2 = ens.NNs[0].get_weights(ens.sess)\n",
        "\tact_point = -b1.T/w1\n",
        "\tfig = plt.figure(figsize=(5, 4))\n",
        "\tax = fig.add_subplot(111)\n",
        "\tax.hist(act_point.ravel(),bins=100, range=(-8,8))\n",
        "\tfig.show()\n",
        "\n",
        "if False:\n",
        "\tfig = plt.figure(figsize=(5, 4))\n",
        "\tfor i in range(X_train.shape[1]):\n",
        "\t\tax = fig.add_subplot(int(X_train.shape[1]/2 +1),2,i+1)\n",
        "\t\tax.scatter(X_train[:,i],y_train)\n",
        "\tfig.show()\n"
      ],
      "metadata": {
        "id": "EXpVBnNJ36B2",
        "outputId": "a2c5a2e1-0e2e-4f04-cdd4-ede4f0e10915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "  ====== run: 0 ======\n",
            "\n",
            "\n",
            "\n",
            "total_ens_run: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0ebaef0c7301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \t\t\t\t)\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                         \u001b[0my_priors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prior_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prior_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                         \u001b[0;31m# plot priors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Bayesian_NN_Ensembles-master/regression/module_NN_ens.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train, X_val, y_val, is_print)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0my_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m#y_train.shape[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;31m# batch_size = n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m                 \u001b[0;31m# --- ensembles w proper anchoring! ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                 \u001b[0mNNs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TWTeONoW36G2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}