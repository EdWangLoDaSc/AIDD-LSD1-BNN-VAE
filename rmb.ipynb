{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6K+ZHxNDhfbbYrmcBANwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdWangLoDaSc/Dropout-as-a-Grid-Search_Representing-Model-Uncertainty-in-Deep-Learning/blob/main/rmb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNdPL9kYKwS0",
        "outputId": "22edb5f6-604b-4aa9-a56b-d1ee9d79da00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.5.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.47.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.7/dist-packages (2022.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from rdkit) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rdkit) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./content')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "IHoDJ1sqK3mQ",
        "outputId": "f9b1f98c-e422-4d98-c5c8-caf5ff60c769"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-de7df87d8825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;34m': timeout during initial read of root folder; for more info: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             'https://research.google.com/colaboratory/faq.html#drive-timeout')\n\u001b[0;32m--> 254\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from sklearn.decomposition import PCA\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torchvision.datasets import MNIST\n",
        "module_path = os.path.abspath('/content/content/MyDrive/pytorch-rbm-autoencoder-main')\n",
        "os.chdir(module_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zHcZ_q0aK3np",
        "outputId": "369b64d7-6994-472d-d1e2-6ae5ffc7968d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-80b624310fec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/content/MyDrive/pytorch-rbm-autoencoder-main'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/content/MyDrive/pytorch-rbm-autoencoder-main'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dae import DAE\n",
        "from demo_train_utils import train_rbm\n",
        "from rbm import RBM\n",
        "from utils import *\n"
      ],
      "metadata": {
        "id": "6t8oD3JkK3zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using device {DEVICE}\")\n",
        "seed_everything(42)\n",
        "\n"
      ],
      "metadata": {
        "id": "yfrHfXLiK31z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dimensions = [\n",
        "    {\n",
        "        \"hidden_dim\": 700, \n",
        "        \"num_epochs\": 100, \n",
        "        \"learning_rate\": 0.001, \n",
        "        \"display_dim1\": 28, \n",
        "        \"display_dim2\": 28, \n",
        "        \"use_gaussian\": False\n",
        "    }, \n",
        "    {\n",
        "        \"hidden_dim\": 256, \n",
        "        \"num_epochs\": 100, \n",
        "        \"learning_rate\": 0.001, \n",
        "        \"use_gaussian\": False\n",
        "    },\n",
        "    {\n",
        "        \"hidden_dim\": 128, \n",
        "        \"num_epochs\": 100, \n",
        "        \"learning_rate\": 0.001, \n",
        "        \"use_gaussian\": False\n",
        "    },\n",
        "    {\n",
        "        \"hidden_dim\": 64, \n",
        "        \"num_epochs\": 100, \n",
        "        \"learning_rate\": 0.001, \n",
        "        \"use_gaussian\": False\n",
        "    },\n",
        "    {\n",
        "        \"hidden_dim\": 32, \n",
        "        \"num_epochs\": 100, \n",
        "        \"learning_rate\": 0.001, # use much lower LR for gaussian to avoid exploding gradient\n",
        "        \"use_gaussian\": True # use a Gaussian distribution for the last hidden layer to let it take advantage of continuous values\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "xqqdQZ0YNDzS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = pd.read_csv('/content/content/MyDrive/pytorch-rbm-autoencoder-main/FP_3_512_D1.csv').values\n",
        "datasets.shape\n",
        "datasets = DataLoader(\n",
        "    TensorDataset(torch.Tensor(datasets).to(DEVICE)),\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "nR94EmW8w8Ru",
        "outputId": "e132fa35-5f03-4dc3-d4e4-7195f4fd7e7c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-a30ebd42ee83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/content/MyDrive/pytorch-rbm-autoencoder-main/FP_3_512_D1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m datasets = DataLoader(\n\u001b[1;32m      4\u001b[0m     \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/content/MyDrive/pytorch-rbm-autoencoder-main/FP_3_512_D1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_dl = datasets\n",
        "\n",
        "visible_dim = 512\n",
        "hidden_dim = None\n",
        "models = [] # trained RBM models\n",
        "for configs in hidden_dimensions:\n",
        "    \n",
        "    # parse configs\n",
        "    hidden_dim = configs[\"hidden_dim\"]\n",
        "    num_epochs = configs[\"num_epochs\"]\n",
        "    lr = configs[\"learning_rate\"]\n",
        "    use_gaussian = configs[\"use_gaussian\"]\n",
        "    \n",
        "    # train RBM\n",
        "    print(50 * '-')\n",
        "    print(f\"{visible_dim} to {hidden_dim}\")\n",
        "    model, v, v_pred = train_rbm(new_train_dl, visible_dim, hidden_dim, k=1, num_epochs=num_epochs, lr=lr, use_gaussian=use_gaussian)\n",
        "    models.append(model)\n",
        "    \n",
        "    # display sample output\n",
        "    #display_output(v, v_pred, d1, d2)\n",
        "\n",
        "    # rederive new data loader based on hidden activations of trained model\n",
        "    new_data = []\n",
        "    for data_list in new_train_dl:\n",
        "        p = model.sample_h(data_list[0])[0]\n",
        "        new_data.append(p.detach().cpu().numpy())\n",
        "    new_input = np.concatenate(new_data)\n",
        "    new_train_dl = DataLoader(\n",
        "        TensorDataset(torch.Tensor(new_input).to(DEVICE)), \n",
        "        batch_size=16, \n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # update new visible_dim for next RBM\n",
        "    visible_dim = hidden_dim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8zTYvtXwyfq",
        "outputId": "24b81e44-0fd7-4c17-c42e-4c1a95baa496"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "512 to 700\n",
            "epoch 0: 0.07056031376123428\n",
            "epoch 1: 0.05753840506076813\n",
            "epoch 2: 0.052218448370695114\n",
            "epoch 3: 0.04920882731676102\n",
            "epoch 4: 0.0472663976252079\n",
            "epoch 5: 0.04182451218366623\n",
            "epoch 6: 0.03317488357424736\n",
            "epoch 7: 0.02865113504230976\n",
            "epoch 8: 0.025878526270389557\n",
            "epoch 9: 0.024073343724012375\n",
            "epoch 10: 0.02270248904824257\n",
            "epoch 11: 0.021667564287781715\n",
            "epoch 12: 0.020888157188892365\n",
            "epoch 13: 0.020286867395043373\n",
            "epoch 14: 0.019751518964767456\n",
            "epoch 15: 0.019359983503818512\n",
            "epoch 16: 0.018938235938549042\n",
            "epoch 17: 0.018597867339849472\n",
            "epoch 18: 0.018412141129374504\n",
            "epoch 19: 0.01813599281013012\n",
            "epoch 20: 0.017971279099583626\n",
            "epoch 21: 0.017762424424290657\n",
            "epoch 22: 0.017598658800125122\n",
            "epoch 23: 0.017433203756809235\n",
            "epoch 24: 0.01733900047838688\n",
            "epoch 25: 0.01721319556236267\n",
            "epoch 26: 0.017123151570558548\n",
            "epoch 27: 0.016993381083011627\n",
            "epoch 28: 0.0169048011302948\n",
            "epoch 29: 0.01680287905037403\n",
            "epoch 30: 0.016706272959709167\n",
            "epoch 31: 0.016642190515995026\n",
            "epoch 32: 0.016551649197936058\n",
            "epoch 33: 0.016448764130473137\n",
            "epoch 34: 0.016436126083135605\n",
            "epoch 35: 0.016383284702897072\n",
            "epoch 36: 0.016337649896740913\n",
            "epoch 37: 0.016213692724704742\n",
            "epoch 38: 0.016231048852205276\n",
            "epoch 39: 0.016142698004841805\n",
            "epoch 40: 0.016103580594062805\n",
            "epoch 41: 0.01606317050755024\n",
            "epoch 42: 0.016001606360077858\n",
            "epoch 43: 0.016002746298909187\n",
            "epoch 44: 0.01591850444674492\n",
            "epoch 45: 0.01596580632030964\n",
            "epoch 46: 0.01591978408396244\n",
            "epoch 47: 0.01584428921341896\n",
            "epoch 48: 0.015840783715248108\n",
            "epoch 49: 0.01574261486530304\n",
            "epoch 50: 0.01574087142944336\n",
            "epoch 51: 0.01573367789387703\n",
            "epoch 52: 0.015743529424071312\n",
            "epoch 53: 0.015681663528084755\n",
            "epoch 54: 0.01557866856455803\n",
            "epoch 55: 0.015601083636283875\n",
            "epoch 56: 0.01566340960562229\n",
            "epoch 57: 0.015586825087666512\n",
            "epoch 58: 0.015561068430542946\n",
            "epoch 59: 0.01549487467855215\n",
            "epoch 60: 0.015524913556873798\n",
            "epoch 61: 0.015496010892093182\n",
            "epoch 62: 0.015513448044657707\n",
            "epoch 63: 0.015451761893928051\n",
            "epoch 64: 0.015423495322465897\n",
            "epoch 65: 0.01540838461369276\n",
            "epoch 66: 0.015354664996266365\n",
            "epoch 67: 0.015283284708857536\n",
            "epoch 68: 0.015403485856950283\n",
            "epoch 69: 0.015355229377746582\n",
            "epoch 70: 0.015281915664672852\n",
            "epoch 71: 0.015319601632654667\n",
            "epoch 72: 0.015271763317286968\n",
            "epoch 73: 0.01521579921245575\n",
            "epoch 74: 0.015245357528328896\n",
            "epoch 75: 0.01526536326855421\n",
            "epoch 76: 0.015168067067861557\n",
            "epoch 77: 0.015199163928627968\n",
            "epoch 78: 0.015211994759738445\n",
            "epoch 79: 0.015220988541841507\n",
            "epoch 80: 0.015149721875786781\n",
            "epoch 81: 0.01520820427685976\n",
            "epoch 82: 0.015124274417757988\n",
            "epoch 83: 0.015124942176043987\n",
            "epoch 84: 0.015151942148804665\n",
            "epoch 85: 0.015092487446963787\n",
            "epoch 86: 0.01507954578846693\n",
            "epoch 87: 0.015047576278448105\n",
            "epoch 88: 0.015032269060611725\n",
            "epoch 89: 0.015028262510895729\n",
            "epoch 90: 0.015080713666975498\n",
            "epoch 91: 0.015029328875243664\n",
            "epoch 92: 0.015037600882351398\n",
            "epoch 93: 0.015040281228721142\n",
            "epoch 94: 0.014997337013483047\n",
            "epoch 95: 0.014982433058321476\n",
            "epoch 96: 0.015048288740217686\n",
            "epoch 97: 0.015002348460257053\n",
            "epoch 98: 0.014977432787418365\n",
            "epoch 99: 0.014981984160840511\n",
            "--------------------------------------------------\n",
            "700 to 256\n",
            "epoch 0: 0.12179003655910492\n",
            "epoch 1: 0.10555019229650497\n",
            "epoch 2: 0.09614851325750351\n",
            "epoch 3: 0.09040119498968124\n",
            "epoch 4: 0.08650380373001099\n",
            "epoch 5: 0.08076898753643036\n",
            "epoch 6: 0.07450547069311142\n",
            "epoch 7: 0.07129181921482086\n",
            "epoch 8: 0.06923738121986389\n",
            "epoch 9: 0.06800108402967453\n",
            "epoch 10: 0.06692399084568024\n",
            "epoch 11: 0.06635729223489761\n",
            "epoch 12: 0.06576473265886307\n",
            "epoch 13: 0.06529804319143295\n",
            "epoch 14: 0.06485915929079056\n",
            "epoch 15: 0.0644695907831192\n",
            "epoch 16: 0.06432052701711655\n",
            "epoch 17: 0.06399496644735336\n",
            "epoch 18: 0.06382805854082108\n",
            "epoch 19: 0.06360157579183578\n",
            "epoch 20: 0.06331111490726471\n",
            "epoch 21: 0.06319228559732437\n",
            "epoch 22: 0.06296281516551971\n",
            "epoch 23: 0.06285209953784943\n",
            "epoch 24: 0.06271370500326157\n",
            "epoch 25: 0.06260082870721817\n",
            "epoch 26: 0.06244745850563049\n",
            "epoch 27: 0.06226745620369911\n",
            "epoch 28: 0.06219421699643135\n",
            "epoch 29: 0.06203804910182953\n",
            "epoch 30: 0.061892881989479065\n",
            "epoch 31: 0.06187989190220833\n",
            "epoch 32: 0.06177644804120064\n",
            "epoch 33: 0.06164006143808365\n",
            "epoch 34: 0.06152603030204773\n",
            "epoch 35: 0.061543818563222885\n",
            "epoch 36: 0.06141339987516403\n",
            "epoch 37: 0.06134573742747307\n",
            "epoch 38: 0.06124717369675636\n",
            "epoch 39: 0.06114271655678749\n",
            "epoch 40: 0.06109829992055893\n",
            "epoch 41: 0.06102427467703819\n",
            "epoch 42: 0.060907334089279175\n",
            "epoch 43: 0.06088121980428696\n",
            "epoch 44: 0.06086817383766174\n",
            "epoch 45: 0.06072099506855011\n",
            "epoch 46: 0.060632314532995224\n",
            "epoch 47: 0.060674797743558884\n",
            "epoch 48: 0.06060982868075371\n",
            "epoch 49: 0.060489337891340256\n",
            "epoch 50: 0.0603511743247509\n",
            "epoch 51: 0.06043446436524391\n",
            "epoch 52: 0.06034025177359581\n",
            "epoch 53: 0.06025075539946556\n",
            "epoch 54: 0.06014608219265938\n",
            "epoch 55: 0.06012202426791191\n",
            "epoch 56: 0.059998203068971634\n",
            "epoch 57: 0.059849150478839874\n",
            "epoch 58: 0.059859760105609894\n",
            "epoch 59: 0.05973748490214348\n",
            "epoch 60: 0.05965904891490936\n",
            "epoch 61: 0.059640347957611084\n",
            "epoch 62: 0.05958789959549904\n",
            "epoch 63: 0.05947480350732803\n",
            "epoch 64: 0.05954562500119209\n",
            "epoch 65: 0.05938391014933586\n",
            "epoch 66: 0.05934768170118332\n",
            "epoch 67: 0.059401459991931915\n",
            "epoch 68: 0.05925322696566582\n",
            "epoch 69: 0.05927293747663498\n",
            "epoch 70: 0.05922559276223183\n",
            "epoch 71: 0.05917081609368324\n",
            "epoch 72: 0.05906121805310249\n",
            "epoch 73: 0.0590805821120739\n",
            "epoch 74: 0.058942873030900955\n",
            "epoch 75: 0.05893871560692787\n",
            "epoch 76: 0.05885549262166023\n",
            "epoch 77: 0.058807939291000366\n",
            "epoch 78: 0.0588107705116272\n",
            "epoch 79: 0.05876191332936287\n",
            "epoch 80: 0.05873045697808266\n",
            "epoch 81: 0.05857870727777481\n",
            "epoch 82: 0.05860995873808861\n",
            "epoch 83: 0.05848437175154686\n",
            "epoch 84: 0.05849944055080414\n",
            "epoch 85: 0.05840755254030228\n",
            "epoch 86: 0.058266531676054\n",
            "epoch 87: 0.05835507810115814\n",
            "epoch 88: 0.058227602392435074\n",
            "epoch 89: 0.05818407982587814\n",
            "epoch 90: 0.05816909670829773\n",
            "epoch 91: 0.05821511149406433\n",
            "epoch 92: 0.058073464781045914\n",
            "epoch 93: 0.05805329233407974\n",
            "epoch 94: 0.057992517948150635\n",
            "epoch 95: 0.057900432497262955\n",
            "epoch 96: 0.05796978250145912\n",
            "epoch 97: 0.0578497014939785\n",
            "epoch 98: 0.05787569656968117\n",
            "epoch 99: 0.05787349492311478\n",
            "--------------------------------------------------\n",
            "256 to 128\n",
            "epoch 0: 0.13949233293533325\n",
            "epoch 1: 0.1285039335489273\n",
            "epoch 2: 0.11931032687425613\n",
            "epoch 3: 0.11281053721904755\n",
            "epoch 4: 0.10793720930814743\n",
            "epoch 5: 0.09990253299474716\n",
            "epoch 6: 0.09162701666355133\n",
            "epoch 7: 0.08744896203279495\n",
            "epoch 8: 0.08490122109651566\n",
            "epoch 9: 0.08322184532880783\n",
            "epoch 10: 0.08199921250343323\n",
            "epoch 11: 0.08119478821754456\n",
            "epoch 12: 0.08047425001859665\n",
            "epoch 13: 0.08011216670274734\n",
            "epoch 14: 0.07959337532520294\n",
            "epoch 15: 0.07925979048013687\n",
            "epoch 16: 0.07894552499055862\n",
            "epoch 17: 0.07871630042791367\n",
            "epoch 18: 0.07839061319828033\n",
            "epoch 19: 0.07813291251659393\n",
            "epoch 20: 0.07781992107629776\n",
            "epoch 21: 0.07781705260276794\n",
            "epoch 22: 0.07752726972103119\n",
            "epoch 23: 0.07740647345781326\n",
            "epoch 24: 0.07725691050291061\n",
            "epoch 25: 0.0771278589963913\n",
            "epoch 26: 0.0771416425704956\n",
            "epoch 27: 0.07685697078704834\n",
            "epoch 28: 0.07686518132686615\n",
            "epoch 29: 0.07676040381193161\n",
            "epoch 30: 0.07671802490949631\n",
            "epoch 31: 0.07647813111543655\n",
            "epoch 32: 0.07646161317825317\n",
            "epoch 33: 0.07629947364330292\n",
            "epoch 34: 0.07635188102722168\n",
            "epoch 35: 0.07616525143384933\n",
            "epoch 36: 0.07631175965070724\n",
            "epoch 37: 0.07610134035348892\n",
            "epoch 38: 0.07599737495183945\n",
            "epoch 39: 0.07583379000425339\n",
            "epoch 40: 0.07587678730487823\n",
            "epoch 41: 0.07571502774953842\n",
            "epoch 42: 0.075764000415802\n",
            "epoch 43: 0.07553347945213318\n",
            "epoch 44: 0.07565997540950775\n",
            "epoch 45: 0.07558459043502808\n",
            "epoch 46: 0.07534906268119812\n",
            "epoch 47: 0.0752723217010498\n",
            "epoch 48: 0.07540509849786758\n",
            "epoch 49: 0.07519695907831192\n",
            "epoch 50: 0.07525954395532608\n",
            "epoch 51: 0.07524654269218445\n",
            "epoch 52: 0.07526077330112457\n",
            "epoch 53: 0.075312040746212\n",
            "epoch 54: 0.07508852332830429\n",
            "epoch 55: 0.07514473050832748\n",
            "epoch 56: 0.0749882310628891\n",
            "epoch 57: 0.07502597570419312\n",
            "epoch 58: 0.07505843043327332\n",
            "epoch 59: 0.0749138742685318\n",
            "epoch 60: 0.0750383734703064\n",
            "epoch 61: 0.07474704831838608\n",
            "epoch 62: 0.07488536089658737\n",
            "epoch 63: 0.07461931556463242\n",
            "epoch 64: 0.07476510852575302\n",
            "epoch 65: 0.07474321871995926\n",
            "epoch 66: 0.0747104361653328\n",
            "epoch 67: 0.07466108351945877\n",
            "epoch 68: 0.07459674030542374\n",
            "epoch 69: 0.07447256147861481\n",
            "epoch 70: 0.07451663911342621\n",
            "epoch 71: 0.07449138164520264\n",
            "epoch 72: 0.07460563629865646\n",
            "epoch 73: 0.07450208067893982\n",
            "epoch 74: 0.07446883618831635\n",
            "epoch 75: 0.07431314140558243\n",
            "epoch 76: 0.07441775500774384\n",
            "epoch 77: 0.07441797107458115\n",
            "epoch 78: 0.07422802597284317\n",
            "epoch 79: 0.07428386062383652\n",
            "epoch 80: 0.07424452155828476\n",
            "epoch 81: 0.07428672164678574\n",
            "epoch 82: 0.07418131083250046\n",
            "epoch 83: 0.07414878159761429\n",
            "epoch 84: 0.07402060925960541\n",
            "epoch 85: 0.07412616163492203\n",
            "epoch 86: 0.07390551269054413\n",
            "epoch 87: 0.07404284179210663\n",
            "epoch 88: 0.07398854941129684\n",
            "epoch 89: 0.07395372539758682\n",
            "epoch 90: 0.07385751605033875\n",
            "epoch 91: 0.07386748492717743\n",
            "epoch 92: 0.07391542941331863\n",
            "epoch 93: 0.07381204515695572\n",
            "epoch 94: 0.07375605404376984\n",
            "epoch 95: 0.0735761746764183\n",
            "epoch 96: 0.0737442821264267\n",
            "epoch 97: 0.07370125502347946\n",
            "epoch 98: 0.0736144483089447\n",
            "epoch 99: 0.07357343286275864\n",
            "--------------------------------------------------\n",
            "128 to 64\n",
            "epoch 0: 0.14133334159851074\n",
            "epoch 1: 0.13342514634132385\n",
            "epoch 2: 0.12427014857530594\n",
            "epoch 3: 0.1170991063117981\n",
            "epoch 4: 0.11187466979026794\n",
            "epoch 5: 0.10246488451957703\n",
            "epoch 6: 0.09372752159833908\n",
            "epoch 7: 0.08953813463449478\n",
            "epoch 8: 0.08707711845636368\n",
            "epoch 9: 0.08529143035411835\n",
            "epoch 10: 0.08442853391170502\n",
            "epoch 11: 0.0834634080529213\n",
            "epoch 12: 0.08268865942955017\n",
            "epoch 13: 0.08247647434473038\n",
            "epoch 14: 0.081988625228405\n",
            "epoch 15: 0.0815289095044136\n",
            "epoch 16: 0.08131051063537598\n",
            "epoch 17: 0.08080948144197464\n",
            "epoch 18: 0.08085537701845169\n",
            "epoch 19: 0.08052137494087219\n",
            "epoch 20: 0.08017727732658386\n",
            "epoch 21: 0.08012473583221436\n",
            "epoch 22: 0.07987281680107117\n",
            "epoch 23: 0.0795375406742096\n",
            "epoch 24: 0.07927485555410385\n",
            "epoch 25: 0.07918564975261688\n",
            "epoch 26: 0.07901675254106522\n",
            "epoch 27: 0.07863803952932358\n",
            "epoch 28: 0.07857108116149902\n",
            "epoch 29: 0.07809378951787949\n",
            "epoch 30: 0.07796285301446915\n",
            "epoch 31: 0.07783250510692596\n",
            "epoch 32: 0.07749255001544952\n",
            "epoch 33: 0.0773550271987915\n",
            "epoch 34: 0.07722211629152298\n",
            "epoch 35: 0.07728791981935501\n",
            "epoch 36: 0.07675810158252716\n",
            "epoch 37: 0.0767098069190979\n",
            "epoch 38: 0.07642403244972229\n",
            "epoch 39: 0.07616892457008362\n",
            "epoch 40: 0.07596089690923691\n",
            "epoch 41: 0.07569792121648788\n",
            "epoch 42: 0.0755794495344162\n",
            "epoch 43: 0.07544835656881332\n",
            "epoch 44: 0.07500617951154709\n",
            "epoch 45: 0.07475577294826508\n",
            "epoch 46: 0.07463536411523819\n",
            "epoch 47: 0.07451688498258591\n",
            "epoch 48: 0.07442072033882141\n",
            "epoch 49: 0.07419060915708542\n",
            "epoch 50: 0.07415786385536194\n",
            "epoch 51: 0.07402098923921585\n",
            "epoch 52: 0.07386580109596252\n",
            "epoch 53: 0.07373856753110886\n",
            "epoch 54: 0.07373201847076416\n",
            "epoch 55: 0.07372678816318512\n",
            "epoch 56: 0.07353418320417404\n",
            "epoch 57: 0.07349637150764465\n",
            "epoch 58: 0.07339056581258774\n",
            "epoch 59: 0.07341548800468445\n",
            "epoch 60: 0.07327771186828613\n",
            "epoch 61: 0.07320458441972733\n",
            "epoch 62: 0.07321086525917053\n",
            "epoch 63: 0.07297976315021515\n",
            "epoch 64: 0.07306475937366486\n",
            "epoch 65: 0.07307847589254379\n",
            "epoch 66: 0.07289263606071472\n",
            "epoch 67: 0.07278616726398468\n",
            "epoch 68: 0.07275331765413284\n",
            "epoch 69: 0.07283543050289154\n",
            "epoch 70: 0.0729113295674324\n",
            "epoch 71: 0.07278373837471008\n",
            "epoch 72: 0.07266221195459366\n",
            "epoch 73: 0.07259528338909149\n",
            "epoch 74: 0.07273653149604797\n",
            "epoch 75: 0.07261412590742111\n",
            "epoch 76: 0.07239037752151489\n",
            "epoch 77: 0.07256829738616943\n",
            "epoch 78: 0.0723998099565506\n",
            "epoch 79: 0.0723840519785881\n",
            "epoch 80: 0.0721520259976387\n",
            "epoch 81: 0.07215213030576706\n",
            "epoch 82: 0.07224231958389282\n",
            "epoch 83: 0.07226059585809708\n",
            "epoch 84: 0.07197189331054688\n",
            "epoch 85: 0.07190690189599991\n",
            "epoch 86: 0.07179152965545654\n",
            "epoch 87: 0.07217220216989517\n",
            "epoch 88: 0.07182611525058746\n",
            "epoch 89: 0.07172683626413345\n",
            "epoch 90: 0.07179775834083557\n",
            "epoch 91: 0.07186689227819443\n",
            "epoch 92: 0.07160969823598862\n",
            "epoch 93: 0.07168560475111008\n",
            "epoch 94: 0.07157216221094131\n",
            "epoch 95: 0.07147236168384552\n",
            "epoch 96: 0.07131572812795639\n",
            "epoch 97: 0.0714079812169075\n",
            "epoch 98: 0.07131683826446533\n",
            "epoch 99: 0.07126642763614655\n",
            "--------------------------------------------------\n",
            "64 to 32\n",
            "epoch 0: 0.1406702697277069\n",
            "epoch 1: 0.13327619433403015\n",
            "epoch 2: 0.12921024858951569\n",
            "epoch 3: 0.12597189843654633\n",
            "epoch 4: 0.1230931282043457\n",
            "epoch 5: 0.11457725614309311\n",
            "epoch 6: 0.10231486707925797\n",
            "epoch 7: 0.09389355033636093\n",
            "epoch 8: 0.08857671916484833\n",
            "epoch 9: 0.08432989567518234\n",
            "epoch 10: 0.0814623087644577\n",
            "epoch 11: 0.07894027978181839\n",
            "epoch 12: 0.07741538435220718\n",
            "epoch 13: 0.07554777711629868\n",
            "epoch 14: 0.07456061989068985\n",
            "epoch 15: 0.07360117882490158\n",
            "epoch 16: 0.07252861559391022\n",
            "epoch 17: 0.07205841690301895\n",
            "epoch 18: 0.07169441133737564\n",
            "epoch 19: 0.07146237790584564\n",
            "epoch 20: 0.07103762775659561\n",
            "epoch 21: 0.07081785798072815\n",
            "epoch 22: 0.0703326165676117\n",
            "epoch 23: 0.07033199071884155\n",
            "epoch 24: 0.07022260129451752\n",
            "epoch 25: 0.06989234685897827\n",
            "epoch 26: 0.06950768828392029\n",
            "epoch 27: 0.06970887631177902\n",
            "epoch 28: 0.06956797093153\n",
            "epoch 29: 0.06927534937858582\n",
            "epoch 30: 0.06915027648210526\n",
            "epoch 31: 0.06931887567043304\n",
            "epoch 32: 0.06913124769926071\n",
            "epoch 33: 0.06893676519393921\n",
            "epoch 34: 0.06895627081394196\n",
            "epoch 35: 0.06870783865451813\n",
            "epoch 36: 0.06887790560722351\n",
            "epoch 37: 0.068868488073349\n",
            "epoch 38: 0.06864496320486069\n",
            "epoch 39: 0.06874046474695206\n",
            "epoch 40: 0.06858713924884796\n",
            "epoch 41: 0.06878629326820374\n",
            "epoch 42: 0.06865821778774261\n",
            "epoch 43: 0.06862597167491913\n",
            "epoch 44: 0.06860169023275375\n",
            "epoch 45: 0.06893553584814072\n",
            "epoch 46: 0.06878471374511719\n",
            "epoch 47: 0.06839693337678909\n",
            "epoch 48: 0.0686238631606102\n",
            "epoch 49: 0.06857505440711975\n",
            "epoch 50: 0.06850230693817139\n",
            "epoch 51: 0.06863301992416382\n",
            "epoch 52: 0.06867074966430664\n",
            "epoch 53: 0.0685524120926857\n",
            "epoch 54: 0.06848203390836716\n",
            "epoch 55: 0.06858055293560028\n",
            "epoch 56: 0.0685538500547409\n",
            "epoch 57: 0.06825291365385056\n",
            "epoch 58: 0.06879796087741852\n",
            "epoch 59: 0.06854364275932312\n",
            "epoch 60: 0.06829480826854706\n",
            "epoch 61: 0.06823495775461197\n",
            "epoch 62: 0.0684453547000885\n",
            "epoch 63: 0.06862884014844894\n",
            "epoch 64: 0.06855478137731552\n",
            "epoch 65: 0.06845002621412277\n",
            "epoch 66: 0.06824972480535507\n",
            "epoch 67: 0.06830620020627975\n",
            "epoch 68: 0.06844495981931686\n",
            "epoch 69: 0.06808754056692123\n",
            "epoch 70: 0.0681639164686203\n",
            "epoch 71: 0.06855050474405289\n",
            "epoch 72: 0.06815291196107864\n",
            "epoch 73: 0.0684230774641037\n",
            "epoch 74: 0.06826281547546387\n",
            "epoch 75: 0.06822588294744492\n",
            "epoch 76: 0.0684204027056694\n",
            "epoch 77: 0.06821675598621368\n",
            "epoch 78: 0.06828826665878296\n",
            "epoch 79: 0.06837796419858932\n",
            "epoch 80: 0.06826092302799225\n",
            "epoch 81: 0.0682099387049675\n",
            "epoch 82: 0.0683361068367958\n",
            "epoch 83: 0.06828190386295319\n",
            "epoch 84: 0.06825464963912964\n",
            "epoch 85: 0.06827572733163834\n",
            "epoch 86: 0.06822536140680313\n",
            "epoch 87: 0.06832832843065262\n",
            "epoch 88: 0.068273164331913\n",
            "epoch 89: 0.06837962567806244\n",
            "epoch 90: 0.06831131130456924\n",
            "epoch 91: 0.0679812878370285\n",
            "epoch 92: 0.06847180426120758\n",
            "epoch 93: 0.0680910125374794\n",
            "epoch 94: 0.06829268485307693\n",
            "epoch 95: 0.06829504668712616\n",
            "epoch 96: 0.06806520372629166\n",
            "epoch 97: 0.06836164742708206\n",
            "epoch 98: 0.06825155764818192\n",
            "epoch 99: 0.06826713681221008\n"
          ]
        }
      ]
    }
  ]
}