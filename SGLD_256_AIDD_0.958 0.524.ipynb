{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdWangLoDaSc/Dropout-as-a-Grid-Search_Representing-Model-Uncertainty-in-Deep-Learning/blob/main/SGLD_256_AIDD_0.958%200.524.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YneWjImThPub",
        "outputId": "1beafc00-9d37-4f44-ea89-12bec0d8d6d3"
      },
      "id": "YneWjImThPub",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "94c44267",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94c44267",
        "outputId": "f2f08acf-8e1c-44c9-d0aa-3d9782e0bb9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: torch-0.4.1-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GPy\n",
            "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
            "\u001b[K     |████████████████████████████████| 959 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from GPy) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from GPy) (1.15.0)\n",
            "Collecting paramz>=0.9.0\n",
            "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from GPy) (0.29.30)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from GPy) (1.7.3)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.7/dist-packages (from paramz>=0.9.0->GPy) (4.4.2)\n",
            "Building wheels for collected packages: GPy, paramz\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.10.0-cp37-cp37m-linux_x86_64.whl size=2565116 sha256=d8158aaef00232b1d707dffa139ea27ad077583e36dd39ccc4c6212fc6c7991a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/18/28/dd1ce0192a81b71a3b086fd952511d088b21e8359ea496860a\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102566 sha256=8bfe6e11c8968bc799cfe11c999d8abdf585e70ef100af62808369165caba1b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/95/f5/ce28482da28162e6028c4b3a32c41d147395825b3cd62bc810\n",
            "Successfully built GPy paramz\n",
            "Installing collected packages: paramz, GPy\n",
            "Successfully installed GPy-1.10.0 paramz-0.9.5\n"
          ]
        }
      ],
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip3 install GPy\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import GPy\n",
        "import time\n",
        "import copy\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.sgd import SGD\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm import tqdm, trange\n",
        "from google.colab import files\n",
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XkP-XKI5mOhv"
      },
      "id": "XkP-XKI5mOhv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7f11def2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7f11def2",
        "outputId": "9fadaae9-625c-469f-cffa-1979ff53c5ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "torch.cuda.device(0)\n",
        "torch.cuda.get_device_name(torch.cuda.current_device())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "613d2696",
      "metadata": {
        "id": "613d2696"
      },
      "outputs": [],
      "source": [
        "def to_variable(var=(), cuda=True, volatile=False):\n",
        "    out = []\n",
        "    for v in var:\n",
        "        \n",
        "        if isinstance(v, np.ndarray):\n",
        "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
        "\n",
        "        if not v.is_cuda and cuda:\n",
        "            v = v.cuda()\n",
        "\n",
        "        if not isinstance(v, Variable):\n",
        "            v = Variable(v, volatile=volatile)\n",
        "\n",
        "        out.append(v)\n",
        "    return out\n",
        "class Langevin_SGD(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr, weight_decay=0, nesterov=False):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "\n",
        "        defaults = dict(lr=lr, weight_decay=weight_decay)\n",
        "        \n",
        "        super(Langevin_SGD, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(SGD, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('nesterov', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            \n",
        "            weight_decay = group['weight_decay']\n",
        "            \n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                d_p = p.grad.data\n",
        "                \n",
        "                if len(p.shape) == 1 and p.shape[0] == 1:\n",
        "                    p.data.add_(-group['lr'], d_p)\n",
        "                    \n",
        "                else:\n",
        "                    if weight_decay != 0:\n",
        "                        d_p.add_(weight_decay, p.data)\n",
        "\n",
        "                    unit_noise = Variable(p.data.new(p.size()).normal_())\n",
        "\n",
        "                    p.data.add_(-group['lr'], 0.5*d_p + unit_noise/group['lr']**0.5)\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b95dd8e4",
      "metadata": {
        "id": "b95dd8e4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def log_gaussian_loss(output, target, sigma, no_dim):\n",
        "    exponent = -0.5*(target - output)**2/sigma**2\n",
        "    log_coeff = -no_dim*torch.log(sigma)\n",
        "    \n",
        "    return - (log_coeff + exponent).sum()\n",
        "\n",
        "\n",
        "def get_kl_divergence(weights, prior, varpost):\n",
        "    prior_loglik = prior.loglik(weights)\n",
        "    \n",
        "    varpost_loglik = varpost.loglik(weights)\n",
        "    varpost_lik = varpost_loglik.exp()\n",
        "    \n",
        "    return (varpost_lik*(varpost_loglik - prior_loglik)).sum()\n",
        "\n",
        "\n",
        "class gaussian:\n",
        "    def __init__(self, mu, sigma):\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def loglik(self, weights):\n",
        "        exponent = -0.5*(weights - self.mu)**2/self.sigma**2\n",
        "        log_coeff = -0.5*(np.log(2*np.pi) + 2*np.log(self.sigma))\n",
        "        \n",
        "        return (exponent + log_coeff).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6a5ba769",
      "metadata": {
        "id": "6a5ba769"
      },
      "outputs": [],
      "source": [
        "class Langevin_Layer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Langevin_Layer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.weights = nn.Parameter(torch.Tensor(self.input_dim, self.output_dim).uniform_(-0.01, 0.01))\n",
        "        self.biases = nn.Parameter(torch.Tensor(self.output_dim).uniform_(-0.01, 0.01))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        return torch.mm(x, self.weights) + self.biases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dc555aa8",
      "metadata": {
        "id": "dc555aa8"
      },
      "outputs": [],
      "source": [
        "class Langevin_Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, num_units):\n",
        "        super(Langevin_Model, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        # network with two hidden and one output layer\n",
        "        self.layer1 = Langevin_Layer(input_dim, num_units)\n",
        "        self.layer2 = Langevin_Layer(num_units, 2*output_dim)\n",
        "        \n",
        "        # activation to be used between hidden layers\n",
        "        self.activation = nn.ReLU(inplace = True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.view(-1, self.input_dim)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.activation(x)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "class Langevin_Wrapper:\n",
        "    def __init__(self, network, learn_rate, batch_size, no_batches, weight_decay):\n",
        "        \n",
        "        self.learn_rate = learn_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.no_batches = no_batches\n",
        "        \n",
        "        self.network = network\n",
        "        self.network.cuda()\n",
        "        \n",
        "        self.optimizer = Langevin_SGD(self.network.parameters(), lr=self.learn_rate, weight_decay=weight_decay)\n",
        "        self.loss_func = log_gaussian_loss\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        x, y = to_variable(var=(x, y), cuda=True)\n",
        "        \n",
        "        # reset gradient and total loss\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        output = self.network(x)\n",
        "        loss = self.loss_func(output[:, :1], y, output[:, 1:].exp(), 1)\n",
        "        \n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    \n",
        "    def test_loss(self, x, y):\n",
        "        x, y = to_variable(var=(x, y), cuda=True)\n",
        "        \n",
        "        output = self.network(x)\n",
        "        loss = self.loss_func(output[:, :1], y, output[:, 1:].exp(), 1)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "24ee5406",
      "metadata": {
        "id": "24ee5406"
      },
      "outputs": [],
      "source": [
        "def eval_ensemble(x, y, ensemble):\n",
        "    \n",
        "    x, y = to_variable(var=(x, y), cuda=True)\n",
        "        \n",
        "    means, stds = [], []\n",
        "    for net in ensemble:\n",
        "        output = net(x)\n",
        "        means.append(output[:, :1, None])\n",
        "        stds.append(output[:, 1:, None].exp())\n",
        "            \n",
        "    means, stds = torch.cat(means, 2), torch.cat(stds, 2)\n",
        "    mean = means.mean(dim=2)\n",
        "    std = (means.var(dim=2) + stds.mean(dim=2)**2)**0.5\n",
        "    loss = log_gaussian_loss(mean, y, std, 1)/len(x)\n",
        "    \n",
        "    rmse = ((mean - y)**2).mean()**0.5\n",
        "\n",
        "    return loss, rmse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "189bc6ae",
      "metadata": {
        "id": "189bc6ae"
      },
      "outputs": [],
      "source": [
        "class Langevin_Model_UCI(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, num_units):\n",
        "        super(Langevin_Model_UCI, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        # network with two hidden and one output layer\n",
        "        self.layer1 = Langevin_Layer(input_dim, num_units)\n",
        "        self.layer2 = Langevin_Layer(num_units, num_units)\n",
        "        self.layer3 = Langevin_Layer(num_units, 2*output_dim)\n",
        "        \n",
        "        # activation to be used between hidden layers\n",
        "        self.activation = nn.ReLU(inplace = True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.view(-1, self.input_dim)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.activation(x)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        x = self.activation(x)\n",
        "        \n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "def train_mc_dropout(data, n_splits, burn_in, mix_time, num_nets, num_units, learn_rate, weight_decay, log_every):\n",
        "    \n",
        "    kf = KFold(n_splits=n_splits)\n",
        "    in_dim = data.shape[1] - 1\n",
        "    train_logliks, test_logliks = [], []\n",
        "    train_rmses, test_rmses = [], []\n",
        "\n",
        "    for j, idx in enumerate(kf.split(data)):\n",
        "        print('FOLD %d:' % j)\n",
        "        train_index, test_index = idx\n",
        "\n",
        "        x_train, y_train = data[train_index, :in_dim], data[train_index, in_dim:]\n",
        "        x_test, y_test = data[test_index, :in_dim], data[test_index, in_dim:]\n",
        "\n",
        "        x_means, x_stds = x_train.mean(axis = 0), x_train.var(axis = 0)**0.5\n",
        "        y_means, y_stds = y_train.mean(axis = 0), y_train.var(axis = 0)**0.5\n",
        "\n",
        "        #x_train = (x_train - x_means)/x_stds\n",
        "        #y_train = (y_train - y_means)/y_stds\n",
        "\n",
        "        #x_test = (x_test - x_means)/x_stds\n",
        "        #y_test = (y_test - y_means)/y_stds\n",
        "\n",
        "        net = Langevin_Wrapper(network=Langevin_Model_UCI(input_dim=in_dim, output_dim=1, num_units=num_units),\n",
        "                               learn_rate=learn_rate, batch_size=batch_size, no_batches=1, weight_decay=weight_decay)\n",
        "\n",
        "        nets, losses = [], []\n",
        "        num_epochs = burn_in + mix_time*num_nets + 1\n",
        "        fit_loss_train = np.zeros(num_epochs)\n",
        "\n",
        "        for i in range(num_epochs):\n",
        "            loss = net.fit(x_train, y_train)\n",
        "\n",
        "            if i % mix_time == 0 and i > burn_in:\n",
        "                nets.append(copy.deepcopy(net.network))\n",
        "                \n",
        "            if i % log_every == 0 or i == num_epochs - 1:\n",
        "                test_loss = net.test_loss(x_test, y_test).cpu().data.numpy()\n",
        "\n",
        "                if len(nets) > 0: ensemble_loss, rmse = eval_ensemble(x_test, y_test, nets)\n",
        "                else: ensemble_loss, rmse = float('nan'), float('nan')\n",
        "\n",
        "                print('Epoch: %4d, Train loss: %6.3f Test loss: %6.3f Ensemble loss: %6.3f RMSE: %.3f Num. networks: %2d' %\n",
        "                      (i, loss.cpu().data.numpy()/len(x_train), test_loss/len(x_test), ensemble_loss, rmse*y_stds[0], len(nets)))\n",
        "\n",
        "\n",
        "        train_loss, train_rmse = eval_ensemble(x_train, y_train, nets)\n",
        "        test_loss, test_rmse = eval_ensemble(x_test, y_test, nets)\n",
        "\n",
        "        train_logliks.append(-(train_loss.cpu().data.numpy() + np.log(y_stds)[0]))\n",
        "        test_logliks.append(-(test_loss.cpu().data.numpy() + np.log(y_stds)[0]))\n",
        "\n",
        "        train_rmses.append(y_stds[0]*train_rmse.cpu().data.numpy())\n",
        "        test_rmses.append(y_stds[0]*test_rmse.cpu().data.numpy())\n",
        "\n",
        "\n",
        "    print('Train log. lik. = %7.3f +/- %6.3f' % (np.array(train_logliks).mean(), np.array(train_logliks).var()**0.5))\n",
        "    print('Test  log. lik. = %7.3f +/- %6.3f' % (np.array(test_logliks).mean(), np.array(test_logliks).var()**0.5))\n",
        "    print('Train RMSE      = %7.3f +/- %6.3f' % (np.array(train_rmses).mean(), np.array(train_rmses).var()**0.5))\n",
        "    print('Test  RMSE      = %7.3f +/- %6.3f' % (np.array(test_rmses).mean(), np.array(test_rmses).var()**0.5))\n",
        "    \n",
        "    return nets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3b9afbcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b9afbcd",
        "outputId": "af0bc06a-6fc3-453a-e4c0-e8ba375c2fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: UserWarning:This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 6250, Train loss: -0.149 Test loss:  4.390 Ensemble loss:  0.565 RMSE: 1.192 Num. networks: 19\n",
            "Epoch: 6260, Train loss: -0.201 Test loss:  5.585 Ensemble loss:  0.565 RMSE: 1.192 Num. networks: 19\n",
            "Epoch: 6270, Train loss: -0.199 Test loss:  5.921 Ensemble loss:  0.565 RMSE: 1.192 Num. networks: 19\n",
            "Epoch: 6280, Train loss:  0.239 Test loss:  2.432 Ensemble loss:  0.565 RMSE: 1.192 Num. networks: 19\n",
            "Epoch: 6290, Train loss: -0.166 Test loss:  4.790 Ensemble loss:  0.565 RMSE: 1.192 Num. networks: 19\n",
            "Epoch: 6300, Train loss: -0.165 Test loss:  4.918 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6310, Train loss:  0.340 Test loss:  2.614 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6320, Train loss: -0.050 Test loss:  6.821 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6330, Train loss: -0.237 Test loss:  7.173 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6340, Train loss: -0.217 Test loss:  5.695 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6350, Train loss: -0.027 Test loss:  4.439 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6360, Train loss: -0.232 Test loss:  7.363 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6370, Train loss: -0.212 Test loss:  8.232 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6380, Train loss:  0.059 Test loss:  4.034 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6390, Train loss: -0.180 Test loss:  7.567 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6400, Train loss: -0.242 Test loss: 17.636 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6410, Train loss: -0.214 Test loss: 11.090 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6420, Train loss: -0.213 Test loss:  8.755 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6430, Train loss: -0.246 Test loss: 11.638 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6440, Train loss: -0.083 Test loss:  5.691 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6450, Train loss: -0.078 Test loss:  5.352 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6460, Train loss: -0.154 Test loss:  7.257 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6470, Train loss: -0.199 Test loss:  8.390 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6480, Train loss: -0.167 Test loss:  7.241 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6490, Train loss: -0.111 Test loss:  5.216 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6500, Train loss:  0.091 Test loss:  3.172 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6510, Train loss: -0.225 Test loss:  6.768 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6520, Train loss: -0.226 Test loss:  7.246 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6530, Train loss: -0.109 Test loss:  4.537 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6540, Train loss:  0.163 Test loss:  2.285 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6550, Train loss: -0.107 Test loss:  4.495 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6560, Train loss: -0.179 Test loss:  4.786 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6570, Train loss: -0.045 Test loss:  2.707 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6580, Train loss:  0.014 Test loss:  3.391 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6590, Train loss: -0.082 Test loss:  3.643 Ensemble loss:  0.571 RMSE: 1.197 Num. networks: 20\n",
            "Epoch: 6600, Train loss: -0.149 Test loss:  3.825 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6610, Train loss: -0.204 Test loss:  5.177 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6620, Train loss:  0.061 Test loss:  4.196 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6630, Train loss: -0.206 Test loss:  7.680 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6640, Train loss: -0.191 Test loss:  7.592 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6650, Train loss: -0.143 Test loss:  7.598 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6660, Train loss: -0.065 Test loss:  5.484 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6670, Train loss: -0.121 Test loss:  6.395 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6680, Train loss: -0.219 Test loss: 11.057 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6690, Train loss: -0.195 Test loss:  9.040 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6700, Train loss: -0.200 Test loss:  8.289 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6710, Train loss: -0.202 Test loss: 10.483 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6720, Train loss: -0.135 Test loss: 13.628 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6730, Train loss: -0.179 Test loss:  8.988 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6740, Train loss:  0.058 Test loss:  7.755 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6750, Train loss: -0.232 Test loss:  7.557 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6760, Train loss: -0.179 Test loss: 10.979 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6770, Train loss:  0.128 Test loss:  7.513 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6780, Train loss: -0.179 Test loss:  8.276 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6790, Train loss: -0.242 Test loss: 10.410 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6800, Train loss:  0.372 Test loss:  3.781 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6810, Train loss:  0.104 Test loss:  3.125 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6820, Train loss: -0.201 Test loss:  4.404 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6830, Train loss: -0.191 Test loss:  6.487 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6840, Train loss:  0.126 Test loss:  9.347 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6850, Train loss:  0.350 Test loss:  3.098 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6860, Train loss:  0.422 Test loss:  4.104 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6870, Train loss: -0.006 Test loss:  6.172 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6880, Train loss: -0.042 Test loss:  5.630 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6890, Train loss: -0.196 Test loss:  8.371 Ensemble loss:  0.574 RMSE: 1.196 Num. networks: 21\n",
            "Epoch: 6900, Train loss: -0.153 Test loss:  8.352 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6910, Train loss: -0.198 Test loss:  7.985 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6920, Train loss: -0.224 Test loss:  8.960 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6930, Train loss: -0.207 Test loss:  8.090 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6940, Train loss: -0.119 Test loss:  9.922 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6950, Train loss: -0.072 Test loss:  7.706 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6960, Train loss: -0.138 Test loss:  6.069 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6970, Train loss: -0.235 Test loss:  7.404 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6980, Train loss: -0.184 Test loss:  7.863 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 6990, Train loss: -0.057 Test loss:  6.617 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7000, Train loss: -0.104 Test loss:  7.369 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7010, Train loss: -0.085 Test loss:  7.824 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7020, Train loss: -0.201 Test loss:  8.347 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7030, Train loss: -0.212 Test loss:  8.133 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7040, Train loss: -0.205 Test loss:  8.890 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7050, Train loss:  0.125 Test loss:  5.188 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7060, Train loss:  0.189 Test loss:  5.037 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7070, Train loss: -0.182 Test loss:  6.551 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7080, Train loss: -0.239 Test loss:  7.178 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7090, Train loss: -0.229 Test loss:  7.015 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7100, Train loss: -0.210 Test loss:  7.657 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7110, Train loss: -0.157 Test loss:  6.170 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7120, Train loss: -0.141 Test loss:  5.709 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7130, Train loss: -0.185 Test loss:  6.436 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7140, Train loss: -0.179 Test loss:  7.391 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7150, Train loss: -0.218 Test loss:  7.683 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7160, Train loss: -0.171 Test loss:  6.366 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7170, Train loss:  0.259 Test loss:  4.415 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7180, Train loss: -0.232 Test loss: 11.145 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7190, Train loss: -0.176 Test loss:  6.774 Ensemble loss:  0.581 RMSE: 1.201 Num. networks: 22\n",
            "Epoch: 7200, Train loss: -0.194 Test loss:  8.027 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7210, Train loss: -0.225 Test loss:  6.427 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7220, Train loss: -0.210 Test loss:  5.011 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7230, Train loss: -0.230 Test loss:  5.280 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7240, Train loss:  0.029 Test loss:  3.427 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7250, Train loss: -0.176 Test loss:  4.818 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7260, Train loss: -0.223 Test loss:  4.140 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7270, Train loss: -0.091 Test loss:  3.532 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7280, Train loss:  0.044 Test loss:  2.417 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7290, Train loss: -0.113 Test loss:  2.826 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7300, Train loss:  0.176 Test loss:  1.724 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7310, Train loss: -0.038 Test loss:  3.027 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7320, Train loss: -0.153 Test loss:  2.372 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7330, Train loss: -0.170 Test loss:  2.853 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7340, Train loss: -0.097 Test loss:  3.400 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7350, Train loss:  0.100 Test loss:  2.139 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7360, Train loss: -0.004 Test loss:  2.577 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7370, Train loss: -0.149 Test loss:  2.759 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7380, Train loss: -0.178 Test loss:  3.178 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7390, Train loss: -0.226 Test loss:  4.531 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7400, Train loss: -0.200 Test loss:  4.103 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7410, Train loss: -0.176 Test loss:  3.422 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7420, Train loss: -0.039 Test loss:  2.380 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7430, Train loss: -0.186 Test loss:  3.750 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7440, Train loss: -0.095 Test loss:  2.937 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7450, Train loss: -0.042 Test loss:  2.745 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7460, Train loss: -0.197 Test loss:  4.482 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7470, Train loss: -0.116 Test loss:  4.143 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7480, Train loss:  0.239 Test loss:  2.312 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7490, Train loss: -0.215 Test loss:  5.824 Ensemble loss:  0.590 RMSE: 1.206 Num. networks: 23\n",
            "Epoch: 7500, Train loss: -0.210 Test loss:  5.161 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7510, Train loss: -0.188 Test loss:  4.802 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7520, Train loss: -0.190 Test loss:  5.639 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7530, Train loss: -0.120 Test loss:  4.488 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7540, Train loss:  0.046 Test loss:  2.632 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7550, Train loss: -0.050 Test loss:  3.140 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7560, Train loss: -0.134 Test loss:  3.713 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7570, Train loss: -0.147 Test loss:  4.552 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7580, Train loss:  0.154 Test loss:  2.342 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7590, Train loss:  0.173 Test loss:  2.052 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7600, Train loss:  0.438 Test loss:  1.510 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7610, Train loss: -0.185 Test loss:  4.112 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7620, Train loss:  0.063 Test loss:  2.646 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7630, Train loss: -0.165 Test loss:  5.096 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7640, Train loss:  0.542 Test loss:  2.339 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7650, Train loss:  0.125 Test loss:  2.798 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7660, Train loss: -0.180 Test loss:  5.003 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7670, Train loss: -0.203 Test loss:  6.507 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7680, Train loss:  0.022 Test loss:  3.598 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7690, Train loss:  0.277 Test loss:  3.043 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7700, Train loss:  0.007 Test loss:  3.020 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7710, Train loss: -0.001 Test loss:  3.266 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7720, Train loss:  0.138 Test loss:  2.447 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7730, Train loss:  0.329 Test loss:  1.772 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7740, Train loss: -0.167 Test loss:  3.802 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7750, Train loss:  0.001 Test loss:  2.605 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7760, Train loss: -0.098 Test loss:  2.758 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7770, Train loss: -0.128 Test loss:  2.868 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7780, Train loss:  0.010 Test loss:  2.191 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7790, Train loss: -0.061 Test loss:  2.690 Ensemble loss:  0.601 RMSE: 1.211 Num. networks: 24\n",
            "Epoch: 7800, Train loss:  0.070 Test loss:  2.222 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7810, Train loss: -0.197 Test loss:  4.597 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7820, Train loss:  0.168 Test loss:  2.119 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7830, Train loss: -0.221 Test loss:  4.671 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7840, Train loss:  0.029 Test loss:  2.817 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7850, Train loss: -0.181 Test loss:  3.275 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7860, Train loss: -0.222 Test loss:  4.258 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7870, Train loss: -0.197 Test loss:  4.953 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7880, Train loss: -0.208 Test loss:  4.818 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7890, Train loss: -0.107 Test loss:  7.035 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7900, Train loss:  0.094 Test loss:  5.083 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7910, Train loss: -0.129 Test loss:  6.920 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7920, Train loss: -0.073 Test loss:  4.647 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7930, Train loss: -0.230 Test loss:  4.969 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7940, Train loss:  0.162 Test loss:  5.681 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7950, Train loss:  0.160 Test loss:  6.544 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7960, Train loss: -0.069 Test loss:  4.421 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7970, Train loss:  0.208 Test loss:  2.527 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7980, Train loss: -0.177 Test loss:  6.199 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 7990, Train loss: -0.252 Test loss:  8.248 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8000, Train loss: -0.222 Test loss:  7.639 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8010, Train loss:  0.039 Test loss:  3.157 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8020, Train loss:  0.109 Test loss:  2.776 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8030, Train loss: -0.162 Test loss:  3.801 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8040, Train loss:  0.295 Test loss:  2.386 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8050, Train loss: -0.083 Test loss:  4.976 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8060, Train loss:  0.192 Test loss:  3.703 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8070, Train loss: -0.195 Test loss:  7.928 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8080, Train loss: -0.188 Test loss:  7.978 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8090, Train loss: -0.162 Test loss:  8.532 Ensemble loss:  0.599 RMSE: 1.208 Num. networks: 25\n",
            "Epoch: 8100, Train loss: -0.078 Test loss:  8.513 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8110, Train loss: -0.139 Test loss:  7.420 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8120, Train loss: -0.071 Test loss:  7.888 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8130, Train loss:  0.065 Test loss:  5.027 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8140, Train loss: -0.185 Test loss:  9.440 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8150, Train loss: -0.149 Test loss:  6.659 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8160, Train loss: -0.174 Test loss:  8.376 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8170, Train loss: -0.139 Test loss: 12.292 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8180, Train loss: -0.028 Test loss:  9.536 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8190, Train loss:  0.063 Test loss:  7.814 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8200, Train loss:  0.019 Test loss:  5.685 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8210, Train loss: -0.133 Test loss:  5.474 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8220, Train loss:  0.060 Test loss:  3.590 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8230, Train loss:  0.090 Test loss:  8.318 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8240, Train loss: -0.196 Test loss: 12.351 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8250, Train loss: -0.162 Test loss:  9.129 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8260, Train loss: -0.201 Test loss: 10.785 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8270, Train loss: -0.198 Test loss: 13.067 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8280, Train loss:  0.097 Test loss:  6.778 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8290, Train loss: -0.042 Test loss:  7.164 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8300, Train loss:  0.225 Test loss:  3.162 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8310, Train loss: -0.198 Test loss:  8.573 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8320, Train loss: -0.183 Test loss:  5.965 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8330, Train loss: -0.189 Test loss:  5.811 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8340, Train loss:  0.213 Test loss:  3.335 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8350, Train loss:  0.288 Test loss:  2.700 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8360, Train loss: -0.156 Test loss:  7.305 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8370, Train loss:  0.086 Test loss:  3.825 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8380, Train loss: -0.153 Test loss:  7.909 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8390, Train loss: -0.016 Test loss:  5.628 Ensemble loss:  0.613 RMSE: 1.214 Num. networks: 26\n",
            "Epoch: 8400, Train loss: -0.161 Test loss:  9.237 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8410, Train loss:  0.070 Test loss:  3.965 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8420, Train loss:  0.204 Test loss:  3.337 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8430, Train loss:  0.494 Test loss:  1.881 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8440, Train loss:  0.377 Test loss:  3.032 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8450, Train loss: -0.169 Test loss:  8.914 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8460, Train loss:  0.503 Test loss:  2.621 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8470, Train loss:  0.223 Test loss:  3.779 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8480, Train loss: -0.118 Test loss:  7.585 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8490, Train loss: -0.112 Test loss:  7.216 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8500, Train loss: -0.032 Test loss:  5.787 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8510, Train loss: -0.014 Test loss:  5.555 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8520, Train loss:  0.100 Test loss:  4.328 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8530, Train loss: -0.161 Test loss:  9.894 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8540, Train loss: -0.096 Test loss: 12.135 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8550, Train loss:  0.149 Test loss:  4.094 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8560, Train loss:  0.062 Test loss:  5.320 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8570, Train loss: -0.125 Test loss: 12.212 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8580, Train loss:  0.404 Test loss:  2.871 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8590, Train loss: -0.139 Test loss:  9.736 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8600, Train loss:  0.069 Test loss:  9.932 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8610, Train loss:  0.024 Test loss: 11.862 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8620, Train loss:  0.084 Test loss: 10.831 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8630, Train loss: -0.157 Test loss: 14.397 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8640, Train loss: -0.108 Test loss:  7.943 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8650, Train loss:  0.034 Test loss:  3.775 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8660, Train loss:  0.008 Test loss:  4.565 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8670, Train loss:  0.187 Test loss:  3.663 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8680, Train loss: -0.113 Test loss:  6.542 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8690, Train loss: -0.197 Test loss:  7.355 Ensemble loss:  0.622 RMSE: 1.218 Num. networks: 27\n",
            "Epoch: 8700, Train loss:  0.020 Test loss:  4.264 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8710, Train loss: -0.139 Test loss:  5.773 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8720, Train loss:  0.013 Test loss:  4.254 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8730, Train loss: -0.057 Test loss:  3.495 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8740, Train loss: -0.184 Test loss:  5.133 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8750, Train loss: -0.195 Test loss:  6.971 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8760, Train loss:  0.169 Test loss:  4.882 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8770, Train loss: -0.150 Test loss:  5.021 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8780, Train loss: -0.054 Test loss:  4.307 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8790, Train loss: -0.089 Test loss:  5.689 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8800, Train loss: -0.155 Test loss:  5.338 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8810, Train loss: -0.195 Test loss:  6.630 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8820, Train loss: -0.160 Test loss:  8.612 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8830, Train loss:  0.170 Test loss:  5.074 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8840, Train loss:  0.238 Test loss:  3.401 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8850, Train loss:  0.075 Test loss:  5.851 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8860, Train loss:  0.158 Test loss:  4.144 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8870, Train loss:  0.017 Test loss:  3.370 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8880, Train loss: -0.118 Test loss:  4.525 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8890, Train loss: -0.127 Test loss:  4.224 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8900, Train loss: -0.185 Test loss:  6.047 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8910, Train loss:  0.132 Test loss:  2.508 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8920, Train loss: -0.189 Test loss:  4.580 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8930, Train loss: -0.176 Test loss:  6.082 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8940, Train loss: -0.026 Test loss:  3.774 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8950, Train loss: -0.038 Test loss:  5.368 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8960, Train loss: -0.109 Test loss:  5.729 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8970, Train loss:  0.084 Test loss:  3.211 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8980, Train loss: -0.118 Test loss:  5.390 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 8990, Train loss: -0.017 Test loss:  7.809 Ensemble loss:  0.628 RMSE: 1.221 Num. networks: 28\n",
            "Epoch: 9000, Train loss: -0.204 Test loss: 15.758 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9010, Train loss: -0.184 Test loss:  7.880 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9020, Train loss: -0.179 Test loss:  7.712 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9030, Train loss:  0.218 Test loss:  4.639 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9040, Train loss: -0.111 Test loss:  6.802 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9050, Train loss:  0.004 Test loss:  3.633 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9060, Train loss: -0.053 Test loss:  5.351 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9070, Train loss:  0.078 Test loss:  6.920 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9080, Train loss:  0.028 Test loss:  7.347 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9090, Train loss: -0.017 Test loss:  4.780 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9100, Train loss: -0.145 Test loss:  5.909 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9110, Train loss: -0.016 Test loss:  4.136 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9120, Train loss: -0.149 Test loss:  4.505 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9130, Train loss:  0.097 Test loss:  3.172 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9140, Train loss:  0.208 Test loss:  2.640 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9150, Train loss:  0.022 Test loss:  6.270 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9160, Train loss:  0.032 Test loss:  4.332 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9170, Train loss:  0.013 Test loss:  6.101 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9180, Train loss: -0.096 Test loss:  7.580 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9190, Train loss:  0.165 Test loss:  4.154 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9200, Train loss:  0.027 Test loss:  4.985 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9210, Train loss: -0.076 Test loss:  4.380 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9220, Train loss: -0.029 Test loss:  3.433 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9230, Train loss: -0.144 Test loss:  6.522 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9240, Train loss: -0.131 Test loss:  8.577 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9250, Train loss: -0.179 Test loss: 14.500 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9260, Train loss: -0.194 Test loss: 11.507 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9270, Train loss:  0.190 Test loss:  5.605 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9280, Train loss: -0.161 Test loss: 12.143 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9290, Train loss: -0.058 Test loss: 10.231 Ensemble loss:  0.638 RMSE: 1.228 Num. networks: 29\n",
            "Epoch: 9300, Train loss: -0.222 Test loss: 12.743 Ensemble loss:  0.648 RMSE: 1.233 Num. networks: 30\n",
            "Epoch: 9310, Train loss: -0.134 Test loss: 13.320 Ensemble loss:  0.648 RMSE: 1.233 Num. networks: 30\n",
            "Epoch: 9320, Train loss:  0.390 Test loss:  2.305 Ensemble loss:  0.648 RMSE: 1.233 Num. networks: 30\n",
            "Epoch: 9330, Train loss:  0.069 Test loss:  6.035 Ensemble loss:  0.648 RMSE: 1.233 Num. networks: 30\n",
            "Epoch: 9340, Train loss: -0.143 Test loss:  9.599 Ensemble loss:  0.648 RMSE: 1.233 Num. networks: 30\n",
            "Epoch: 9350, Train loss: -0.191 Test loss: 10.740 Ensemble loss:  0.648 RMSE: 1.233 Num. networks: 30\n",
            "FOLD 5:\n",
            "Epoch:    0, Train loss: 18.273 Test loss: 13.480 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   10, Train loss:  4.840 Test loss:  4.631 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   20, Train loss:  3.428 Test loss:  3.378 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   30, Train loss:  2.958 Test loss:  2.930 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   40, Train loss:  2.679 Test loss:  2.673 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   50, Train loss:  2.525 Test loss:  2.522 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   60, Train loss:  2.415 Test loss:  2.409 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   70, Train loss:  2.363 Test loss:  2.361 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   80, Train loss:  2.321 Test loss:  2.318 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   90, Train loss:  2.289 Test loss:  2.289 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  100, Train loss:  2.259 Test loss:  2.258 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  110, Train loss:  2.245 Test loss:  2.245 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  120, Train loss:  2.236 Test loss:  2.237 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  130, Train loss:  2.228 Test loss:  2.230 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  140, Train loss:  2.221 Test loss:  2.222 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  150, Train loss:  2.214 Test loss:  2.217 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  160, Train loss:  2.209 Test loss:  2.213 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  170, Train loss:  2.204 Test loss:  2.206 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  180, Train loss:  2.197 Test loss:  2.196 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  190, Train loss:  2.194 Test loss:  2.196 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  200, Train loss:  2.186 Test loss:  2.187 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  210, Train loss:  2.186 Test loss:  2.188 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  220, Train loss:  2.183 Test loss:  2.183 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  230, Train loss:  2.171 Test loss:  2.172 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  240, Train loss:  2.168 Test loss:  2.166 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  250, Train loss:  2.163 Test loss:  2.163 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  260, Train loss:  2.157 Test loss:  2.160 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  270, Train loss:  2.157 Test loss:  2.158 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  280, Train loss:  2.147 Test loss:  2.149 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  290, Train loss:  2.142 Test loss:  2.148 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  300, Train loss:  2.133 Test loss:  2.139 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  310, Train loss:  2.128 Test loss:  2.131 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  320, Train loss:  2.122 Test loss:  2.116 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  330, Train loss:  2.108 Test loss:  2.103 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  340, Train loss:  2.101 Test loss:  2.092 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  350, Train loss:  2.072 Test loss:  2.070 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  360, Train loss:  2.056 Test loss:  2.058 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  370, Train loss:  2.046 Test loss:  2.050 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  380, Train loss:  2.014 Test loss:  2.022 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  390, Train loss:  1.982 Test loss:  1.990 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  400, Train loss:  1.951 Test loss:  1.958 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  410, Train loss:  1.884 Test loss:  1.895 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  420, Train loss:  1.825 Test loss:  1.837 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  430, Train loss:  1.764 Test loss:  1.786 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  440, Train loss:  1.664 Test loss:  1.693 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  450, Train loss:  1.530 Test loss:  1.533 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  460, Train loss:  1.328 Test loss:  1.319 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  470, Train loss:  1.119 Test loss:  1.055 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  480, Train loss:  0.953 Test loss:  0.865 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  490, Train loss:  0.867 Test loss:  0.779 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  500, Train loss:  0.787 Test loss:  0.685 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  510, Train loss:  0.720 Test loss:  0.664 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  520, Train loss:  0.659 Test loss:  0.632 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  530, Train loss:  0.618 Test loss:  0.630 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  540, Train loss:  0.585 Test loss:  0.633 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  550, Train loss:  0.548 Test loss:  0.628 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  560, Train loss:  0.517 Test loss:  0.621 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  570, Train loss:  0.496 Test loss:  0.637 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  580, Train loss:  0.474 Test loss:  0.623 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  590, Train loss:  0.457 Test loss:  0.633 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  600, Train loss:  0.453 Test loss:  0.689 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  610, Train loss:  0.433 Test loss:  0.699 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  620, Train loss:  0.421 Test loss:  0.727 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  630, Train loss:  0.417 Test loss:  0.702 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  640, Train loss:  0.410 Test loss:  0.692 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  650, Train loss:  0.401 Test loss:  0.694 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  660, Train loss:  0.391 Test loss:  0.677 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  670, Train loss:  0.383 Test loss:  0.698 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  680, Train loss:  0.361 Test loss:  0.697 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  690, Train loss:  0.352 Test loss:  0.681 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  700, Train loss:  0.341 Test loss:  0.687 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  710, Train loss:  0.320 Test loss:  0.677 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  720, Train loss:  0.316 Test loss:  0.726 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  730, Train loss:  0.301 Test loss:  0.704 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  740, Train loss:  0.294 Test loss:  0.741 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  750, Train loss:  0.286 Test loss:  0.743 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  760, Train loss:  0.281 Test loss:  0.783 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  770, Train loss:  0.268 Test loss:  0.894 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  780, Train loss:  0.264 Test loss:  0.777 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  790, Train loss:  0.243 Test loss:  0.814 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  800, Train loss:  0.246 Test loss:  0.700 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  810, Train loss:  0.237 Test loss:  0.744 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  820, Train loss:  0.231 Test loss:  0.805 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  830, Train loss:  0.224 Test loss:  0.810 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  840, Train loss:  0.219 Test loss:  0.736 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  850, Train loss:  0.215 Test loss:  0.722 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  860, Train loss:  0.227 Test loss:  0.778 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  870, Train loss:  0.208 Test loss:  0.776 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  880, Train loss:  0.199 Test loss:  0.849 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  890, Train loss:  0.195 Test loss:  0.919 Ensemble loss:    nan RMSE: 1.335 Num. networks:  1\n",
            "Epoch:  900, Train loss:  0.186 Test loss:  0.854 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  910, Train loss:  0.183 Test loss:  0.891 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  920, Train loss:  0.181 Test loss:  0.819 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  930, Train loss:  0.184 Test loss:  0.890 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  940, Train loss:  0.171 Test loss:  0.963 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  950, Train loss:  0.170 Test loss:  0.961 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  960, Train loss:  0.170 Test loss:  0.926 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  970, Train loss:  0.149 Test loss:  0.998 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  980, Train loss:  0.160 Test loss:  0.891 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch:  990, Train loss:  0.159 Test loss:  0.820 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1000, Train loss:  0.146 Test loss:  1.010 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1010, Train loss:  0.124 Test loss:  0.980 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1020, Train loss:  0.122 Test loss:  1.072 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1030, Train loss:  0.120 Test loss:  1.036 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1040, Train loss:  0.152 Test loss:  0.994 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1050, Train loss:  0.157 Test loss:  0.940 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1060, Train loss:  0.129 Test loss:  0.916 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1070, Train loss:  0.124 Test loss:  1.184 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1080, Train loss:  0.135 Test loss:  1.121 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1090, Train loss:  0.086 Test loss:  1.162 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1100, Train loss:  0.094 Test loss:  1.161 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1110, Train loss:  0.134 Test loss:  1.014 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1120, Train loss:  0.108 Test loss:  1.092 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1130, Train loss:  0.107 Test loss:  1.209 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1140, Train loss:  0.092 Test loss:  1.543 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1150, Train loss:  0.101 Test loss:  1.118 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1160, Train loss:  0.061 Test loss:  1.164 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1170, Train loss:  0.056 Test loss:  1.202 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1180, Train loss:  0.083 Test loss:  1.002 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1190, Train loss:  0.045 Test loss:  1.099 Ensemble loss:  0.626 RMSE: 1.241 Num. networks:  2\n",
            "Epoch: 1200, Train loss:  0.092 Test loss:  0.974 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1210, Train loss:  0.051 Test loss:  0.876 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1220, Train loss:  0.046 Test loss:  1.110 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1230, Train loss:  0.061 Test loss:  1.020 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1240, Train loss:  0.030 Test loss:  0.994 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1250, Train loss:  0.038 Test loss:  1.183 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1260, Train loss:  0.064 Test loss:  1.053 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1270, Train loss:  0.049 Test loss:  1.119 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1280, Train loss:  0.080 Test loss:  1.153 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1290, Train loss:  0.095 Test loss:  0.902 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1300, Train loss:  0.006 Test loss:  1.045 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1310, Train loss: -0.002 Test loss:  0.998 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1320, Train loss:  0.056 Test loss:  1.052 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1330, Train loss:  0.020 Test loss:  0.886 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1340, Train loss:  0.045 Test loss:  0.947 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1350, Train loss:  0.049 Test loss:  0.913 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1360, Train loss: -0.012 Test loss:  0.966 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1370, Train loss:  0.062 Test loss:  0.852 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1380, Train loss:  0.072 Test loss:  0.886 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1390, Train loss:  0.049 Test loss:  0.869 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1400, Train loss:  0.028 Test loss:  0.878 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1410, Train loss:  0.072 Test loss:  0.798 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1420, Train loss:  0.131 Test loss:  0.754 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1430, Train loss:  0.010 Test loss:  0.811 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1440, Train loss:  0.093 Test loss:  0.809 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1450, Train loss:  0.173 Test loss:  0.737 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1460, Train loss:  0.194 Test loss:  0.692 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1470, Train loss: -0.007 Test loss:  0.884 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1480, Train loss:  0.080 Test loss:  0.831 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1490, Train loss:  0.065 Test loss:  0.850 Ensemble loss:  0.624 RMSE: 1.194 Num. networks:  3\n",
            "Epoch: 1500, Train loss:  0.316 Test loss:  0.720 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1510, Train loss:  0.139 Test loss:  0.840 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1520, Train loss:  0.135 Test loss:  0.889 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1530, Train loss: -0.003 Test loss:  0.993 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1540, Train loss:  0.106 Test loss:  0.853 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1550, Train loss:  0.141 Test loss:  0.905 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1560, Train loss: -0.048 Test loss:  1.080 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1570, Train loss:  0.180 Test loss:  0.924 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1580, Train loss: -0.007 Test loss:  0.966 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1590, Train loss:  0.106 Test loss:  0.885 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1600, Train loss:  0.010 Test loss:  0.919 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1610, Train loss: -0.016 Test loss:  0.811 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1620, Train loss:  0.071 Test loss:  0.678 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1630, Train loss:  0.026 Test loss:  0.725 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1640, Train loss: -0.004 Test loss:  0.723 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1650, Train loss:  0.100 Test loss:  0.688 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1660, Train loss:  0.019 Test loss:  0.662 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1670, Train loss:  0.019 Test loss:  0.656 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1680, Train loss: -0.023 Test loss:  0.646 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1690, Train loss: -0.009 Test loss:  0.653 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1700, Train loss:  0.094 Test loss:  0.719 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1710, Train loss: -0.007 Test loss:  0.820 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1720, Train loss: -0.054 Test loss:  0.900 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1730, Train loss:  0.038 Test loss:  0.843 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1740, Train loss: -0.027 Test loss:  0.824 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1750, Train loss: -0.063 Test loss:  0.782 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1760, Train loss:  0.065 Test loss:  0.792 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1770, Train loss:  0.025 Test loss:  0.895 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1780, Train loss:  0.041 Test loss:  0.743 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1790, Train loss: -0.083 Test loss:  0.899 Ensemble loss:  0.570 RMSE: 1.138 Num. networks:  4\n",
            "Epoch: 1800, Train loss:  0.081 Test loss:  0.941 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1810, Train loss: -0.031 Test loss:  1.017 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1820, Train loss:  0.052 Test loss:  0.812 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1830, Train loss: -0.052 Test loss:  0.968 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1840, Train loss: -0.083 Test loss:  1.374 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1850, Train loss: -0.045 Test loss:  1.157 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1860, Train loss:  0.073 Test loss:  0.860 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1870, Train loss:  0.141 Test loss:  0.845 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1880, Train loss:  0.065 Test loss:  1.016 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1890, Train loss: -0.036 Test loss:  1.302 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1900, Train loss:  0.115 Test loss:  1.344 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1910, Train loss:  0.084 Test loss:  1.664 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1920, Train loss:  0.018 Test loss:  1.544 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1930, Train loss: -0.026 Test loss:  1.612 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1940, Train loss: -0.032 Test loss:  1.497 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1950, Train loss: -0.079 Test loss:  1.447 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1960, Train loss:  0.084 Test loss:  1.307 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1970, Train loss:  0.049 Test loss:  1.117 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1980, Train loss: -0.035 Test loss:  1.106 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 1990, Train loss: -0.074 Test loss:  1.224 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2000, Train loss:  0.190 Test loss:  0.979 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2010, Train loss:  0.150 Test loss:  0.865 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2020, Train loss: -0.088 Test loss:  1.226 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2030, Train loss: -0.039 Test loss:  1.175 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2040, Train loss: -0.052 Test loss:  0.996 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2050, Train loss: -0.077 Test loss:  0.826 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2060, Train loss:  0.135 Test loss:  1.123 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2070, Train loss: -0.045 Test loss:  0.938 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2080, Train loss: -0.090 Test loss:  0.899 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2090, Train loss:  0.004 Test loss:  0.872 Ensemble loss:  0.563 RMSE: 1.125 Num. networks:  5\n",
            "Epoch: 2100, Train loss:  0.063 Test loss:  0.921 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2110, Train loss: -0.072 Test loss:  0.873 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2120, Train loss: -0.067 Test loss:  0.830 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2130, Train loss: -0.040 Test loss:  0.804 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2140, Train loss: -0.031 Test loss:  0.736 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2150, Train loss:  0.087 Test loss:  0.701 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2160, Train loss:  0.079 Test loss:  0.622 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2170, Train loss: -0.009 Test loss:  0.836 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2180, Train loss: -0.118 Test loss:  0.830 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2190, Train loss: -0.048 Test loss:  0.682 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2200, Train loss: -0.119 Test loss:  0.724 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2210, Train loss:  0.210 Test loss:  0.665 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2220, Train loss: -0.004 Test loss:  0.600 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2230, Train loss: -0.076 Test loss:  0.825 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2240, Train loss:  0.214 Test loss:  0.627 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2250, Train loss: -0.002 Test loss:  0.659 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2260, Train loss:  0.591 Test loss:  0.504 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2270, Train loss: -0.115 Test loss:  0.661 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2280, Train loss: -0.100 Test loss:  0.901 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2290, Train loss:  0.105 Test loss:  0.884 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2300, Train loss:  0.025 Test loss:  0.646 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2310, Train loss: -0.060 Test loss:  0.848 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2320, Train loss: -0.036 Test loss:  0.920 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2330, Train loss:  0.005 Test loss:  0.943 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2340, Train loss:  0.320 Test loss:  1.070 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2350, Train loss: -0.036 Test loss:  0.654 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2360, Train loss: -0.048 Test loss:  0.844 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2370, Train loss:  0.022 Test loss:  0.807 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2380, Train loss:  0.033 Test loss:  0.914 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2390, Train loss: -0.056 Test loss:  0.828 Ensemble loss:  0.508 RMSE: 1.085 Num. networks:  6\n",
            "Epoch: 2400, Train loss:  0.068 Test loss:  0.714 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2410, Train loss:  0.154 Test loss:  0.865 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2420, Train loss:  0.044 Test loss:  0.788 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2430, Train loss:  0.079 Test loss:  0.916 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2440, Train loss:  0.064 Test loss:  0.709 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2450, Train loss: -0.071 Test loss:  0.987 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2460, Train loss: -0.062 Test loss:  0.861 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2470, Train loss: -0.082 Test loss:  0.976 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2480, Train loss: -0.080 Test loss:  0.833 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2490, Train loss: -0.102 Test loss:  1.228 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2500, Train loss: -0.099 Test loss:  0.982 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2510, Train loss:  0.073 Test loss:  0.825 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2520, Train loss:  0.031 Test loss:  0.711 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2530, Train loss:  0.286 Test loss:  0.690 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2540, Train loss:  0.117 Test loss:  0.769 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2550, Train loss:  0.124 Test loss:  0.769 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2560, Train loss:  0.114 Test loss:  1.204 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2570, Train loss:  0.297 Test loss:  0.741 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2580, Train loss:  0.283 Test loss:  1.008 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2590, Train loss: -0.031 Test loss:  1.608 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2600, Train loss: -0.081 Test loss:  1.989 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2610, Train loss: -0.115 Test loss:  1.876 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2620, Train loss: -0.101 Test loss:  2.203 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2630, Train loss: -0.091 Test loss:  1.597 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2640, Train loss:  0.069 Test loss:  1.224 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2650, Train loss: -0.097 Test loss:  1.428 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2660, Train loss: -0.092 Test loss:  1.229 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2670, Train loss: -0.061 Test loss:  1.651 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2680, Train loss: -0.051 Test loss:  1.742 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2690, Train loss: -0.037 Test loss:  2.061 Ensemble loss:  0.498 RMSE: 1.069 Num. networks:  7\n",
            "Epoch: 2700, Train loss: -0.094 Test loss:  1.923 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2710, Train loss: -0.022 Test loss:  1.805 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2720, Train loss:  0.012 Test loss:  1.194 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2730, Train loss:  0.003 Test loss:  1.510 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2740, Train loss:  0.060 Test loss:  1.449 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2750, Train loss: -0.049 Test loss:  1.498 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2760, Train loss: -0.057 Test loss:  1.612 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2770, Train loss: -0.103 Test loss:  1.671 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2780, Train loss: -0.010 Test loss:  1.726 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2790, Train loss:  0.151 Test loss:  1.211 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2800, Train loss:  0.052 Test loss:  1.207 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2810, Train loss:  0.016 Test loss:  1.265 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2820, Train loss:  0.081 Test loss:  1.050 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2830, Train loss: -0.060 Test loss:  1.705 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2840, Train loss: -0.041 Test loss:  1.529 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2850, Train loss:  0.006 Test loss:  1.122 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2860, Train loss:  0.037 Test loss:  1.061 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2870, Train loss:  0.035 Test loss:  0.919 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2880, Train loss:  0.000 Test loss:  0.952 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2890, Train loss: -0.062 Test loss:  1.471 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2900, Train loss:  0.082 Test loss:  1.339 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2910, Train loss: -0.058 Test loss:  1.577 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2920, Train loss: -0.095 Test loss:  1.463 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2930, Train loss:  0.300 Test loss:  1.274 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2940, Train loss:  0.080 Test loss:  2.281 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2950, Train loss: -0.033 Test loss:  1.143 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2960, Train loss: -0.018 Test loss:  1.043 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2970, Train loss: -0.080 Test loss:  1.337 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2980, Train loss:  0.048 Test loss:  1.022 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 2990, Train loss: -0.077 Test loss:  1.362 Ensemble loss:  0.485 RMSE: 1.064 Num. networks:  8\n",
            "Epoch: 3000, Train loss: -0.042 Test loss:  1.246 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3010, Train loss: -0.033 Test loss:  1.597 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3020, Train loss:  0.117 Test loss:  1.329 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3030, Train loss: -0.017 Test loss:  3.662 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3040, Train loss: -0.084 Test loss:  3.570 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3050, Train loss:  0.023 Test loss:  3.022 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3060, Train loss:  0.102 Test loss:  2.764 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3070, Train loss: -0.048 Test loss:  2.227 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3080, Train loss: -0.072 Test loss:  2.737 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3090, Train loss: -0.031 Test loss:  2.390 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3100, Train loss:  0.183 Test loss:  1.911 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3110, Train loss:  0.316 Test loss:  1.598 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3120, Train loss:  0.162 Test loss:  1.540 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3130, Train loss:  0.308 Test loss:  2.114 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3140, Train loss: -0.103 Test loss:  3.296 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3150, Train loss: -0.076 Test loss:  2.583 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3160, Train loss:  0.105 Test loss:  1.554 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3170, Train loss:  0.383 Test loss:  1.399 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3180, Train loss:  0.313 Test loss:  1.047 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3190, Train loss:  0.080 Test loss:  2.058 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3200, Train loss: -0.127 Test loss:  2.389 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3210, Train loss: -0.072 Test loss:  2.930 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3220, Train loss:  0.062 Test loss:  1.752 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3230, Train loss:  0.024 Test loss:  2.471 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3240, Train loss:  0.408 Test loss:  1.594 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3250, Train loss: -0.131 Test loss:  3.089 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3260, Train loss: -0.136 Test loss:  2.529 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3270, Train loss: -0.145 Test loss:  3.352 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3280, Train loss:  0.025 Test loss:  1.887 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3290, Train loss: -0.107 Test loss:  2.736 Ensemble loss:  0.499 RMSE: 1.071 Num. networks:  9\n",
            "Epoch: 3300, Train loss: -0.132 Test loss:  3.168 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3310, Train loss: -0.119 Test loss:  2.705 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3320, Train loss: -0.134 Test loss:  2.371 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3330, Train loss:  0.028 Test loss:  2.004 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3340, Train loss:  0.499 Test loss:  1.392 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3350, Train loss:  0.049 Test loss:  2.844 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3360, Train loss: -0.131 Test loss:  3.389 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3370, Train loss:  0.101 Test loss:  3.048 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3380, Train loss:  0.006 Test loss:  3.047 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3390, Train loss: -0.102 Test loss:  3.723 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3400, Train loss: -0.144 Test loss:  3.301 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3410, Train loss: -0.077 Test loss:  1.990 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3420, Train loss:  0.106 Test loss:  1.434 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3430, Train loss: -0.118 Test loss:  3.011 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3440, Train loss:  0.048 Test loss:  1.636 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3450, Train loss: -0.069 Test loss:  2.654 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3460, Train loss: -0.127 Test loss:  3.766 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3470, Train loss:  0.018 Test loss:  1.942 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3480, Train loss: -0.129 Test loss:  2.782 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3490, Train loss: -0.134 Test loss:  2.755 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3500, Train loss:  0.243 Test loss:  1.453 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3510, Train loss: -0.117 Test loss:  2.809 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3520, Train loss:  0.136 Test loss:  1.622 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3530, Train loss: -0.046 Test loss:  2.889 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3540, Train loss:  0.127 Test loss:  2.550 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3550, Train loss: -0.085 Test loss:  3.321 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3560, Train loss:  0.044 Test loss:  2.565 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3570, Train loss: -0.062 Test loss:  3.713 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3580, Train loss:  0.145 Test loss:  3.460 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3590, Train loss: -0.070 Test loss:  2.639 Ensemble loss:  0.502 RMSE: 1.080 Num. networks: 10\n",
            "Epoch: 3600, Train loss: -0.121 Test loss:  2.785 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3610, Train loss: -0.021 Test loss:  1.878 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3620, Train loss: -0.049 Test loss:  2.047 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3630, Train loss: -0.045 Test loss:  1.419 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3640, Train loss:  0.033 Test loss:  1.168 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3650, Train loss:  0.191 Test loss:  1.167 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3660, Train loss: -0.084 Test loss:  2.188 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3670, Train loss:  0.253 Test loss:  2.231 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3680, Train loss:  0.138 Test loss:  2.396 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3690, Train loss:  0.013 Test loss:  1.686 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3700, Train loss:  0.165 Test loss:  1.372 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3710, Train loss: -0.121 Test loss:  1.890 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3720, Train loss:  0.040 Test loss:  1.429 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3730, Train loss: -0.013 Test loss:  1.645 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3740, Train loss: -0.126 Test loss:  1.992 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3750, Train loss: -0.175 Test loss:  3.008 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3760, Train loss:  0.407 Test loss:  2.111 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3770, Train loss: -0.182 Test loss:  3.212 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3780, Train loss: -0.173 Test loss:  4.055 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3790, Train loss: -0.112 Test loss:  3.899 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3800, Train loss:  0.205 Test loss:  2.501 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3810, Train loss:  0.326 Test loss:  1.534 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3820, Train loss: -0.035 Test loss:  2.337 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3830, Train loss: -0.072 Test loss:  3.472 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3840, Train loss:  0.150 Test loss:  1.270 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3850, Train loss: -0.104 Test loss:  2.802 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3860, Train loss: -0.109 Test loss:  5.219 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3870, Train loss: -0.012 Test loss:  2.902 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3880, Train loss: -0.153 Test loss:  2.488 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3890, Train loss: -0.121 Test loss:  4.294 Ensemble loss:  0.494 RMSE: 1.082 Num. networks: 11\n",
            "Epoch: 3900, Train loss:  0.028 Test loss:  2.450 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3910, Train loss: -0.175 Test loss:  3.540 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3920, Train loss: -0.165 Test loss:  3.194 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3930, Train loss: -0.199 Test loss:  3.063 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3940, Train loss: -0.133 Test loss:  2.000 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3950, Train loss: -0.027 Test loss:  1.682 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3960, Train loss: -0.082 Test loss:  2.027 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3970, Train loss:  0.362 Test loss:  1.705 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3980, Train loss:  0.190 Test loss:  1.127 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 3990, Train loss:  0.480 Test loss:  0.936 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4000, Train loss:  0.479 Test loss:  0.974 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4010, Train loss:  0.624 Test loss:  1.853 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4020, Train loss:  0.046 Test loss:  1.919 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4030, Train loss:  0.206 Test loss:  2.126 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4040, Train loss: -0.034 Test loss:  3.732 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4050, Train loss: -0.219 Test loss:  6.453 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4060, Train loss:  0.014 Test loss:  2.047 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4070, Train loss: -0.049 Test loss:  3.437 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4080, Train loss: -0.110 Test loss:  4.665 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4090, Train loss:  0.185 Test loss:  2.357 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4100, Train loss: -0.138 Test loss:  4.418 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4110, Train loss: -0.074 Test loss:  5.408 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4120, Train loss:  0.159 Test loss:  2.179 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4130, Train loss: -0.014 Test loss:  5.427 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4140, Train loss: -0.110 Test loss:  6.263 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4150, Train loss:  0.004 Test loss:  3.735 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4160, Train loss: -0.176 Test loss:  6.391 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4170, Train loss: -0.166 Test loss:  4.831 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4180, Train loss: -0.164 Test loss:  4.905 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4190, Train loss: -0.160 Test loss:  3.611 Ensemble loss:  0.499 RMSE: 1.084 Num. networks: 12\n",
            "Epoch: 4200, Train loss:  0.015 Test loss:  1.978 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4210, Train loss:  0.000 Test loss:  2.398 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4220, Train loss: -0.168 Test loss:  4.378 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4230, Train loss: -0.157 Test loss:  3.958 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4240, Train loss: -0.132 Test loss:  4.756 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4250, Train loss: -0.141 Test loss:  4.555 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4260, Train loss: -0.149 Test loss:  4.425 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4270, Train loss:  0.358 Test loss:  1.937 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4280, Train loss: -0.160 Test loss:  2.416 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4290, Train loss:  0.156 Test loss:  1.134 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4300, Train loss: -0.035 Test loss:  2.492 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4310, Train loss: -0.208 Test loss:  3.225 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4320, Train loss: -0.218 Test loss:  2.796 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4330, Train loss: -0.205 Test loss:  3.406 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4340, Train loss:  0.101 Test loss:  3.833 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4350, Train loss:  0.046 Test loss:  1.208 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4360, Train loss:  0.161 Test loss:  3.771 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4370, Train loss: -0.047 Test loss:  1.403 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4380, Train loss: -0.126 Test loss:  1.382 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4390, Train loss: -0.096 Test loss:  1.389 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4400, Train loss: -0.111 Test loss:  1.539 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4410, Train loss:  0.297 Test loss:  2.315 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4420, Train loss: -0.086 Test loss:  1.859 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4430, Train loss: -0.193 Test loss:  2.606 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4440, Train loss: -0.198 Test loss:  1.995 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4450, Train loss: -0.138 Test loss:  1.434 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4460, Train loss:  0.066 Test loss:  0.949 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4470, Train loss:  0.231 Test loss:  1.526 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4480, Train loss:  0.790 Test loss:  0.632 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4490, Train loss:  0.063 Test loss:  0.896 Ensemble loss:  0.498 RMSE: 1.083 Num. networks: 13\n",
            "Epoch: 4500, Train loss: -0.018 Test loss:  1.021 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4510, Train loss:  0.103 Test loss:  0.910 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4520, Train loss:  0.190 Test loss:  0.838 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4530, Train loss: -0.027 Test loss:  0.930 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4540, Train loss: -0.174 Test loss:  1.439 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4550, Train loss:  0.302 Test loss:  1.363 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4560, Train loss: -0.160 Test loss:  1.927 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4570, Train loss: -0.208 Test loss:  2.255 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4580, Train loss:  0.403 Test loss:  1.354 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4590, Train loss: -0.127 Test loss:  1.517 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4600, Train loss: -0.092 Test loss:  1.339 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4610, Train loss:  0.108 Test loss:  1.019 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4620, Train loss: -0.137 Test loss:  1.616 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4630, Train loss:  0.078 Test loss:  1.191 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4640, Train loss:  0.193 Test loss:  1.055 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4650, Train loss: -0.162 Test loss:  2.014 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4660, Train loss:  0.020 Test loss:  3.122 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4670, Train loss: -0.091 Test loss:  2.435 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4680, Train loss: -0.045 Test loss:  3.235 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4690, Train loss: -0.006 Test loss:  2.516 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4700, Train loss: -0.064 Test loss:  3.361 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4710, Train loss: -0.084 Test loss:  2.808 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4720, Train loss: -0.045 Test loss:  3.055 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4730, Train loss: -0.112 Test loss:  2.557 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4740, Train loss: -0.103 Test loss:  2.934 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4750, Train loss: -0.126 Test loss:  2.851 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4760, Train loss: -0.095 Test loss:  2.595 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4770, Train loss:  0.032 Test loss:  1.875 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4780, Train loss: -0.010 Test loss:  2.030 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4790, Train loss: -0.023 Test loss:  2.267 Ensemble loss:  0.482 RMSE: 1.069 Num. networks: 14\n",
            "Epoch: 4800, Train loss:  0.033 Test loss:  2.190 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4810, Train loss: -0.188 Test loss:  4.502 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4820, Train loss: -0.155 Test loss:  5.548 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4830, Train loss: -0.104 Test loss:  3.805 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4840, Train loss: -0.081 Test loss:  2.805 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4850, Train loss: -0.181 Test loss:  4.086 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4860, Train loss: -0.152 Test loss:  4.585 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4870, Train loss:  0.090 Test loss:  1.743 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4880, Train loss: -0.191 Test loss:  2.975 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4890, Train loss: -0.157 Test loss:  3.813 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4900, Train loss: -0.059 Test loss:  1.874 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4910, Train loss: -0.132 Test loss:  2.830 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4920, Train loss: -0.072 Test loss:  2.674 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4930, Train loss:  0.131 Test loss:  1.656 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4940, Train loss: -0.014 Test loss:  1.782 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4950, Train loss: -0.190 Test loss:  3.972 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4960, Train loss: -0.176 Test loss:  3.368 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4970, Train loss: -0.176 Test loss:  3.274 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4980, Train loss:  0.076 Test loss:  1.639 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 4990, Train loss: -0.184 Test loss:  3.874 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5000, Train loss: -0.131 Test loss:  2.458 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5010, Train loss: -0.216 Test loss:  3.767 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5020, Train loss:  0.110 Test loss:  2.876 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5030, Train loss: -0.063 Test loss:  2.303 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5040, Train loss: -0.175 Test loss:  2.693 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5050, Train loss:  0.031 Test loss:  1.514 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5060, Train loss: -0.078 Test loss:  2.730 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5070, Train loss:  0.055 Test loss:  2.063 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5080, Train loss: -0.073 Test loss:  3.467 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5090, Train loss: -0.117 Test loss:  3.235 Ensemble loss:  0.478 RMSE: 1.054 Num. networks: 15\n",
            "Epoch: 5100, Train loss:  0.066 Test loss:  1.506 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5110, Train loss: -0.049 Test loss:  3.122 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5120, Train loss: -0.166 Test loss:  4.293 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5130, Train loss: -0.157 Test loss:  3.089 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5140, Train loss:  0.461 Test loss:  1.063 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5150, Train loss: -0.076 Test loss:  3.849 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5160, Train loss: -0.103 Test loss:  3.091 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5170, Train loss: -0.078 Test loss:  4.495 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5180, Train loss:  0.235 Test loss:  1.774 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5190, Train loss:  0.008 Test loss:  3.367 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5200, Train loss:  0.138 Test loss:  2.013 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5210, Train loss: -0.161 Test loss:  2.275 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5220, Train loss: -0.107 Test loss:  1.796 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5230, Train loss: -0.165 Test loss:  1.583 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5240, Train loss: -0.059 Test loss:  1.813 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5250, Train loss: -0.070 Test loss:  1.215 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5260, Train loss: -0.157 Test loss:  1.364 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5270, Train loss:  0.260 Test loss:  0.849 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5280, Train loss: -0.123 Test loss:  1.631 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5290, Train loss: -0.165 Test loss:  2.211 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5300, Train loss:  0.033 Test loss:  2.462 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5310, Train loss: -0.111 Test loss:  1.863 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5320, Train loss: -0.174 Test loss:  3.155 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5330, Train loss: -0.193 Test loss:  2.781 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5340, Train loss: -0.189 Test loss:  3.153 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5350, Train loss:  0.077 Test loss:  3.505 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5360, Train loss: -0.200 Test loss:  3.699 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5370, Train loss: -0.165 Test loss:  4.074 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5380, Train loss: -0.204 Test loss:  4.177 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5390, Train loss: -0.123 Test loss:  2.852 Ensemble loss:  0.472 RMSE: 1.048 Num. networks: 16\n",
            "Epoch: 5400, Train loss:  0.170 Test loss:  3.019 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5410, Train loss: -0.022 Test loss:  2.369 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5420, Train loss:  0.099 Test loss:  1.502 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5430, Train loss:  0.143 Test loss:  1.491 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5440, Train loss: -0.182 Test loss:  3.503 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5450, Train loss: -0.091 Test loss:  1.733 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5460, Train loss: -0.182 Test loss:  2.124 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5470, Train loss: -0.142 Test loss:  2.079 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5480, Train loss: -0.210 Test loss:  2.654 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5490, Train loss: -0.202 Test loss:  2.650 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5500, Train loss: -0.155 Test loss:  2.397 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5510, Train loss: -0.186 Test loss:  3.360 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5520, Train loss: -0.183 Test loss:  3.180 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5530, Train loss: -0.091 Test loss:  3.064 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5540, Train loss:  0.076 Test loss:  2.124 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5550, Train loss:  0.175 Test loss:  1.771 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5560, Train loss:  0.208 Test loss:  1.638 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5570, Train loss:  0.049 Test loss:  1.439 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5580, Train loss: -0.016 Test loss:  1.670 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5590, Train loss:  0.132 Test loss:  1.073 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5600, Train loss:  0.119 Test loss:  1.304 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5610, Train loss: -0.187 Test loss:  2.727 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5620, Train loss: -0.182 Test loss:  2.423 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5630, Train loss: -0.174 Test loss:  2.428 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5640, Train loss: -0.178 Test loss:  3.274 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5650, Train loss:  0.236 Test loss:  1.135 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5660, Train loss: -0.095 Test loss:  2.790 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5670, Train loss:  0.316 Test loss:  1.265 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5680, Train loss: -0.106 Test loss:  2.098 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5690, Train loss:  0.103 Test loss:  1.930 Ensemble loss:  0.457 RMSE: 1.035 Num. networks: 17\n",
            "Epoch: 5700, Train loss: -0.063 Test loss:  1.659 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5710, Train loss: -0.110 Test loss:  1.684 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5720, Train loss:  0.066 Test loss:  1.718 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5730, Train loss: -0.049 Test loss:  2.038 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5740, Train loss: -0.173 Test loss:  1.954 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5750, Train loss: -0.069 Test loss:  1.523 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5760, Train loss: -0.127 Test loss:  1.602 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5770, Train loss: -0.082 Test loss:  2.258 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5780, Train loss:  0.018 Test loss:  1.475 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5790, Train loss: -0.101 Test loss:  2.464 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5800, Train loss: -0.090 Test loss:  2.302 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5810, Train loss: -0.065 Test loss:  1.953 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5820, Train loss:  0.067 Test loss:  2.123 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5830, Train loss: -0.194 Test loss:  4.816 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5840, Train loss: -0.094 Test loss:  2.759 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5850, Train loss: -0.042 Test loss:  2.503 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5860, Train loss:  0.562 Test loss:  1.979 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5870, Train loss:  0.043 Test loss:  2.618 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5880, Train loss: -0.146 Test loss:  4.237 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5890, Train loss:  0.158 Test loss:  3.537 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5900, Train loss: -0.014 Test loss:  3.556 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5910, Train loss: -0.014 Test loss:  3.269 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5920, Train loss:  0.037 Test loss:  3.275 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5930, Train loss:  0.116 Test loss:  2.802 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5940, Train loss:  0.153 Test loss:  1.632 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5950, Train loss: -0.168 Test loss:  2.834 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5960, Train loss:  0.053 Test loss:  2.890 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5970, Train loss:  0.208 Test loss:  1.353 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5980, Train loss: -0.179 Test loss:  3.387 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 5990, Train loss: -0.104 Test loss:  2.775 Ensemble loss:  0.453 RMSE: 1.027 Num. networks: 18\n",
            "Epoch: 6000, Train loss: -0.114 Test loss:  2.434 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6010, Train loss:  0.324 Test loss:  1.588 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6020, Train loss:  0.023 Test loss:  2.646 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6030, Train loss:  0.181 Test loss:  2.321 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6040, Train loss:  0.032 Test loss:  2.617 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6050, Train loss: -0.118 Test loss:  2.825 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6060, Train loss: -0.123 Test loss:  3.654 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6070, Train loss: -0.145 Test loss:  3.422 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6080, Train loss:  0.311 Test loss:  2.019 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6090, Train loss: -0.125 Test loss:  3.686 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6100, Train loss: -0.154 Test loss:  4.250 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6110, Train loss: -0.005 Test loss:  4.808 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6120, Train loss:  0.025 Test loss:  2.140 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6130, Train loss: -0.049 Test loss:  2.599 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6140, Train loss: -0.043 Test loss:  2.944 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6150, Train loss: -0.077 Test loss:  3.469 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6160, Train loss: -0.056 Test loss:  2.502 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6170, Train loss: -0.086 Test loss:  2.841 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6180, Train loss: -0.026 Test loss:  1.580 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6190, Train loss:  0.057 Test loss:  1.200 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6200, Train loss:  0.126 Test loss:  1.654 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6210, Train loss:  0.235 Test loss:  0.809 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6220, Train loss:  0.103 Test loss:  0.911 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6230, Train loss: -0.187 Test loss:  2.252 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6240, Train loss: -0.214 Test loss:  2.429 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6250, Train loss: -0.180 Test loss:  2.636 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6260, Train loss: -0.156 Test loss:  3.097 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6270, Train loss: -0.202 Test loss:  3.579 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6280, Train loss: -0.139 Test loss:  3.515 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6290, Train loss:  0.062 Test loss:  2.273 Ensemble loss:  0.444 RMSE: 1.020 Num. networks: 19\n",
            "Epoch: 6300, Train loss: -0.205 Test loss:  2.992 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6310, Train loss:  0.160 Test loss:  2.255 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6320, Train loss: -0.176 Test loss:  2.477 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6330, Train loss: -0.212 Test loss:  2.455 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6340, Train loss: -0.213 Test loss:  3.031 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6350, Train loss: -0.212 Test loss:  2.357 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6360, Train loss: -0.097 Test loss:  1.681 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6370, Train loss: -0.213 Test loss:  2.237 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6380, Train loss: -0.117 Test loss:  1.855 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6390, Train loss: -0.089 Test loss:  1.694 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6400, Train loss:  0.077 Test loss:  1.310 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6410, Train loss:  0.042 Test loss:  1.823 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6420, Train loss: -0.243 Test loss:  2.341 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6430, Train loss: -0.202 Test loss:  2.022 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6440, Train loss: -0.104 Test loss:  1.422 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6450, Train loss: -0.172 Test loss:  1.415 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6460, Train loss: -0.223 Test loss:  1.284 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6470, Train loss: -0.077 Test loss:  2.026 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6480, Train loss: -0.214 Test loss:  1.455 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6490, Train loss:  0.433 Test loss:  0.980 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6500, Train loss: -0.048 Test loss:  1.170 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6510, Train loss: -0.207 Test loss:  2.094 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6520, Train loss: -0.058 Test loss:  2.284 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6530, Train loss: -0.094 Test loss:  1.204 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6540, Train loss: -0.211 Test loss:  2.163 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6550, Train loss: -0.051 Test loss:  2.591 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6560, Train loss: -0.220 Test loss:  2.744 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6570, Train loss: -0.165 Test loss:  3.425 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6580, Train loss:  0.537 Test loss:  1.070 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6590, Train loss: -0.227 Test loss:  2.890 Ensemble loss:  0.429 RMSE: 1.006 Num. networks: 20\n",
            "Epoch: 6600, Train loss: -0.232 Test loss:  2.884 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6610, Train loss:  0.025 Test loss:  2.405 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6620, Train loss: -0.068 Test loss:  2.072 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6630, Train loss: -0.238 Test loss:  3.334 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6640, Train loss: -0.231 Test loss:  3.549 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6650, Train loss: -0.254 Test loss:  3.344 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6660, Train loss: -0.163 Test loss:  3.055 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6670, Train loss: -0.102 Test loss:  2.080 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6680, Train loss: -0.190 Test loss:  2.568 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6690, Train loss:  0.020 Test loss:  1.242 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6700, Train loss: -0.063 Test loss:  2.102 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6710, Train loss: -0.127 Test loss:  2.275 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6720, Train loss: -0.112 Test loss:  2.165 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6730, Train loss: -0.186 Test loss:  1.780 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6740, Train loss: -0.186 Test loss:  2.152 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6750, Train loss: -0.216 Test loss:  2.090 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6760, Train loss: -0.170 Test loss:  2.348 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6770, Train loss: -0.075 Test loss:  2.043 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6780, Train loss: -0.103 Test loss:  1.844 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6790, Train loss: -0.180 Test loss:  1.687 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6800, Train loss: -0.200 Test loss:  3.246 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6810, Train loss: -0.204 Test loss:  2.732 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6820, Train loss: -0.176 Test loss:  2.246 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6830, Train loss: -0.189 Test loss:  2.835 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6840, Train loss: -0.052 Test loss:  2.897 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6850, Train loss:  0.146 Test loss:  1.376 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6860, Train loss: -0.208 Test loss:  2.475 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6870, Train loss: -0.171 Test loss:  2.818 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6880, Train loss: -0.006 Test loss:  2.281 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6890, Train loss:  0.310 Test loss:  0.940 Ensemble loss:  0.422 RMSE: 0.997 Num. networks: 21\n",
            "Epoch: 6900, Train loss: -0.112 Test loss:  1.703 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6910, Train loss: -0.046 Test loss:  2.096 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6920, Train loss: -0.093 Test loss:  1.645 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6930, Train loss: -0.155 Test loss:  2.184 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6940, Train loss: -0.146 Test loss:  1.806 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6950, Train loss: -0.219 Test loss:  2.416 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6960, Train loss: -0.208 Test loss:  2.185 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6970, Train loss: -0.239 Test loss:  2.015 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6980, Train loss: -0.158 Test loss:  2.206 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 6990, Train loss: -0.051 Test loss:  1.283 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7000, Train loss: -0.186 Test loss:  2.241 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7010, Train loss: -0.201 Test loss:  2.546 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7020, Train loss: -0.158 Test loss:  3.023 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7030, Train loss: -0.013 Test loss:  2.446 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7040, Train loss:  0.038 Test loss:  2.263 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7050, Train loss:  0.110 Test loss:  1.719 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7060, Train loss: -0.034 Test loss:  1.685 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7070, Train loss: -0.165 Test loss:  2.615 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7080, Train loss:  0.164 Test loss:  1.209 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7090, Train loss: -0.180 Test loss:  2.517 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7100, Train loss:  0.314 Test loss:  1.468 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7110, Train loss: -0.114 Test loss:  1.561 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7120, Train loss: -0.183 Test loss:  2.168 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7130, Train loss: -0.106 Test loss:  1.779 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7140, Train loss:  0.081 Test loss:  1.432 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7150, Train loss: -0.069 Test loss:  1.321 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7160, Train loss: -0.123 Test loss:  1.424 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7170, Train loss:  0.080 Test loss:  0.989 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7180, Train loss: -0.197 Test loss:  1.789 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7190, Train loss: -0.208 Test loss:  2.080 Ensemble loss:  0.416 RMSE: 0.991 Num. networks: 22\n",
            "Epoch: 7200, Train loss: -0.116 Test loss:  2.197 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7210, Train loss:  0.167 Test loss:  1.634 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7220, Train loss: -0.030 Test loss:  1.613 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7230, Train loss:  0.001 Test loss:  1.302 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7240, Train loss:  0.060 Test loss:  1.688 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7250, Train loss: -0.187 Test loss:  1.808 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7260, Train loss: -0.193 Test loss:  2.452 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7270, Train loss: -0.070 Test loss:  2.652 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7280, Train loss: -0.111 Test loss:  2.591 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7290, Train loss: -0.133 Test loss:  1.785 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7300, Train loss: -0.120 Test loss:  2.091 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7310, Train loss: -0.092 Test loss:  2.357 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7320, Train loss:  0.258 Test loss:  0.990 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7330, Train loss: -0.067 Test loss:  1.187 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7340, Train loss: -0.110 Test loss:  1.672 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7350, Train loss: -0.220 Test loss:  1.850 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7360, Train loss: -0.153 Test loss:  1.673 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7370, Train loss: -0.210 Test loss:  2.254 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7380, Train loss: -0.218 Test loss:  2.056 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7390, Train loss: -0.220 Test loss:  1.772 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7400, Train loss: -0.123 Test loss:  2.164 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7410, Train loss: -0.148 Test loss:  1.389 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7420, Train loss: -0.211 Test loss:  1.944 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7430, Train loss: -0.215 Test loss:  2.086 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7440, Train loss: -0.004 Test loss:  2.430 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7450, Train loss:  0.011 Test loss:  1.640 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7460, Train loss: -0.145 Test loss:  1.268 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7470, Train loss: -0.238 Test loss:  1.883 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7480, Train loss:  0.088 Test loss:  1.203 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7490, Train loss:  0.307 Test loss:  1.188 Ensemble loss:  0.416 RMSE: 0.984 Num. networks: 23\n",
            "Epoch: 7500, Train loss:  0.132 Test loss:  1.123 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7510, Train loss: -0.149 Test loss:  1.531 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7520, Train loss: -0.213 Test loss:  1.709 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7530, Train loss: -0.219 Test loss:  1.706 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7540, Train loss: -0.214 Test loss:  2.195 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7550, Train loss: -0.145 Test loss:  1.489 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7560, Train loss: -0.214 Test loss:  2.094 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7570, Train loss: -0.216 Test loss:  2.360 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7580, Train loss: -0.226 Test loss:  2.676 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7590, Train loss: -0.185 Test loss:  2.689 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7600, Train loss:  0.616 Test loss:  0.928 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7610, Train loss: -0.123 Test loss:  2.265 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7620, Train loss: -0.242 Test loss:  3.636 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7630, Train loss: -0.179 Test loss:  3.167 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7640, Train loss: -0.239 Test loss:  2.782 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7650, Train loss: -0.238 Test loss:  2.733 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7660, Train loss: -0.065 Test loss:  2.223 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7670, Train loss:  0.115 Test loss:  1.713 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7680, Train loss:  0.128 Test loss:  1.001 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7690, Train loss: -0.179 Test loss:  2.331 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7700, Train loss:  0.049 Test loss:  2.466 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7710, Train loss: -0.017 Test loss:  1.719 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7720, Train loss:  0.033 Test loss:  1.876 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7730, Train loss: -0.168 Test loss:  2.624 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7740, Train loss: -0.180 Test loss:  2.246 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7750, Train loss: -0.187 Test loss:  1.787 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7760, Train loss: -0.163 Test loss:  2.376 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7770, Train loss: -0.145 Test loss:  1.760 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7780, Train loss:  0.030 Test loss:  1.476 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7790, Train loss:  0.113 Test loss:  1.039 Ensemble loss:  0.409 RMSE: 0.977 Num. networks: 24\n",
            "Epoch: 7800, Train loss: -0.122 Test loss:  1.652 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7810, Train loss: -0.068 Test loss:  1.302 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7820, Train loss: -0.092 Test loss:  2.015 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7830, Train loss: -0.169 Test loss:  2.287 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7840, Train loss: -0.016 Test loss:  3.073 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7850, Train loss: -0.101 Test loss:  2.591 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7860, Train loss:  0.097 Test loss:  1.626 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7870, Train loss: -0.064 Test loss:  2.264 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7880, Train loss:  0.023 Test loss:  2.080 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7890, Train loss: -0.030 Test loss:  1.988 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7900, Train loss: -0.165 Test loss:  2.591 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7910, Train loss:  0.039 Test loss:  1.726 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7920, Train loss:  0.055 Test loss:  1.353 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7930, Train loss: -0.040 Test loss:  1.328 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7940, Train loss: -0.096 Test loss:  1.625 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7950, Train loss:  0.181 Test loss:  1.209 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7960, Train loss:  0.292 Test loss:  1.082 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7970, Train loss: -0.155 Test loss:  2.771 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7980, Train loss: -0.150 Test loss:  2.864 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 7990, Train loss: -0.163 Test loss:  2.580 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8000, Train loss: -0.039 Test loss:  1.360 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8010, Train loss: -0.187 Test loss:  1.937 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8020, Train loss:  0.252 Test loss:  1.063 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8030, Train loss: -0.148 Test loss:  1.889 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8040, Train loss:  0.294 Test loss:  1.109 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8050, Train loss:  0.077 Test loss:  1.111 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8060, Train loss: -0.180 Test loss:  1.989 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8070, Train loss: -0.169 Test loss:  2.891 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8080, Train loss:  0.009 Test loss:  1.562 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8090, Train loss:  0.036 Test loss:  1.514 Ensemble loss:  0.395 RMSE: 0.971 Num. networks: 25\n",
            "Epoch: 8100, Train loss: -0.167 Test loss:  2.778 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8110, Train loss: -0.004 Test loss:  2.450 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8120, Train loss: -0.091 Test loss:  2.056 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8130, Train loss:  0.155 Test loss:  1.750 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8140, Train loss:  0.116 Test loss:  2.191 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8150, Train loss:  0.129 Test loss:  1.122 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8160, Train loss: -0.117 Test loss:  2.438 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8170, Train loss:  0.483 Test loss:  0.978 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8180, Train loss: -0.160 Test loss:  2.255 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8190, Train loss: -0.125 Test loss:  2.197 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8200, Train loss:  0.142 Test loss:  0.972 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8210, Train loss: -0.118 Test loss:  1.868 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8220, Train loss:  0.185 Test loss:  0.830 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8230, Train loss:  0.125 Test loss:  0.874 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8240, Train loss: -0.155 Test loss:  1.442 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8250, Train loss: -0.168 Test loss:  2.994 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8260, Train loss:  0.200 Test loss:  2.402 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8270, Train loss:  0.164 Test loss:  1.689 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8280, Train loss: -0.149 Test loss:  3.517 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8290, Train loss: -0.133 Test loss:  3.056 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8300, Train loss:  0.245 Test loss:  1.600 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8310, Train loss:  0.327 Test loss:  1.346 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8320, Train loss:  0.213 Test loss:  1.321 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8330, Train loss: -0.189 Test loss:  2.544 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8340, Train loss: -0.118 Test loss:  3.171 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8350, Train loss:  0.543 Test loss:  1.169 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8360, Train loss: -0.167 Test loss:  3.031 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8370, Train loss: -0.170 Test loss:  3.427 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8380, Train loss: -0.014 Test loss:  3.207 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8390, Train loss: -0.189 Test loss:  3.115 Ensemble loss:  0.383 RMSE: 0.964 Num. networks: 26\n",
            "Epoch: 8400, Train loss: -0.031 Test loss:  3.018 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8410, Train loss:  0.684 Test loss:  0.847 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8420, Train loss:  0.018 Test loss:  2.157 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8430, Train loss: -0.128 Test loss:  3.326 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8440, Train loss: -0.186 Test loss:  3.868 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8450, Train loss: -0.145 Test loss:  3.598 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8460, Train loss: -0.046 Test loss:  3.027 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8470, Train loss: -0.113 Test loss:  2.950 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8480, Train loss:  0.166 Test loss:  1.277 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8490, Train loss: -0.167 Test loss:  2.562 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8500, Train loss:  0.158 Test loss:  2.372 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8510, Train loss: -0.152 Test loss:  2.380 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8520, Train loss:  0.238 Test loss:  1.267 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8530, Train loss:  0.053 Test loss:  1.629 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8540, Train loss: -0.136 Test loss:  1.765 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8550, Train loss:  0.171 Test loss:  1.224 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8560, Train loss: -0.197 Test loss:  2.274 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8570, Train loss: -0.191 Test loss:  2.638 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8580, Train loss:  0.337 Test loss:  1.417 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8590, Train loss: -0.137 Test loss:  3.618 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8600, Train loss:  0.506 Test loss:  0.969 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8610, Train loss: -0.161 Test loss:  2.337 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8620, Train loss:  0.244 Test loss:  2.690 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8630, Train loss:  0.542 Test loss:  1.003 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8640, Train loss:  0.051 Test loss:  1.630 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8650, Train loss: -0.172 Test loss:  2.013 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8660, Train loss: -0.181 Test loss:  2.918 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8670, Train loss: -0.171 Test loss:  2.601 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8680, Train loss:  0.140 Test loss:  1.859 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8690, Train loss: -0.165 Test loss:  3.214 Ensemble loss:  0.383 RMSE: 0.963 Num. networks: 27\n",
            "Epoch: 8700, Train loss: -0.127 Test loss:  2.293 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8710, Train loss: -0.137 Test loss:  2.515 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8720, Train loss: -0.077 Test loss:  2.315 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8730, Train loss:  0.001 Test loss:  2.647 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8740, Train loss:  0.055 Test loss:  1.662 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8750, Train loss: -0.051 Test loss:  3.422 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8760, Train loss: -0.140 Test loss:  3.023 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8770, Train loss: -0.153 Test loss:  2.839 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8780, Train loss: -0.012 Test loss:  1.891 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8790, Train loss:  0.012 Test loss:  1.405 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8800, Train loss: -0.173 Test loss:  2.740 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8810, Train loss:  0.236 Test loss:  1.294 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8820, Train loss:  0.156 Test loss:  1.490 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8830, Train loss: -0.145 Test loss:  2.778 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8840, Train loss: -0.174 Test loss:  2.757 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8850, Train loss: -0.169 Test loss:  2.550 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8860, Train loss: -0.190 Test loss:  3.005 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8870, Train loss: -0.163 Test loss:  4.718 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8880, Train loss:  0.189 Test loss:  2.563 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8890, Train loss:  0.316 Test loss:  1.255 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8900, Train loss:  0.194 Test loss:  1.303 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8910, Train loss:  0.196 Test loss:  1.192 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8920, Train loss:  0.189 Test loss:  1.566 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8930, Train loss: -0.026 Test loss:  2.002 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8940, Train loss: -0.174 Test loss:  3.396 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8950, Train loss:  0.392 Test loss:  0.877 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8960, Train loss:  0.085 Test loss:  1.586 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8970, Train loss: -0.177 Test loss:  3.942 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8980, Train loss:  0.704 Test loss:  1.416 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 8990, Train loss:  0.059 Test loss:  2.697 Ensemble loss:  0.382 RMSE: 0.961 Num. networks: 28\n",
            "Epoch: 9000, Train loss: -0.173 Test loss:  3.975 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9010, Train loss: -0.140 Test loss:  2.528 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9020, Train loss:  0.077 Test loss:  1.433 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9030, Train loss: -0.163 Test loss:  3.413 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9040, Train loss: -0.160 Test loss:  2.380 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9050, Train loss: -0.165 Test loss:  3.217 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9060, Train loss:  0.510 Test loss:  1.710 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9070, Train loss:  0.149 Test loss:  1.644 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9080, Train loss:  0.581 Test loss:  1.100 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9090, Train loss:  0.266 Test loss:  3.144 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9100, Train loss: -0.205 Test loss:  4.104 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9110, Train loss: -0.201 Test loss:  3.018 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9120, Train loss: -0.170 Test loss:  3.931 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9130, Train loss: -0.025 Test loss:  3.527 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9140, Train loss:  0.029 Test loss:  1.916 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9150, Train loss:  0.022 Test loss:  1.823 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9160, Train loss: -0.119 Test loss:  2.906 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9170, Train loss: -0.186 Test loss:  3.836 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9180, Train loss:  0.079 Test loss:  2.432 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9190, Train loss: -0.125 Test loss:  5.004 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9200, Train loss:  0.226 Test loss:  0.956 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9210, Train loss: -0.148 Test loss:  2.500 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9220, Train loss: -0.130 Test loss:  3.407 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9230, Train loss: -0.149 Test loss:  4.423 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9240, Train loss:  0.001 Test loss:  5.119 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9250, Train loss:  0.089 Test loss:  3.484 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9260, Train loss: -0.108 Test loss:  3.175 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9270, Train loss: -0.050 Test loss:  4.366 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9280, Train loss: -0.180 Test loss:  3.636 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9290, Train loss: -0.195 Test loss:  5.929 Ensemble loss:  0.377 RMSE: 0.957 Num. networks: 29\n",
            "Epoch: 9300, Train loss: -0.151 Test loss:  6.276 Ensemble loss:  0.372 RMSE: 0.953 Num. networks: 30\n",
            "Epoch: 9310, Train loss:  0.009 Test loss:  2.477 Ensemble loss:  0.372 RMSE: 0.953 Num. networks: 30\n",
            "Epoch: 9320, Train loss: -0.093 Test loss:  4.117 Ensemble loss:  0.372 RMSE: 0.953 Num. networks: 30\n",
            "Epoch: 9330, Train loss:  0.277 Test loss:  1.421 Ensemble loss:  0.372 RMSE: 0.953 Num. networks: 30\n",
            "Epoch: 9340, Train loss: -0.157 Test loss:  3.155 Ensemble loss:  0.372 RMSE: 0.953 Num. networks: 30\n",
            "Epoch: 9350, Train loss: -0.061 Test loss:  1.989 Ensemble loss:  0.372 RMSE: 0.953 Num. networks: 30\n",
            "FOLD 6:\n",
            "Epoch:    0, Train loss: 18.295 Test loss: 15.403 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   10, Train loss:  4.883 Test loss:  5.242 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   20, Train loss:  3.385 Test loss:  3.687 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   30, Train loss:  2.845 Test loss:  3.067 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   40, Train loss:  2.577 Test loss:  2.775 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   50, Train loss:  2.461 Test loss:  2.649 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   60, Train loss:  2.386 Test loss:  2.547 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   70, Train loss:  2.327 Test loss:  2.460 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   80, Train loss:  2.292 Test loss:  2.417 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   90, Train loss:  2.275 Test loss:  2.389 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  100, Train loss:  2.265 Test loss:  2.381 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  110, Train loss:  2.242 Test loss:  2.346 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  120, Train loss:  2.239 Test loss:  2.336 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  130, Train loss:  2.238 Test loss:  2.332 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  140, Train loss:  2.236 Test loss:  2.326 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  150, Train loss:  2.232 Test loss:  2.323 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  160, Train loss:  2.226 Test loss:  2.314 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  170, Train loss:  2.219 Test loss:  2.302 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  180, Train loss:  2.213 Test loss:  2.298 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  190, Train loss:  2.208 Test loss:  2.295 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  200, Train loss:  2.210 Test loss:  2.294 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  210, Train loss:  2.206 Test loss:  2.292 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  220, Train loss:  2.202 Test loss:  2.287 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  230, Train loss:  2.193 Test loss:  2.272 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  240, Train loss:  2.181 Test loss:  2.264 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  250, Train loss:  2.171 Test loss:  2.259 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  260, Train loss:  2.171 Test loss:  2.263 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  270, Train loss:  2.169 Test loss:  2.266 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  280, Train loss:  2.161 Test loss:  2.259 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  290, Train loss:  2.150 Test loss:  2.251 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  300, Train loss:  2.139 Test loss:  2.235 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  310, Train loss:  2.131 Test loss:  2.223 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  320, Train loss:  2.115 Test loss:  2.207 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  330, Train loss:  2.092 Test loss:  2.188 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  340, Train loss:  2.074 Test loss:  2.179 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  350, Train loss:  2.060 Test loss:  2.161 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  360, Train loss:  2.052 Test loss:  2.145 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  370, Train loss:  2.015 Test loss:  2.129 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  380, Train loss:  2.004 Test loss:  2.113 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  390, Train loss:  1.968 Test loss:  2.084 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  400, Train loss:  1.943 Test loss:  2.063 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  410, Train loss:  1.910 Test loss:  2.032 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  420, Train loss:  1.859 Test loss:  1.980 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  430, Train loss:  1.788 Test loss:  1.911 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  440, Train loss:  1.703 Test loss:  1.839 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  450, Train loss:  1.612 Test loss:  1.768 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  460, Train loss:  1.464 Test loss:  1.605 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  470, Train loss:  1.176 Test loss:  1.318 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  480, Train loss:  1.026 Test loss:  1.075 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  490, Train loss:  0.922 Test loss:  0.947 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  500, Train loss:  0.850 Test loss:  0.864 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  510, Train loss:  0.765 Test loss:  0.800 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  520, Train loss:  0.714 Test loss:  0.785 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  530, Train loss:  0.686 Test loss:  0.741 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  540, Train loss:  0.641 Test loss:  0.652 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  550, Train loss:  0.602 Test loss:  0.657 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  560, Train loss:  0.563 Test loss:  0.623 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  570, Train loss:  0.549 Test loss:  0.614 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  580, Train loss:  0.530 Test loss:  0.598 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  590, Train loss:  0.515 Test loss:  0.599 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  600, Train loss:  0.502 Test loss:  0.602 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  610, Train loss:  0.465 Test loss:  0.545 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  620, Train loss:  0.459 Test loss:  0.548 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  630, Train loss:  0.439 Test loss:  0.521 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  640, Train loss:  0.408 Test loss:  0.522 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  650, Train loss:  0.396 Test loss:  0.497 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  660, Train loss:  0.376 Test loss:  0.430 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  670, Train loss:  0.367 Test loss:  0.438 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  680, Train loss:  0.370 Test loss:  0.458 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  690, Train loss:  0.359 Test loss:  0.480 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  700, Train loss:  0.344 Test loss:  0.509 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  710, Train loss:  0.332 Test loss:  0.506 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  720, Train loss:  0.320 Test loss:  0.516 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  730, Train loss:  0.304 Test loss:  0.479 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  740, Train loss:  0.287 Test loss:  0.511 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  750, Train loss:  0.270 Test loss:  0.490 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  760, Train loss:  0.268 Test loss:  0.572 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  770, Train loss:  0.257 Test loss:  0.511 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  780, Train loss:  0.246 Test loss:  0.522 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  790, Train loss:  0.244 Test loss:  0.509 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  800, Train loss:  0.227 Test loss:  0.465 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  810, Train loss:  0.214 Test loss:  0.465 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  820, Train loss:  0.218 Test loss:  0.467 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  830, Train loss:  0.201 Test loss:  0.498 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  840, Train loss:  0.190 Test loss:  0.484 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  850, Train loss:  0.186 Test loss:  0.504 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  860, Train loss:  0.180 Test loss:  0.468 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  870, Train loss:  0.164 Test loss:  0.476 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  880, Train loss:  0.169 Test loss:  0.513 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  890, Train loss:  0.162 Test loss:  0.434 Ensemble loss:    nan RMSE: 1.316 Num. networks:  1\n",
            "Epoch:  900, Train loss:  0.147 Test loss:  0.398 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  910, Train loss:  0.154 Test loss:  0.426 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  920, Train loss:  0.161 Test loss:  0.401 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  930, Train loss:  0.152 Test loss:  0.384 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  940, Train loss:  0.162 Test loss:  0.403 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  950, Train loss:  0.149 Test loss:  0.461 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  960, Train loss:  0.145 Test loss:  0.443 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  970, Train loss:  0.139 Test loss:  0.451 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  980, Train loss:  0.142 Test loss:  0.469 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch:  990, Train loss:  0.140 Test loss:  0.460 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1000, Train loss:  0.128 Test loss:  0.464 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1010, Train loss:  0.119 Test loss:  0.582 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1020, Train loss:  0.113 Test loss:  0.532 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1030, Train loss:  0.110 Test loss:  0.497 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1040, Train loss:  0.096 Test loss:  0.575 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1050, Train loss:  0.099 Test loss:  0.532 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1060, Train loss:  0.089 Test loss:  0.659 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1070, Train loss:  0.083 Test loss:  0.663 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1080, Train loss:  0.075 Test loss:  0.648 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1090, Train loss:  0.074 Test loss:  0.618 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1100, Train loss:  0.068 Test loss:  0.590 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1110, Train loss:  0.058 Test loss:  0.566 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1120, Train loss:  0.051 Test loss:  0.465 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1130, Train loss:  0.045 Test loss:  0.450 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1140, Train loss:  0.052 Test loss:  0.536 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1150, Train loss:  0.025 Test loss:  0.445 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1160, Train loss:  0.204 Test loss:  0.481 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1170, Train loss:  0.029 Test loss:  0.401 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1180, Train loss:  0.102 Test loss:  0.371 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1190, Train loss:  0.058 Test loss:  0.435 Ensemble loss:  0.460 RMSE: 1.079 Num. networks:  2\n",
            "Epoch: 1200, Train loss:  0.052 Test loss:  0.418 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1210, Train loss:  0.067 Test loss:  0.480 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1220, Train loss:  0.100 Test loss:  0.463 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1230, Train loss:  0.011 Test loss:  0.459 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1240, Train loss:  0.030 Test loss:  0.503 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1250, Train loss:  0.103 Test loss:  0.588 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1260, Train loss:  0.084 Test loss:  0.539 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1270, Train loss:  0.063 Test loss:  0.674 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1280, Train loss:  0.069 Test loss:  0.802 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1290, Train loss:  0.020 Test loss:  0.725 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1300, Train loss:  0.112 Test loss:  0.730 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1310, Train loss:  0.140 Test loss:  0.616 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1320, Train loss:  0.013 Test loss:  0.723 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1330, Train loss:  0.068 Test loss:  0.651 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1340, Train loss:  0.048 Test loss:  0.705 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1350, Train loss:  0.038 Test loss:  0.667 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1360, Train loss:  0.094 Test loss:  0.571 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1370, Train loss:  0.068 Test loss:  0.644 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1380, Train loss:  0.044 Test loss:  0.640 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1390, Train loss:  0.136 Test loss:  0.724 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1400, Train loss:  0.055 Test loss:  0.794 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1410, Train loss:  0.015 Test loss:  0.758 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1420, Train loss: -0.003 Test loss:  0.709 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1430, Train loss:  0.057 Test loss:  0.749 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1440, Train loss:  0.085 Test loss:  0.959 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1450, Train loss: -0.028 Test loss:  1.117 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1460, Train loss:  0.034 Test loss:  1.105 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1470, Train loss:  0.208 Test loss:  0.665 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1480, Train loss:  0.003 Test loss:  1.133 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1490, Train loss:  0.204 Test loss:  0.921 Ensemble loss:  0.385 RMSE: 0.996 Num. networks:  3\n",
            "Epoch: 1500, Train loss:  0.051 Test loss:  0.640 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1510, Train loss:  0.333 Test loss:  0.786 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1520, Train loss: -0.024 Test loss:  1.199 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1530, Train loss: -0.022 Test loss:  1.015 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1540, Train loss:  0.232 Test loss:  0.632 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1550, Train loss:  0.068 Test loss:  0.820 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1560, Train loss:  0.195 Test loss:  0.695 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1570, Train loss: -0.017 Test loss:  0.914 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1580, Train loss:  0.236 Test loss:  0.474 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1590, Train loss:  0.057 Test loss:  0.654 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1600, Train loss: -0.016 Test loss:  0.824 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1610, Train loss:  0.005 Test loss:  0.764 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1620, Train loss: -0.027 Test loss:  0.685 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1630, Train loss: -0.013 Test loss:  0.846 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1640, Train loss:  0.188 Test loss:  0.637 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1650, Train loss:  0.184 Test loss:  0.704 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1660, Train loss:  0.385 Test loss:  0.523 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1670, Train loss: -0.023 Test loss:  0.676 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1680, Train loss:  0.046 Test loss:  0.756 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1690, Train loss:  0.008 Test loss:  0.517 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1700, Train loss: -0.016 Test loss:  0.564 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1710, Train loss:  0.046 Test loss:  0.390 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1720, Train loss:  0.010 Test loss:  0.475 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1730, Train loss:  0.180 Test loss:  0.447 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1740, Train loss: -0.019 Test loss:  0.629 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1750, Train loss:  0.055 Test loss:  0.714 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1760, Train loss: -0.051 Test loss:  0.748 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1770, Train loss: -0.035 Test loss:  0.768 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1780, Train loss: -0.036 Test loss:  0.702 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1790, Train loss: -0.065 Test loss:  0.657 Ensemble loss:  0.341 RMSE: 0.941 Num. networks:  4\n",
            "Epoch: 1800, Train loss: -0.020 Test loss:  0.704 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1810, Train loss: -0.046 Test loss:  0.637 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1820, Train loss:  0.057 Test loss:  0.869 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1830, Train loss:  0.003 Test loss:  1.143 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1840, Train loss: -0.066 Test loss:  0.874 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1850, Train loss:  0.004 Test loss:  0.622 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1860, Train loss: -0.046 Test loss:  0.845 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1870, Train loss:  0.231 Test loss:  0.438 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1880, Train loss: -0.047 Test loss:  0.592 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1890, Train loss: -0.020 Test loss:  0.736 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1900, Train loss:  0.271 Test loss:  1.034 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1910, Train loss: -0.089 Test loss:  0.808 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1920, Train loss: -0.037 Test loss:  0.781 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1930, Train loss: -0.085 Test loss:  1.055 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1940, Train loss: -0.012 Test loss:  0.969 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1950, Train loss:  0.196 Test loss:  0.733 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1960, Train loss: -0.083 Test loss:  1.036 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1970, Train loss: -0.048 Test loss:  1.444 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1980, Train loss:  0.299 Test loss:  0.814 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 1990, Train loss: -0.050 Test loss:  0.744 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2000, Train loss:  0.180 Test loss:  0.982 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2010, Train loss:  0.001 Test loss:  0.687 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2020, Train loss: -0.097 Test loss:  0.838 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2030, Train loss: -0.080 Test loss:  0.924 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2040, Train loss: -0.029 Test loss:  0.837 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2050, Train loss:  0.036 Test loss:  0.854 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2060, Train loss:  0.083 Test loss:  0.905 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2070, Train loss:  0.065 Test loss:  0.825 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2080, Train loss: -0.031 Test loss:  0.856 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2090, Train loss: -0.057 Test loss:  0.877 Ensemble loss:  0.322 RMSE: 0.918 Num. networks:  5\n",
            "Epoch: 2100, Train loss:  0.017 Test loss:  1.056 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2110, Train loss:  0.382 Test loss:  0.518 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2120, Train loss:  0.108 Test loss:  0.649 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2130, Train loss: -0.028 Test loss:  0.693 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2140, Train loss:  0.016 Test loss:  0.739 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2150, Train loss: -0.073 Test loss:  0.843 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2160, Train loss:  0.006 Test loss:  0.688 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2170, Train loss:  0.034 Test loss:  0.651 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2180, Train loss: -0.012 Test loss:  0.569 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2190, Train loss: -0.017 Test loss:  0.707 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2200, Train loss: -0.051 Test loss:  0.699 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2210, Train loss:  0.026 Test loss:  0.690 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2220, Train loss: -0.044 Test loss:  0.750 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2230, Train loss:  0.146 Test loss:  0.596 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2240, Train loss:  0.006 Test loss:  0.771 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2250, Train loss:  0.076 Test loss:  0.737 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2260, Train loss:  0.027 Test loss:  0.778 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2270, Train loss:  0.055 Test loss:  0.693 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2280, Train loss:  0.116 Test loss:  0.825 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2290, Train loss: -0.072 Test loss:  1.262 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2300, Train loss:  0.279 Test loss:  0.767 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2310, Train loss: -0.069 Test loss:  1.066 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2320, Train loss: -0.043 Test loss:  1.514 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2330, Train loss:  0.127 Test loss:  1.245 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2340, Train loss:  0.012 Test loss:  1.277 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2350, Train loss:  0.032 Test loss:  1.651 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2360, Train loss: -0.017 Test loss:  1.750 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2370, Train loss: -0.019 Test loss:  1.561 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2380, Train loss:  0.060 Test loss:  1.422 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2390, Train loss:  0.045 Test loss:  1.321 Ensemble loss:  0.291 RMSE: 0.873 Num. networks:  6\n",
            "Epoch: 2400, Train loss:  0.184 Test loss:  1.092 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2410, Train loss:  0.275 Test loss:  0.953 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2420, Train loss: -0.097 Test loss:  1.238 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2430, Train loss:  0.308 Test loss:  0.864 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2440, Train loss:  0.144 Test loss:  1.862 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2450, Train loss:  0.155 Test loss:  0.975 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2460, Train loss: -0.100 Test loss:  1.396 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2470, Train loss:  0.276 Test loss:  1.783 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2480, Train loss:  0.187 Test loss:  1.022 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2490, Train loss: -0.065 Test loss:  1.665 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2500, Train loss: -0.110 Test loss:  2.048 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2510, Train loss:  0.122 Test loss:  1.110 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2520, Train loss: -0.078 Test loss:  2.507 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2530, Train loss: -0.103 Test loss:  1.507 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2540, Train loss: -0.102 Test loss:  2.140 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2550, Train loss: -0.077 Test loss:  2.340 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2560, Train loss:  0.199 Test loss:  1.040 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2570, Train loss: -0.082 Test loss:  1.782 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2580, Train loss: -0.095 Test loss:  2.168 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2590, Train loss:  0.203 Test loss:  0.966 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2600, Train loss:  0.475 Test loss:  0.665 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2610, Train loss:  0.228 Test loss:  1.780 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2620, Train loss: -0.053 Test loss:  1.273 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2630, Train loss: -0.044 Test loss:  1.462 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2640, Train loss:  0.125 Test loss:  1.102 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2650, Train loss:  0.052 Test loss:  1.262 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2660, Train loss: -0.042 Test loss:  1.331 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2670, Train loss:  0.364 Test loss:  2.219 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2680, Train loss: -0.070 Test loss:  2.431 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2690, Train loss: -0.068 Test loss:  1.466 Ensemble loss:  0.280 RMSE: 0.851 Num. networks:  7\n",
            "Epoch: 2700, Train loss: -0.013 Test loss:  1.297 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2710, Train loss: -0.073 Test loss:  1.911 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2720, Train loss:  0.027 Test loss:  1.436 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2730, Train loss: -0.063 Test loss:  1.823 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2740, Train loss:  0.073 Test loss:  1.281 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2750, Train loss: -0.074 Test loss:  2.031 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2760, Train loss:  0.207 Test loss:  1.115 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2770, Train loss: -0.103 Test loss:  1.517 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2780, Train loss: -0.032 Test loss:  2.295 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2790, Train loss: -0.143 Test loss:  1.457 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2800, Train loss: -0.137 Test loss:  1.272 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2810, Train loss: -0.012 Test loss:  1.865 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2820, Train loss:  0.063 Test loss:  0.766 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2830, Train loss: -0.134 Test loss:  1.259 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2840, Train loss: -0.114 Test loss:  1.223 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2850, Train loss: -0.131 Test loss:  0.887 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2860, Train loss: -0.088 Test loss:  1.066 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2870, Train loss:  0.004 Test loss:  1.143 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2880, Train loss:  0.329 Test loss:  0.668 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2890, Train loss: -0.018 Test loss:  0.632 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2900, Train loss: -0.127 Test loss:  0.730 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2910, Train loss:  0.150 Test loss:  0.574 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2920, Train loss: -0.097 Test loss:  0.867 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2930, Train loss:  0.046 Test loss:  0.585 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2940, Train loss: -0.088 Test loss:  0.770 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2950, Train loss:  0.147 Test loss:  0.541 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2960, Train loss:  0.122 Test loss:  0.456 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2970, Train loss:  0.006 Test loss:  0.558 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2980, Train loss:  0.049 Test loss:  0.597 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 2990, Train loss: -0.036 Test loss:  0.912 Ensemble loss:  0.285 RMSE: 0.849 Num. networks:  8\n",
            "Epoch: 3000, Train loss:  0.168 Test loss:  0.729 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3010, Train loss:  0.107 Test loss:  0.797 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3020, Train loss: -0.042 Test loss:  0.802 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3030, Train loss:  0.120 Test loss:  0.640 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3040, Train loss: -0.061 Test loss:  0.920 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3050, Train loss:  0.013 Test loss:  0.949 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3060, Train loss:  0.244 Test loss:  0.600 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3070, Train loss: -0.062 Test loss:  0.837 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3080, Train loss:  0.070 Test loss:  0.696 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3090, Train loss: -0.015 Test loss:  0.909 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3100, Train loss: -0.009 Test loss:  0.861 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3110, Train loss: -0.013 Test loss:  0.954 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3120, Train loss: -0.103 Test loss:  1.150 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3130, Train loss:  0.263 Test loss:  0.760 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3140, Train loss: -0.100 Test loss:  1.143 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3150, Train loss: -0.066 Test loss:  0.829 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3160, Train loss:  0.056 Test loss:  0.899 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3170, Train loss: -0.083 Test loss:  1.054 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3180, Train loss: -0.065 Test loss:  0.756 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3190, Train loss:  0.126 Test loss:  0.758 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3200, Train loss: -0.127 Test loss:  0.959 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3210, Train loss:  0.063 Test loss:  0.724 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3220, Train loss: -0.032 Test loss:  0.816 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3230, Train loss:  0.042 Test loss:  0.758 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3240, Train loss:  0.152 Test loss:  0.739 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3250, Train loss: -0.047 Test loss:  1.089 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3260, Train loss: -0.068 Test loss:  1.275 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3270, Train loss:  0.064 Test loss:  1.036 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3280, Train loss:  0.111 Test loss:  0.750 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3290, Train loss: -0.013 Test loss:  0.859 Ensemble loss:  0.283 RMSE: 0.835 Num. networks:  9\n",
            "Epoch: 3300, Train loss: -0.060 Test loss:  1.246 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3310, Train loss: -0.036 Test loss:  1.200 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3320, Train loss:  0.003 Test loss:  0.965 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3330, Train loss:  0.068 Test loss:  1.044 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3340, Train loss:  0.059 Test loss:  1.086 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3350, Train loss: -0.116 Test loss:  1.395 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3360, Train loss:  0.035 Test loss:  1.137 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3370, Train loss: -0.077 Test loss:  1.319 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3380, Train loss:  0.150 Test loss:  0.852 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3390, Train loss: -0.139 Test loss:  1.452 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3400, Train loss: -0.040 Test loss:  1.649 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3410, Train loss:  0.349 Test loss:  1.419 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3420, Train loss: -0.115 Test loss:  1.652 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3430, Train loss:  0.669 Test loss:  0.854 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3440, Train loss: -0.161 Test loss:  1.613 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3450, Train loss: -0.083 Test loss:  1.682 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3460, Train loss: -0.008 Test loss:  2.062 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3470, Train loss:  0.009 Test loss:  1.874 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3480, Train loss: -0.037 Test loss:  1.952 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3490, Train loss: -0.132 Test loss:  2.914 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3500, Train loss: -0.052 Test loss:  1.738 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3510, Train loss:  0.040 Test loss:  1.427 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3520, Train loss:  0.217 Test loss:  1.191 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3530, Train loss: -0.121 Test loss:  2.556 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3540, Train loss: -0.013 Test loss:  2.183 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3550, Train loss: -0.159 Test loss:  2.477 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3560, Train loss: -0.135 Test loss:  3.132 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3570, Train loss: -0.009 Test loss:  2.361 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3580, Train loss:  0.019 Test loss:  2.086 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3590, Train loss:  0.036 Test loss:  1.596 Ensemble loss:  0.275 RMSE: 0.831 Num. networks: 10\n",
            "Epoch: 3600, Train loss: -0.020 Test loss:  1.159 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3610, Train loss: -0.072 Test loss:  1.595 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3620, Train loss:  0.060 Test loss:  1.351 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3630, Train loss:  0.176 Test loss:  1.981 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3640, Train loss:  0.002 Test loss:  2.293 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3650, Train loss: -0.131 Test loss:  3.335 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3660, Train loss:  0.044 Test loss:  3.110 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3670, Train loss:  0.082 Test loss:  1.489 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3680, Train loss: -0.167 Test loss:  2.309 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3690, Train loss: -0.066 Test loss:  3.689 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3700, Train loss:  0.130 Test loss:  2.102 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3710, Train loss:  0.195 Test loss:  1.323 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3720, Train loss:  0.008 Test loss:  1.604 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3730, Train loss: -0.154 Test loss:  2.385 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3740, Train loss: -0.161 Test loss:  2.460 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3750, Train loss: -0.169 Test loss:  2.255 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3760, Train loss: -0.154 Test loss:  1.931 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3770, Train loss: -0.167 Test loss:  2.015 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3780, Train loss:  0.382 Test loss:  0.862 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3790, Train loss: -0.134 Test loss:  1.950 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3800, Train loss: -0.092 Test loss:  1.455 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3810, Train loss: -0.125 Test loss:  1.521 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3820, Train loss:  0.041 Test loss:  1.189 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3830, Train loss: -0.167 Test loss:  1.977 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3840, Train loss: -0.163 Test loss:  2.028 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3850, Train loss: -0.109 Test loss:  1.915 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3860, Train loss:  0.229 Test loss:  1.109 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3870, Train loss: -0.071 Test loss:  1.695 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3880, Train loss: -0.054 Test loss:  1.891 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3890, Train loss: -0.076 Test loss:  1.829 Ensemble loss:  0.292 RMSE: 0.844 Num. networks: 11\n",
            "Epoch: 3900, Train loss: -0.111 Test loss:  2.474 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3910, Train loss: -0.089 Test loss:  2.375 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3920, Train loss: -0.082 Test loss:  2.537 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3930, Train loss: -0.132 Test loss:  2.887 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3940, Train loss: -0.129 Test loss:  3.165 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3950, Train loss:  0.251 Test loss:  1.476 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3960, Train loss:  0.059 Test loss:  2.225 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3970, Train loss: -0.128 Test loss:  3.342 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3980, Train loss: -0.090 Test loss:  3.254 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 3990, Train loss: -0.094 Test loss:  4.095 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4000, Train loss:  0.196 Test loss:  2.305 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4010, Train loss: -0.092 Test loss:  4.559 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4020, Train loss:  0.063 Test loss:  2.343 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4030, Train loss:  0.071 Test loss:  2.407 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4040, Train loss: -0.112 Test loss:  3.377 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4050, Train loss: -0.121 Test loss:  3.062 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4060, Train loss: -0.142 Test loss:  4.091 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4070, Train loss:  0.148 Test loss:  3.102 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4080, Train loss:  0.062 Test loss:  1.761 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4090, Train loss: -0.023 Test loss:  3.578 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4100, Train loss: -0.014 Test loss:  3.311 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4110, Train loss: -0.158 Test loss:  3.178 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4120, Train loss:  0.038 Test loss:  2.615 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4130, Train loss: -0.094 Test loss:  3.513 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4140, Train loss: -0.130 Test loss:  4.040 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4150, Train loss:  0.177 Test loss:  2.084 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4160, Train loss: -0.082 Test loss:  2.668 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4170, Train loss:  0.205 Test loss:  1.643 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4180, Train loss: -0.095 Test loss:  2.721 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4190, Train loss: -0.043 Test loss:  3.193 Ensemble loss:  0.298 RMSE: 0.858 Num. networks: 12\n",
            "Epoch: 4200, Train loss: -0.048 Test loss:  2.570 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4210, Train loss:  0.042 Test loss:  2.281 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4220, Train loss:  0.118 Test loss:  1.789 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4230, Train loss: -0.129 Test loss:  2.850 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4240, Train loss: -0.172 Test loss:  4.091 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4250, Train loss:  0.111 Test loss:  2.172 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4260, Train loss: -0.127 Test loss:  3.104 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4270, Train loss:  0.179 Test loss:  2.923 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4280, Train loss: -0.101 Test loss:  2.950 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4290, Train loss:  0.101 Test loss:  1.758 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4300, Train loss:  0.182 Test loss:  1.527 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4310, Train loss: -0.070 Test loss:  2.939 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4320, Train loss:  0.125 Test loss:  1.544 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4330, Train loss: -0.079 Test loss:  2.853 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4340, Train loss:  0.151 Test loss:  1.991 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4350, Train loss: -0.063 Test loss:  3.074 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4360, Train loss:  0.091 Test loss:  2.703 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4370, Train loss:  0.010 Test loss:  2.193 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4380, Train loss: -0.152 Test loss:  2.934 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4390, Train loss: -0.149 Test loss:  2.671 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4400, Train loss: -0.156 Test loss:  2.693 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4410, Train loss:  0.089 Test loss:  2.757 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4420, Train loss:  0.107 Test loss:  2.166 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4430, Train loss: -0.065 Test loss:  2.559 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4440, Train loss: -0.017 Test loss:  2.676 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4450, Train loss:  0.032 Test loss:  2.933 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4460, Train loss:  0.071 Test loss:  2.170 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4470, Train loss: -0.136 Test loss:  3.042 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4480, Train loss: -0.122 Test loss:  2.824 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4490, Train loss:  0.004 Test loss:  3.687 Ensemble loss:  0.310 RMSE: 0.871 Num. networks: 13\n",
            "Epoch: 4500, Train loss:  0.211 Test loss:  2.181 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4510, Train loss: -0.106 Test loss:  3.167 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4520, Train loss:  0.316 Test loss:  2.335 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4530, Train loss:  0.082 Test loss:  1.675 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4540, Train loss: -0.140 Test loss:  2.990 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4550, Train loss: -0.141 Test loss:  2.577 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4560, Train loss: -0.058 Test loss:  2.507 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4570, Train loss: -0.127 Test loss:  1.729 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4580, Train loss:  0.226 Test loss:  0.967 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4590, Train loss:  0.580 Test loss:  0.955 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4600, Train loss:  0.076 Test loss:  1.303 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4610, Train loss: -0.041 Test loss:  2.357 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4620, Train loss: -0.022 Test loss:  2.102 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4630, Train loss:  0.072 Test loss:  1.572 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4640, Train loss: -0.153 Test loss:  1.900 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4650, Train loss: -0.136 Test loss:  2.278 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4660, Train loss: -0.033 Test loss:  2.826 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4670, Train loss:  0.246 Test loss:  0.934 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4680, Train loss:  0.181 Test loss:  2.325 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4690, Train loss:  0.131 Test loss:  1.936 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4700, Train loss: -0.143 Test loss:  1.630 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4710, Train loss:  0.217 Test loss:  1.070 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4720, Train loss:  0.081 Test loss:  1.170 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4730, Train loss:  0.283 Test loss:  1.022 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4740, Train loss: -0.087 Test loss:  1.434 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4750, Train loss:  0.005 Test loss:  1.338 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4760, Train loss: -0.036 Test loss:  1.552 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4770, Train loss: -0.142 Test loss:  2.509 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4780, Train loss: -0.069 Test loss:  1.476 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4790, Train loss:  0.141 Test loss:  1.126 Ensemble loss:  0.339 RMSE: 0.888 Num. networks: 14\n",
            "Epoch: 4800, Train loss: -0.113 Test loss:  1.962 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4810, Train loss: -0.159 Test loss:  2.549 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4820, Train loss:  0.225 Test loss:  1.134 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4830, Train loss: -0.108 Test loss:  1.564 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4840, Train loss: -0.087 Test loss:  1.619 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4850, Train loss:  0.547 Test loss:  1.682 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4860, Train loss: -0.147 Test loss:  2.368 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4870, Train loss:  0.056 Test loss:  2.891 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4880, Train loss:  0.127 Test loss:  1.070 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4890, Train loss:  0.050 Test loss:  1.146 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4900, Train loss: -0.163 Test loss:  2.014 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4910, Train loss: -0.181 Test loss:  1.784 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4920, Train loss: -0.029 Test loss:  1.350 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4930, Train loss:  0.279 Test loss:  0.841 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4940, Train loss:  0.005 Test loss:  1.308 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4950, Train loss: -0.178 Test loss:  2.071 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4960, Train loss: -0.004 Test loss:  2.062 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4970, Train loss: -0.134 Test loss:  2.070 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4980, Train loss: -0.183 Test loss:  1.989 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 4990, Train loss:  0.042 Test loss:  1.656 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5000, Train loss: -0.072 Test loss:  1.717 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5010, Train loss:  0.221 Test loss:  0.900 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5020, Train loss:  0.203 Test loss:  0.832 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5030, Train loss: -0.116 Test loss:  1.396 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5040, Train loss:  0.102 Test loss:  1.230 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5050, Train loss: -0.111 Test loss:  1.559 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5060, Train loss: -0.179 Test loss:  1.494 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5070, Train loss: -0.182 Test loss:  2.022 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5080, Train loss: -0.063 Test loss:  1.511 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5090, Train loss: -0.030 Test loss:  1.271 Ensemble loss:  0.344 RMSE: 0.895 Num. networks: 15\n",
            "Epoch: 5100, Train loss:  0.032 Test loss:  1.131 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5110, Train loss:  0.070 Test loss:  1.126 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5120, Train loss: -0.017 Test loss:  1.261 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5130, Train loss:  0.415 Test loss:  0.759 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5140, Train loss:  0.189 Test loss:  1.003 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5150, Train loss: -0.040 Test loss:  1.802 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5160, Train loss: -0.177 Test loss:  2.332 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5170, Train loss: -0.155 Test loss:  2.554 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5180, Train loss: -0.151 Test loss:  3.709 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5190, Train loss:  0.006 Test loss:  3.191 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5200, Train loss:  0.229 Test loss:  0.959 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5210, Train loss:  0.049 Test loss:  1.351 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5220, Train loss: -0.118 Test loss:  2.616 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5230, Train loss: -0.119 Test loss:  2.012 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5240, Train loss: -0.104 Test loss:  1.975 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5250, Train loss: -0.091 Test loss:  2.006 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5260, Train loss: -0.058 Test loss:  2.826 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5270, Train loss: -0.139 Test loss:  1.912 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5280, Train loss:  0.045 Test loss:  1.193 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5290, Train loss: -0.095 Test loss:  1.175 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5300, Train loss: -0.033 Test loss:  1.370 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5310, Train loss: -0.015 Test loss:  1.892 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5320, Train loss:  0.119 Test loss:  1.354 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5330, Train loss: -0.066 Test loss:  1.634 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5340, Train loss: -0.093 Test loss:  1.259 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5350, Train loss: -0.147 Test loss:  1.824 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5360, Train loss: -0.174 Test loss:  1.554 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5370, Train loss: -0.180 Test loss:  1.697 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5380, Train loss: -0.163 Test loss:  1.325 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5390, Train loss: -0.091 Test loss:  1.332 Ensemble loss:  0.343 RMSE: 0.891 Num. networks: 16\n",
            "Epoch: 5400, Train loss: -0.204 Test loss:  1.340 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5410, Train loss: -0.130 Test loss:  1.361 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5420, Train loss: -0.038 Test loss:  1.164 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5430, Train loss: -0.020 Test loss:  1.384 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5440, Train loss: -0.156 Test loss:  1.611 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5450, Train loss: -0.146 Test loss:  1.439 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5460, Train loss:  0.238 Test loss:  0.891 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5470, Train loss: -0.115 Test loss:  1.501 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5480, Train loss: -0.158 Test loss:  1.697 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5490, Train loss: -0.138 Test loss:  1.924 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5500, Train loss: -0.191 Test loss:  1.895 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5510, Train loss:  0.365 Test loss:  0.942 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5520, Train loss: -0.197 Test loss:  2.094 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5530, Train loss: -0.176 Test loss:  1.718 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5540, Train loss: -0.181 Test loss:  1.903 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5550, Train loss: -0.194 Test loss:  2.041 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5560, Train loss: -0.157 Test loss:  1.385 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5570, Train loss: -0.158 Test loss:  1.538 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5580, Train loss: -0.172 Test loss:  2.051 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5590, Train loss: -0.064 Test loss:  1.672 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5600, Train loss:  0.082 Test loss:  1.643 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5610, Train loss:  0.042 Test loss:  1.545 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5620, Train loss:  0.015 Test loss:  1.294 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5630, Train loss: -0.161 Test loss:  2.070 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5640, Train loss: -0.034 Test loss:  1.955 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5650, Train loss:  0.476 Test loss:  1.535 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5660, Train loss:  0.366 Test loss:  2.347 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5670, Train loss: -0.234 Test loss:  3.468 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5680, Train loss: -0.193 Test loss:  4.108 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5690, Train loss:  0.041 Test loss:  2.718 Ensemble loss:  0.341 RMSE: 0.895 Num. networks: 17\n",
            "Epoch: 5700, Train loss: -0.014 Test loss:  3.118 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5710, Train loss:  0.415 Test loss:  1.431 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5720, Train loss:  0.064 Test loss:  1.877 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5730, Train loss: -0.134 Test loss:  2.399 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5740, Train loss: -0.037 Test loss:  1.498 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5750, Train loss: -0.156 Test loss:  2.537 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5760, Train loss:  0.008 Test loss:  1.645 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5770, Train loss:  0.199 Test loss:  1.245 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5780, Train loss:  0.069 Test loss:  1.177 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5790, Train loss: -0.181 Test loss:  2.146 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5800, Train loss: -0.189 Test loss:  2.266 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5810, Train loss: -0.193 Test loss:  2.291 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5820, Train loss: -0.183 Test loss:  2.243 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5830, Train loss:  0.237 Test loss:  1.631 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5840, Train loss: -0.031 Test loss:  1.467 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5850, Train loss:  0.499 Test loss:  0.989 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5860, Train loss:  0.116 Test loss:  1.854 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5870, Train loss: -0.150 Test loss:  2.866 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5880, Train loss: -0.164 Test loss:  3.281 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5890, Train loss: -0.119 Test loss:  2.670 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5900, Train loss: -0.145 Test loss:  2.573 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5910, Train loss: -0.123 Test loss:  2.730 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5920, Train loss:  0.015 Test loss:  1.791 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5930, Train loss:  0.053 Test loss:  1.997 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5940, Train loss:  0.045 Test loss:  1.790 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5950, Train loss: -0.023 Test loss:  2.006 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5960, Train loss: -0.093 Test loss:  1.768 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5970, Train loss: -0.010 Test loss:  1.618 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5980, Train loss:  0.282 Test loss:  0.909 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 5990, Train loss:  0.045 Test loss:  1.685 Ensemble loss:  0.347 RMSE: 0.894 Num. networks: 18\n",
            "Epoch: 6000, Train loss: -0.058 Test loss:  1.383 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6010, Train loss: -0.065 Test loss:  1.434 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6020, Train loss: -0.142 Test loss:  1.691 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6030, Train loss: -0.187 Test loss:  2.821 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6040, Train loss: -0.126 Test loss:  2.348 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6050, Train loss: -0.143 Test loss:  2.473 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6060, Train loss: -0.074 Test loss:  1.838 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6070, Train loss: -0.104 Test loss:  2.890 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6080, Train loss: -0.086 Test loss:  2.757 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6090, Train loss:  0.271 Test loss:  1.222 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6100, Train loss: -0.200 Test loss:  2.070 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6110, Train loss: -0.217 Test loss:  2.369 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6120, Train loss: -0.101 Test loss:  2.103 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6130, Train loss: -0.054 Test loss:  1.704 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6140, Train loss: -0.036 Test loss:  1.592 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6150, Train loss: -0.184 Test loss:  2.321 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6160, Train loss: -0.195 Test loss:  2.202 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6170, Train loss: -0.091 Test loss:  2.984 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6180, Train loss: -0.202 Test loss:  2.095 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6190, Train loss: -0.192 Test loss:  1.870 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6200, Train loss: -0.079 Test loss:  2.166 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6210, Train loss: -0.160 Test loss:  2.026 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6220, Train loss: -0.158 Test loss:  2.711 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6230, Train loss:  0.016 Test loss:  1.473 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6240, Train loss: -0.057 Test loss:  1.860 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6250, Train loss: -0.179 Test loss:  2.529 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6260, Train loss:  0.083 Test loss:  1.755 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6270, Train loss:  0.444 Test loss:  1.215 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6280, Train loss:  0.250 Test loss:  2.405 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6290, Train loss: -0.067 Test loss:  1.849 Ensemble loss:  0.342 RMSE: 0.893 Num. networks: 19\n",
            "Epoch: 6300, Train loss: -0.226 Test loss:  2.546 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6310, Train loss: -0.094 Test loss:  4.707 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6320, Train loss:  0.258 Test loss:  1.191 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6330, Train loss: -0.185 Test loss:  3.566 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6340, Train loss: -0.183 Test loss:  3.801 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6350, Train loss: -0.195 Test loss:  3.879 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6360, Train loss: -0.159 Test loss:  6.468 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6370, Train loss: -0.194 Test loss:  4.466 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6380, Train loss: -0.145 Test loss:  3.595 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6390, Train loss: -0.204 Test loss:  4.063 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6400, Train loss: -0.122 Test loss:  3.059 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6410, Train loss: -0.088 Test loss:  2.282 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6420, Train loss:  0.053 Test loss:  1.793 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6430, Train loss: -0.060 Test loss:  2.817 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6440, Train loss: -0.211 Test loss:  4.197 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6450, Train loss: -0.251 Test loss:  4.938 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6460, Train loss: -0.222 Test loss:  3.770 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6470, Train loss: -0.220 Test loss:  3.470 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6480, Train loss: -0.209 Test loss:  3.554 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6490, Train loss: -0.194 Test loss:  2.808 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6500, Train loss: -0.201 Test loss:  2.870 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6510, Train loss: -0.097 Test loss:  2.621 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6520, Train loss: -0.221 Test loss:  3.993 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6530, Train loss: -0.181 Test loss:  3.407 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6540, Train loss: -0.171 Test loss:  2.995 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6550, Train loss: -0.159 Test loss:  3.513 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6560, Train loss:  0.008 Test loss:  3.592 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6570, Train loss:  0.042 Test loss:  2.262 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6580, Train loss: -0.063 Test loss:  3.141 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6590, Train loss: -0.043 Test loss:  3.196 Ensemble loss:  0.343 RMSE: 0.896 Num. networks: 20\n",
            "Epoch: 6600, Train loss: -0.011 Test loss:  3.903 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6610, Train loss:  0.677 Test loss:  1.477 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6620, Train loss:  0.208 Test loss:  3.825 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6630, Train loss:  0.023 Test loss:  3.857 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6640, Train loss: -0.224 Test loss:  5.234 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6650, Train loss:  0.242 Test loss:  1.751 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6660, Train loss: -0.137 Test loss:  3.611 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6670, Train loss: -0.198 Test loss:  4.418 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6680, Train loss: -0.211 Test loss:  3.840 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6690, Train loss: -0.085 Test loss:  3.260 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6700, Train loss: -0.014 Test loss:  2.643 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6710, Train loss: -0.248 Test loss:  4.967 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6720, Train loss: -0.258 Test loss:  4.297 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6730, Train loss: -0.205 Test loss:  3.536 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6740, Train loss: -0.137 Test loss:  2.864 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6750, Train loss:  0.662 Test loss:  0.923 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6760, Train loss: -0.208 Test loss:  2.604 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6770, Train loss: -0.250 Test loss:  3.807 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6780, Train loss: -0.199 Test loss:  2.128 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6790, Train loss: -0.202 Test loss:  2.657 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6800, Train loss: -0.215 Test loss:  4.270 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6810, Train loss: -0.122 Test loss:  3.435 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6820, Train loss: -0.001 Test loss:  2.152 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6830, Train loss: -0.173 Test loss:  3.531 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6840, Train loss: -0.102 Test loss:  2.501 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6850, Train loss: -0.130 Test loss:  2.036 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6860, Train loss:  0.126 Test loss:  1.112 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6870, Train loss: -0.167 Test loss:  1.581 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6880, Train loss: -0.189 Test loss:  1.882 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6890, Train loss: -0.196 Test loss:  1.556 Ensemble loss:  0.349 RMSE: 0.910 Num. networks: 21\n",
            "Epoch: 6900, Train loss:  0.232 Test loss:  0.766 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6910, Train loss: -0.204 Test loss:  1.547 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6920, Train loss: -0.165 Test loss:  1.397 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6930, Train loss: -0.192 Test loss:  2.153 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6940, Train loss: -0.196 Test loss:  1.843 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6950, Train loss: -0.043 Test loss:  1.665 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6960, Train loss: -0.040 Test loss:  1.455 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6970, Train loss: -0.140 Test loss:  1.380 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6980, Train loss:  0.035 Test loss:  1.173 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 6990, Train loss: -0.140 Test loss:  1.657 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7000, Train loss: -0.163 Test loss:  1.756 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7010, Train loss: -0.113 Test loss:  1.401 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7020, Train loss: -0.179 Test loss:  1.525 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7030, Train loss: -0.167 Test loss:  1.580 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7040, Train loss: -0.149 Test loss:  1.672 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7050, Train loss:  0.045 Test loss:  1.501 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7060, Train loss: -0.106 Test loss:  1.360 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7070, Train loss: -0.108 Test loss:  1.401 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7080, Train loss: -0.169 Test loss:  1.738 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7090, Train loss: -0.162 Test loss:  1.770 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7100, Train loss: -0.130 Test loss:  1.771 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7110, Train loss:  0.097 Test loss:  1.423 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7120, Train loss: -0.134 Test loss:  2.147 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7130, Train loss: -0.152 Test loss:  2.499 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7140, Train loss: -0.205 Test loss:  2.543 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7150, Train loss: -0.177 Test loss:  2.499 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7160, Train loss:  0.119 Test loss:  1.925 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7170, Train loss: -0.116 Test loss:  1.987 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7180, Train loss: -0.130 Test loss:  2.604 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7190, Train loss: -0.014 Test loss:  2.222 Ensemble loss:  0.347 RMSE: 0.911 Num. networks: 22\n",
            "Epoch: 7200, Train loss: -0.166 Test loss:  2.047 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7210, Train loss: -0.143 Test loss:  1.947 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7220, Train loss:  0.100 Test loss:  1.106 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7230, Train loss:  0.049 Test loss:  1.234 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7240, Train loss: -0.192 Test loss:  1.572 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7250, Train loss: -0.209 Test loss:  1.796 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7260, Train loss: -0.185 Test loss:  2.002 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7270, Train loss:  0.078 Test loss:  2.462 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7280, Train loss:  0.339 Test loss:  0.968 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7290, Train loss: -0.119 Test loss:  1.925 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7300, Train loss: -0.110 Test loss:  1.904 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7310, Train loss:  0.103 Test loss:  1.264 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7320, Train loss: -0.147 Test loss:  1.782 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7330, Train loss: -0.204 Test loss:  2.183 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7340, Train loss: -0.148 Test loss:  2.042 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7350, Train loss: -0.201 Test loss:  2.644 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7360, Train loss: -0.203 Test loss:  2.057 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7370, Train loss:  0.157 Test loss:  1.534 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7380, Train loss: -0.145 Test loss:  1.887 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7390, Train loss: -0.177 Test loss:  2.290 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7400, Train loss: -0.205 Test loss:  3.805 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7410, Train loss: -0.149 Test loss:  4.193 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7420, Train loss:  0.141 Test loss:  2.052 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7430, Train loss: -0.181 Test loss:  3.688 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7440, Train loss: -0.201 Test loss:  3.202 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7450, Train loss: -0.214 Test loss:  2.783 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7460, Train loss:  0.017 Test loss:  2.095 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7470, Train loss: -0.206 Test loss:  2.597 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7480, Train loss: -0.192 Test loss:  2.642 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7490, Train loss: -0.158 Test loss:  2.428 Ensemble loss:  0.343 RMSE: 0.910 Num. networks: 23\n",
            "Epoch: 7500, Train loss: -0.023 Test loss:  1.992 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7510, Train loss: -0.198 Test loss:  2.590 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7520, Train loss: -0.111 Test loss:  2.328 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7530, Train loss: -0.215 Test loss:  2.825 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7540, Train loss: -0.123 Test loss:  1.670 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7550, Train loss:  0.257 Test loss:  0.734 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7560, Train loss: -0.185 Test loss:  1.414 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7570, Train loss: -0.187 Test loss:  1.646 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7580, Train loss: -0.207 Test loss:  1.599 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7590, Train loss: -0.203 Test loss:  1.603 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7600, Train loss: -0.189 Test loss:  1.471 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7610, Train loss: -0.142 Test loss:  1.408 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7620, Train loss:  0.325 Test loss:  1.115 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7630, Train loss: -0.112 Test loss:  1.412 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7640, Train loss: -0.190 Test loss:  1.680 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7650, Train loss: -0.177 Test loss:  1.173 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7660, Train loss: -0.157 Test loss:  1.197 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7670, Train loss: -0.095 Test loss:  0.989 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7680, Train loss:  0.070 Test loss:  0.721 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7690, Train loss: -0.137 Test loss:  1.154 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7700, Train loss: -0.178 Test loss:  1.419 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7710, Train loss:  0.066 Test loss:  1.058 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7720, Train loss: -0.135 Test loss:  1.376 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7730, Train loss: -0.052 Test loss:  1.236 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7740, Train loss: -0.160 Test loss:  2.076 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7750, Train loss: -0.146 Test loss:  1.655 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7760, Train loss: -0.153 Test loss:  1.418 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7770, Train loss: -0.188 Test loss:  1.674 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7780, Train loss:  0.019 Test loss:  1.573 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7790, Train loss:  0.388 Test loss:  0.907 Ensemble loss:  0.340 RMSE: 0.910 Num. networks: 24\n",
            "Epoch: 7800, Train loss:  0.209 Test loss:  0.700 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7810, Train loss:  0.115 Test loss:  0.762 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7820, Train loss: -0.173 Test loss:  1.772 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7830, Train loss: -0.034 Test loss:  1.522 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7840, Train loss: -0.146 Test loss:  1.760 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7850, Train loss: -0.193 Test loss:  2.500 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7860, Train loss:  0.192 Test loss:  1.310 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7870, Train loss:  0.059 Test loss:  1.314 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7880, Train loss: -0.181 Test loss:  2.338 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7890, Train loss: -0.189 Test loss:  2.726 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7900, Train loss: -0.164 Test loss:  3.511 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7910, Train loss: -0.208 Test loss:  5.230 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7920, Train loss: -0.168 Test loss:  4.193 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7930, Train loss: -0.192 Test loss:  3.751 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7940, Train loss:  0.323 Test loss:  1.847 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7950, Train loss:  0.121 Test loss:  2.691 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7960, Train loss:  0.114 Test loss:  2.223 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7970, Train loss:  0.274 Test loss:  0.952 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7980, Train loss: -0.156 Test loss:  3.067 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 7990, Train loss: -0.040 Test loss:  2.514 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8000, Train loss:  0.023 Test loss:  1.892 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8010, Train loss:  0.643 Test loss:  0.932 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8020, Train loss: -0.138 Test loss:  2.041 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8030, Train loss: -0.195 Test loss:  2.040 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8040, Train loss: -0.085 Test loss:  2.646 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8050, Train loss: -0.122 Test loss:  1.838 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8060, Train loss:  0.230 Test loss:  1.280 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8070, Train loss: -0.150 Test loss:  1.966 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8080, Train loss: -0.164 Test loss:  2.192 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8090, Train loss: -0.156 Test loss:  3.739 Ensemble loss:  0.343 RMSE: 0.908 Num. networks: 25\n",
            "Epoch: 8100, Train loss: -0.115 Test loss:  5.343 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8110, Train loss: -0.157 Test loss:  4.636 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8120, Train loss: -0.162 Test loss:  3.201 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8130, Train loss: -0.174 Test loss:  2.441 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8140, Train loss: -0.021 Test loss:  1.958 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8150, Train loss: -0.046 Test loss:  1.974 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8160, Train loss: -0.150 Test loss:  2.320 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8170, Train loss: -0.153 Test loss:  3.356 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8180, Train loss:  0.464 Test loss:  1.409 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8190, Train loss: -0.070 Test loss:  2.212 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8200, Train loss:  0.082 Test loss:  2.381 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8210, Train loss:  0.180 Test loss:  1.892 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8220, Train loss: -0.165 Test loss:  2.520 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8230, Train loss: -0.140 Test loss:  2.392 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8240, Train loss:  0.149 Test loss:  1.675 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8250, Train loss: -0.194 Test loss:  2.916 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8260, Train loss: -0.001 Test loss:  1.368 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8270, Train loss:  0.381 Test loss:  0.683 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8280, Train loss:  0.233 Test loss:  0.657 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8290, Train loss:  0.396 Test loss:  0.566 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8300, Train loss: -0.020 Test loss:  0.916 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8310, Train loss: -0.167 Test loss:  1.492 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8320, Train loss: -0.186 Test loss:  1.803 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8330, Train loss:  0.174 Test loss:  1.202 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8340, Train loss:  0.382 Test loss:  0.557 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8350, Train loss: -0.020 Test loss:  0.892 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8360, Train loss: -0.132 Test loss:  1.120 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8370, Train loss: -0.174 Test loss:  1.349 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8380, Train loss: -0.189 Test loss:  1.842 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8390, Train loss: -0.152 Test loss:  1.058 Ensemble loss:  0.343 RMSE: 0.905 Num. networks: 26\n",
            "Epoch: 8400, Train loss: -0.180 Test loss:  1.425 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8410, Train loss: -0.163 Test loss:  1.077 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8420, Train loss: -0.191 Test loss:  1.262 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8430, Train loss:  0.098 Test loss:  1.419 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8440, Train loss: -0.020 Test loss:  0.971 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8450, Train loss: -0.175 Test loss:  1.533 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8460, Train loss:  0.174 Test loss:  0.990 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8470, Train loss: -0.135 Test loss:  1.546 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8480, Train loss: -0.151 Test loss:  1.613 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8490, Train loss:  0.083 Test loss:  1.459 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8500, Train loss:  0.050 Test loss:  0.775 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8510, Train loss: -0.067 Test loss:  1.130 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8520, Train loss: -0.085 Test loss:  1.333 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8530, Train loss: -0.125 Test loss:  1.900 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8540, Train loss:  0.636 Test loss:  0.616 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8550, Train loss: -0.072 Test loss:  1.011 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8560, Train loss:  0.138 Test loss:  0.781 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8570, Train loss: -0.157 Test loss:  1.591 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8580, Train loss: -0.164 Test loss:  1.727 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8590, Train loss: -0.164 Test loss:  1.595 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8600, Train loss:  0.069 Test loss:  1.284 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8610, Train loss: -0.158 Test loss:  1.834 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8620, Train loss:  0.442 Test loss:  1.225 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8630, Train loss:  0.105 Test loss:  1.850 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8640, Train loss: -0.079 Test loss:  1.315 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8650, Train loss: -0.173 Test loss:  2.377 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8660, Train loss: -0.122 Test loss:  2.364 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8670, Train loss:  0.120 Test loss:  1.474 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8680, Train loss: -0.155 Test loss:  2.661 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8690, Train loss: -0.205 Test loss:  2.822 Ensemble loss:  0.336 RMSE: 0.900 Num. networks: 27\n",
            "Epoch: 8700, Train loss:  0.122 Test loss:  1.526 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8710, Train loss:  0.611 Test loss:  0.802 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8720, Train loss: -0.130 Test loss:  1.465 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8730, Train loss: -0.233 Test loss:  2.879 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8740, Train loss:  0.115 Test loss:  2.241 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8750, Train loss:  0.086 Test loss:  1.652 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8760, Train loss: -0.182 Test loss:  2.681 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8770, Train loss: -0.153 Test loss:  2.414 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8780, Train loss: -0.194 Test loss:  2.711 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8790, Train loss:  0.148 Test loss:  1.182 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8800, Train loss: -0.149 Test loss:  2.345 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8810, Train loss: -0.034 Test loss:  2.307 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8820, Train loss:  0.147 Test loss:  2.482 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8830, Train loss:  0.155 Test loss:  1.247 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8840, Train loss: -0.147 Test loss:  2.626 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8850, Train loss: -0.109 Test loss:  3.596 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8860, Train loss:  0.719 Test loss:  0.743 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8870, Train loss:  0.020 Test loss:  2.439 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8880, Train loss:  0.428 Test loss:  0.860 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8890, Train loss: -0.126 Test loss:  3.115 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8900, Train loss:  0.143 Test loss:  2.035 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8910, Train loss: -0.066 Test loss:  3.187 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8920, Train loss:  0.237 Test loss:  2.135 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8930, Train loss: -0.122 Test loss:  3.083 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8940, Train loss: -0.074 Test loss:  1.867 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8950, Train loss: -0.051 Test loss:  1.939 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8960, Train loss: -0.078 Test loss:  1.834 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8970, Train loss:  0.111 Test loss:  1.292 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8980, Train loss:  0.073 Test loss:  1.494 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 8990, Train loss: -0.110 Test loss:  4.127 Ensemble loss:  0.341 RMSE: 0.906 Num. networks: 28\n",
            "Epoch: 9000, Train loss:  0.133 Test loss:  2.179 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9010, Train loss: -0.075 Test loss:  3.187 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9020, Train loss: -0.127 Test loss:  3.994 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9030, Train loss:  0.161 Test loss:  2.362 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9040, Train loss:  0.069 Test loss:  4.653 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9050, Train loss:  0.075 Test loss:  1.624 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9060, Train loss: -0.026 Test loss:  1.668 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9070, Train loss:  0.054 Test loss:  2.772 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9080, Train loss: -0.043 Test loss:  2.633 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9090, Train loss:  0.276 Test loss:  1.135 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9100, Train loss: -0.052 Test loss:  1.742 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9110, Train loss:  0.003 Test loss:  1.748 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9120, Train loss: -0.108 Test loss:  2.426 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9130, Train loss: -0.123 Test loss:  2.754 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9140, Train loss: -0.121 Test loss:  1.965 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9150, Train loss: -0.091 Test loss:  2.599 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9160, Train loss:  0.034 Test loss:  2.746 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9170, Train loss:  0.018 Test loss:  2.240 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9180, Train loss:  0.101 Test loss:  1.503 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9190, Train loss: -0.102 Test loss:  2.987 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9200, Train loss:  0.213 Test loss:  1.716 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9210, Train loss: -0.054 Test loss:  3.888 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9220, Train loss:  0.080 Test loss:  2.149 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9230, Train loss: -0.076 Test loss:  3.211 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9240, Train loss: -0.127 Test loss:  5.267 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9250, Train loss: -0.150 Test loss:  5.537 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9260, Train loss: -0.141 Test loss:  3.810 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9270, Train loss: -0.016 Test loss:  3.416 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9280, Train loss: -0.089 Test loss:  2.637 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9290, Train loss: -0.100 Test loss:  2.526 Ensemble loss:  0.343 RMSE: 0.911 Num. networks: 29\n",
            "Epoch: 9300, Train loss: -0.017 Test loss:  1.478 Ensemble loss:  0.341 RMSE: 0.912 Num. networks: 30\n",
            "Epoch: 9310, Train loss:  0.249 Test loss:  0.817 Ensemble loss:  0.341 RMSE: 0.912 Num. networks: 30\n",
            "Epoch: 9320, Train loss:  0.115 Test loss:  1.122 Ensemble loss:  0.341 RMSE: 0.912 Num. networks: 30\n",
            "Epoch: 9330, Train loss: -0.021 Test loss:  2.105 Ensemble loss:  0.341 RMSE: 0.912 Num. networks: 30\n",
            "Epoch: 9340, Train loss: -0.162 Test loss:  2.374 Ensemble loss:  0.341 RMSE: 0.912 Num. networks: 30\n",
            "Epoch: 9350, Train loss:  0.019 Test loss:  2.145 Ensemble loss:  0.341 RMSE: 0.912 Num. networks: 30\n",
            "FOLD 7:\n",
            "Epoch:    0, Train loss: 18.139 Test loss: 16.126 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   10, Train loss:  4.898 Test loss:  5.484 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   20, Train loss:  3.403 Test loss:  3.834 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   30, Train loss:  2.896 Test loss:  3.242 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   40, Train loss:  2.630 Test loss:  2.899 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   50, Train loss:  2.480 Test loss:  2.710 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   60, Train loss:  2.383 Test loss:  2.590 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   70, Train loss:  2.329 Test loss:  2.529 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   80, Train loss:  2.303 Test loss:  2.487 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   90, Train loss:  2.279 Test loss:  2.447 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  100, Train loss:  2.248 Test loss:  2.398 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  110, Train loss:  2.240 Test loss:  2.380 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  120, Train loss:  2.232 Test loss:  2.365 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  130, Train loss:  2.223 Test loss:  2.355 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  140, Train loss:  2.218 Test loss:  2.341 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  150, Train loss:  2.217 Test loss:  2.344 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  160, Train loss:  2.218 Test loss:  2.342 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  170, Train loss:  2.211 Test loss:  2.323 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  180, Train loss:  2.207 Test loss:  2.318 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  190, Train loss:  2.202 Test loss:  2.312 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  200, Train loss:  2.198 Test loss:  2.299 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  210, Train loss:  2.187 Test loss:  2.284 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  220, Train loss:  2.179 Test loss:  2.277 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  230, Train loss:  2.171 Test loss:  2.270 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  240, Train loss:  2.163 Test loss:  2.265 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  250, Train loss:  2.159 Test loss:  2.266 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  260, Train loss:  2.159 Test loss:  2.268 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  270, Train loss:  2.152 Test loss:  2.264 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  280, Train loss:  2.138 Test loss:  2.262 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  290, Train loss:  2.125 Test loss:  2.238 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  300, Train loss:  2.119 Test loss:  2.231 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  310, Train loss:  2.110 Test loss:  2.227 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  320, Train loss:  2.105 Test loss:  2.226 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  330, Train loss:  2.099 Test loss:  2.228 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  340, Train loss:  2.101 Test loss:  2.224 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  350, Train loss:  2.089 Test loss:  2.217 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  360, Train loss:  2.077 Test loss:  2.199 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  370, Train loss:  2.066 Test loss:  2.188 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  380, Train loss:  2.045 Test loss:  2.170 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  390, Train loss:  2.020 Test loss:  2.146 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  400, Train loss:  2.001 Test loss:  2.119 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  410, Train loss:  1.980 Test loss:  2.110 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  420, Train loss:  1.928 Test loss:  2.062 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  430, Train loss:  1.880 Test loss:  2.022 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  440, Train loss:  1.809 Test loss:  1.971 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  450, Train loss:  1.747 Test loss:  1.914 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  460, Train loss:  1.659 Test loss:  1.854 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  470, Train loss:  1.516 Test loss:  1.725 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  480, Train loss:  1.320 Test loss:  1.546 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  490, Train loss:  1.095 Test loss:  1.333 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  500, Train loss:  0.979 Test loss:  1.159 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  510, Train loss:  0.891 Test loss:  1.014 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  520, Train loss:  0.812 Test loss:  0.907 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  530, Train loss:  0.728 Test loss:  0.824 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  540, Train loss:  0.688 Test loss:  0.793 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  550, Train loss:  0.655 Test loss:  0.726 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  560, Train loss:  0.609 Test loss:  0.759 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  570, Train loss:  0.557 Test loss:  0.695 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  580, Train loss:  0.533 Test loss:  0.661 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  590, Train loss:  0.506 Test loss:  0.634 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  600, Train loss:  0.493 Test loss:  0.642 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  610, Train loss:  0.467 Test loss:  0.648 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  620, Train loss:  0.450 Test loss:  0.629 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  630, Train loss:  0.441 Test loss:  0.629 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  640, Train loss:  0.427 Test loss:  0.586 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  650, Train loss:  0.418 Test loss:  0.530 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  660, Train loss:  0.406 Test loss:  0.531 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  670, Train loss:  0.417 Test loss:  0.573 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  680, Train loss:  0.411 Test loss:  0.530 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  690, Train loss:  0.384 Test loss:  0.498 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  700, Train loss:  0.377 Test loss:  0.541 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  710, Train loss:  0.363 Test loss:  0.505 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  720, Train loss:  0.362 Test loss:  0.526 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  730, Train loss:  0.354 Test loss:  0.586 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  740, Train loss:  0.358 Test loss:  0.531 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  750, Train loss:  0.341 Test loss:  0.539 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  760, Train loss:  0.323 Test loss:  0.571 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  770, Train loss:  0.315 Test loss:  0.589 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  780, Train loss:  0.318 Test loss:  0.550 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  790, Train loss:  0.304 Test loss:  0.532 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  800, Train loss:  0.285 Test loss:  0.544 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  810, Train loss:  0.271 Test loss:  0.528 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  820, Train loss:  0.271 Test loss:  0.564 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  830, Train loss:  0.264 Test loss:  0.532 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  840, Train loss:  0.258 Test loss:  0.573 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  850, Train loss:  0.258 Test loss:  0.539 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  860, Train loss:  0.242 Test loss:  0.642 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  870, Train loss:  0.243 Test loss:  0.654 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  880, Train loss:  0.227 Test loss:  0.606 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  890, Train loss:  0.226 Test loss:  0.552 Ensemble loss:    nan RMSE: 1.271 Num. networks:  1\n",
            "Epoch:  900, Train loss:  0.223 Test loss:  0.602 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  910, Train loss:  0.227 Test loss:  0.548 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  920, Train loss:  0.207 Test loss:  0.545 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  930, Train loss:  0.207 Test loss:  0.580 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  940, Train loss:  0.202 Test loss:  0.632 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  950, Train loss:  0.197 Test loss:  0.748 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  960, Train loss:  0.211 Test loss:  0.759 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  970, Train loss:  0.213 Test loss:  0.712 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  980, Train loss:  0.196 Test loss:  0.704 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch:  990, Train loss:  0.196 Test loss:  0.744 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1000, Train loss:  0.183 Test loss:  0.660 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1010, Train loss:  0.189 Test loss:  0.696 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1020, Train loss:  0.185 Test loss:  0.665 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1030, Train loss:  0.175 Test loss:  0.580 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1040, Train loss:  0.167 Test loss:  0.576 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1050, Train loss:  0.152 Test loss:  0.536 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1060, Train loss:  0.154 Test loss:  0.596 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1070, Train loss:  0.143 Test loss:  0.565 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1080, Train loss:  0.145 Test loss:  0.582 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1090, Train loss:  0.138 Test loss:  0.531 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1100, Train loss:  0.140 Test loss:  0.586 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1110, Train loss:  0.124 Test loss:  0.562 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1120, Train loss:  0.124 Test loss:  0.614 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1130, Train loss:  0.175 Test loss:  0.617 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1140, Train loss:  0.154 Test loss:  0.629 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1150, Train loss:  0.130 Test loss:  0.703 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1160, Train loss:  0.132 Test loss:  0.723 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1170, Train loss:  0.115 Test loss:  0.626 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1180, Train loss:  0.151 Test loss:  0.802 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1190, Train loss:  0.097 Test loss:  0.787 Ensemble loss:  0.530 RMSE: 1.146 Num. networks:  2\n",
            "Epoch: 1200, Train loss:  0.118 Test loss:  0.654 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1210, Train loss:  0.099 Test loss:  0.623 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1220, Train loss:  0.087 Test loss:  0.692 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1230, Train loss:  0.084 Test loss:  0.643 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1240, Train loss:  0.069 Test loss:  0.600 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1250, Train loss:  0.075 Test loss:  0.780 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1260, Train loss:  0.063 Test loss:  0.733 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1270, Train loss:  0.064 Test loss:  0.600 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1280, Train loss:  0.151 Test loss:  0.505 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1290, Train loss:  0.072 Test loss:  0.545 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1300, Train loss:  0.077 Test loss:  0.635 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1310, Train loss:  0.248 Test loss:  0.462 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1320, Train loss:  0.298 Test loss:  0.397 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1330, Train loss:  0.158 Test loss:  0.786 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1340, Train loss:  0.080 Test loss:  0.518 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1350, Train loss:  0.170 Test loss:  0.639 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1360, Train loss:  0.069 Test loss:  0.659 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1370, Train loss:  0.169 Test loss:  0.657 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1380, Train loss:  0.145 Test loss:  0.680 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1390, Train loss:  0.215 Test loss:  0.882 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1400, Train loss:  0.118 Test loss:  0.575 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1410, Train loss:  0.173 Test loss:  0.687 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1420, Train loss:  0.147 Test loss:  0.507 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1430, Train loss:  0.048 Test loss:  0.643 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1440, Train loss:  0.085 Test loss:  0.654 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1450, Train loss:  0.206 Test loss:  0.813 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1460, Train loss:  0.100 Test loss:  0.671 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1470, Train loss:  0.116 Test loss:  0.834 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1480, Train loss:  0.396 Test loss:  0.648 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1490, Train loss:  0.152 Test loss:  0.717 Ensemble loss:  0.457 RMSE: 1.065 Num. networks:  3\n",
            "Epoch: 1500, Train loss:  0.064 Test loss:  0.696 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1510, Train loss:  0.077 Test loss:  0.726 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1520, Train loss:  0.208 Test loss:  0.641 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1530, Train loss:  0.042 Test loss:  0.792 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1540, Train loss:  0.210 Test loss:  0.722 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1550, Train loss:  0.119 Test loss:  0.676 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1560, Train loss:  0.075 Test loss:  0.631 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1570, Train loss:  0.171 Test loss:  0.724 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1580, Train loss:  0.028 Test loss:  0.659 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1590, Train loss: -0.008 Test loss:  0.634 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1600, Train loss:  0.207 Test loss:  0.466 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1610, Train loss:  0.004 Test loss:  0.577 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1620, Train loss:  0.308 Test loss:  0.578 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1630, Train loss:  0.101 Test loss:  0.653 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1640, Train loss:  0.019 Test loss:  0.780 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1650, Train loss:  0.156 Test loss:  0.534 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1660, Train loss:  0.025 Test loss:  0.399 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1670, Train loss: -0.033 Test loss:  0.561 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1680, Train loss:  0.032 Test loss:  0.646 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1690, Train loss:  0.474 Test loss:  0.396 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1700, Train loss: -0.020 Test loss:  0.580 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1710, Train loss: -0.011 Test loss:  0.556 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1720, Train loss:  0.321 Test loss:  0.351 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1730, Train loss:  0.181 Test loss:  0.540 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1740, Train loss:  0.208 Test loss:  0.735 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1750, Train loss:  0.519 Test loss:  0.560 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1760, Train loss: -0.001 Test loss:  0.485 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1770, Train loss: -0.024 Test loss:  0.489 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1780, Train loss:  0.106 Test loss:  0.501 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1790, Train loss: -0.037 Test loss:  0.667 Ensemble loss:  0.402 RMSE: 0.994 Num. networks:  4\n",
            "Epoch: 1800, Train loss: -0.035 Test loss:  0.859 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1810, Train loss:  0.523 Test loss:  0.519 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1820, Train loss:  0.152 Test loss:  0.465 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1830, Train loss: -0.030 Test loss:  0.444 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1840, Train loss: -0.048 Test loss:  0.397 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1850, Train loss:  0.424 Test loss:  0.932 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1860, Train loss:  0.087 Test loss:  0.482 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1870, Train loss: -0.017 Test loss:  0.804 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1880, Train loss:  0.133 Test loss:  1.167 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1890, Train loss:  0.430 Test loss:  0.997 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1900, Train loss:  0.007 Test loss:  1.206 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1910, Train loss:  0.244 Test loss:  0.579 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1920, Train loss:  0.016 Test loss:  0.567 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1930, Train loss: -0.010 Test loss:  0.599 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1940, Train loss:  0.147 Test loss:  0.572 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1950, Train loss:  0.021 Test loss:  0.701 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1960, Train loss: -0.021 Test loss:  0.573 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1970, Train loss:  0.106 Test loss:  0.557 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1980, Train loss:  0.469 Test loss:  0.455 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 1990, Train loss:  0.265 Test loss:  1.094 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2000, Train loss:  0.471 Test loss:  0.456 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2010, Train loss: -0.027 Test loss:  0.844 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2020, Train loss: -0.001 Test loss:  0.943 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2030, Train loss:  0.210 Test loss:  0.547 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2040, Train loss:  0.183 Test loss:  0.883 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2050, Train loss:  0.142 Test loss:  0.916 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2060, Train loss: -0.048 Test loss:  1.197 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2070, Train loss: -0.042 Test loss:  1.117 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2080, Train loss:  0.078 Test loss:  0.916 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2090, Train loss:  0.129 Test loss:  0.945 Ensemble loss:  0.365 RMSE: 0.961 Num. networks:  5\n",
            "Epoch: 2100, Train loss: -0.073 Test loss:  1.398 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2110, Train loss: -0.034 Test loss:  1.278 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2120, Train loss:  0.040 Test loss:  1.322 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2130, Train loss:  0.024 Test loss:  1.277 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2140, Train loss: -0.035 Test loss:  1.357 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2150, Train loss:  0.068 Test loss:  1.618 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2160, Train loss:  0.041 Test loss:  1.361 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2170, Train loss:  0.035 Test loss:  1.065 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2180, Train loss: -0.025 Test loss:  1.224 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2190, Train loss:  0.014 Test loss:  0.876 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2200, Train loss: -0.036 Test loss:  0.920 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2210, Train loss: -0.058 Test loss:  0.851 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2220, Train loss:  0.074 Test loss:  0.867 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2230, Train loss:  0.021 Test loss:  0.871 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2240, Train loss:  0.119 Test loss:  1.238 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2250, Train loss: -0.050 Test loss:  0.680 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2260, Train loss:  0.262 Test loss:  0.487 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2270, Train loss:  0.058 Test loss:  0.747 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2280, Train loss: -0.049 Test loss:  0.857 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2290, Train loss:  0.042 Test loss:  0.881 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2300, Train loss:  0.040 Test loss:  0.965 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2310, Train loss: -0.028 Test loss:  0.731 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2320, Train loss:  0.107 Test loss:  0.753 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2330, Train loss:  0.061 Test loss:  0.464 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2340, Train loss: -0.031 Test loss:  0.662 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2350, Train loss:  0.095 Test loss:  0.763 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2360, Train loss:  0.024 Test loss:  0.777 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2370, Train loss: -0.008 Test loss:  0.822 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2380, Train loss: -0.032 Test loss:  1.359 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2390, Train loss: -0.062 Test loss:  1.112 Ensemble loss:  0.351 RMSE: 0.942 Num. networks:  6\n",
            "Epoch: 2400, Train loss: -0.005 Test loss:  1.302 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2410, Train loss:  0.106 Test loss:  1.266 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2420, Train loss:  0.024 Test loss:  0.930 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2430, Train loss:  0.106 Test loss:  0.895 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2440, Train loss: -0.065 Test loss:  1.262 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2450, Train loss: -0.042 Test loss:  1.370 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2460, Train loss: -0.068 Test loss:  1.147 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2470, Train loss: -0.078 Test loss:  1.061 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2480, Train loss: -0.069 Test loss:  0.867 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2490, Train loss:  0.052 Test loss:  0.827 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2500, Train loss:  0.216 Test loss:  0.651 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2510, Train loss:  0.024 Test loss:  0.898 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2520, Train loss: -0.051 Test loss:  0.966 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2530, Train loss:  0.073 Test loss:  0.558 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2540, Train loss: -0.066 Test loss:  0.737 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2550, Train loss:  0.067 Test loss:  0.537 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2560, Train loss: -0.096 Test loss:  0.892 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2570, Train loss: -0.080 Test loss:  0.681 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2580, Train loss: -0.008 Test loss:  0.650 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2590, Train loss: -0.041 Test loss:  0.541 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2600, Train loss: -0.071 Test loss:  0.573 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2610, Train loss: -0.070 Test loss:  0.801 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2620, Train loss: -0.028 Test loss:  0.725 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2630, Train loss:  0.029 Test loss:  0.808 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2640, Train loss: -0.089 Test loss:  0.791 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2650, Train loss: -0.034 Test loss:  0.699 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2660, Train loss: -0.099 Test loss:  0.810 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2670, Train loss:  0.049 Test loss:  0.802 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2680, Train loss:  0.039 Test loss:  0.822 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2690, Train loss: -0.112 Test loss:  1.075 Ensemble loss:  0.334 RMSE: 0.940 Num. networks:  7\n",
            "Epoch: 2700, Train loss: -0.048 Test loss:  1.253 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2710, Train loss: -0.103 Test loss:  1.383 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2720, Train loss: -0.143 Test loss:  1.554 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2730, Train loss: -0.167 Test loss:  1.458 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2740, Train loss: -0.077 Test loss:  1.291 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2750, Train loss: -0.141 Test loss:  1.734 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2760, Train loss: -0.067 Test loss:  1.314 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2770, Train loss: -0.135 Test loss:  1.579 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2780, Train loss: -0.035 Test loss:  1.346 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2790, Train loss:  0.161 Test loss:  1.384 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2800, Train loss:  0.030 Test loss:  1.329 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2810, Train loss: -0.042 Test loss:  0.807 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2820, Train loss: -0.059 Test loss:  1.228 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2830, Train loss: -0.163 Test loss:  1.389 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2840, Train loss: -0.156 Test loss:  1.525 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2850, Train loss: -0.124 Test loss:  1.662 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2860, Train loss: -0.029 Test loss:  1.370 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2870, Train loss: -0.025 Test loss:  1.343 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2880, Train loss: -0.081 Test loss:  1.340 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2890, Train loss: -0.125 Test loss:  1.543 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2900, Train loss: -0.043 Test loss:  1.474 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2910, Train loss:  0.066 Test loss:  1.157 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2920, Train loss: -0.033 Test loss:  1.400 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2930, Train loss: -0.083 Test loss:  1.478 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2940, Train loss: -0.078 Test loss:  1.611 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2950, Train loss: -0.042 Test loss:  1.580 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2960, Train loss:  0.002 Test loss:  1.129 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2970, Train loss: -0.041 Test loss:  1.153 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2980, Train loss:  0.081 Test loss:  1.259 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 2990, Train loss:  0.171 Test loss:  1.176 Ensemble loss:  0.314 RMSE: 0.903 Num. networks:  8\n",
            "Epoch: 3000, Train loss: -0.053 Test loss:  1.230 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3010, Train loss: -0.094 Test loss:  1.516 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3020, Train loss: -0.148 Test loss:  1.705 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3030, Train loss: -0.149 Test loss:  1.361 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3040, Train loss: -0.121 Test loss:  1.554 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3050, Train loss:  0.009 Test loss:  1.515 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3060, Train loss:  0.185 Test loss:  1.254 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3070, Train loss: -0.147 Test loss:  2.251 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3080, Train loss: -0.092 Test loss:  2.720 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3090, Train loss:  0.091 Test loss:  1.713 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3100, Train loss:  0.054 Test loss:  1.496 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3110, Train loss: -0.093 Test loss:  1.592 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3120, Train loss:  0.042 Test loss:  1.429 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3130, Train loss: -0.011 Test loss:  1.547 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3140, Train loss: -0.104 Test loss:  1.536 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3150, Train loss: -0.090 Test loss:  2.161 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3160, Train loss:  0.028 Test loss:  2.062 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3170, Train loss: -0.053 Test loss:  2.443 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3180, Train loss: -0.064 Test loss:  2.258 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3190, Train loss: -0.001 Test loss:  1.076 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3200, Train loss:  0.101 Test loss:  1.213 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3210, Train loss:  0.210 Test loss:  0.988 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3220, Train loss: -0.033 Test loss:  1.420 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3230, Train loss: -0.125 Test loss:  1.605 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3240, Train loss: -0.018 Test loss:  1.087 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3250, Train loss: -0.112 Test loss:  1.769 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3260, Train loss: -0.132 Test loss:  1.491 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3270, Train loss: -0.116 Test loss:  1.881 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3280, Train loss:  0.108 Test loss:  0.783 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3290, Train loss: -0.036 Test loss:  1.746 Ensemble loss:  0.282 RMSE: 0.869 Num. networks:  9\n",
            "Epoch: 3300, Train loss: -0.093 Test loss:  2.433 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3310, Train loss: -0.011 Test loss:  2.834 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3320, Train loss:  0.058 Test loss:  2.705 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3330, Train loss:  0.088 Test loss:  0.911 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3340, Train loss: -0.125 Test loss:  1.666 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3350, Train loss: -0.095 Test loss:  1.310 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3360, Train loss: -0.125 Test loss:  2.123 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3370, Train loss: -0.111 Test loss:  1.937 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3380, Train loss:  0.041 Test loss:  2.526 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3390, Train loss: -0.079 Test loss:  3.326 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3400, Train loss: -0.022 Test loss:  3.063 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3410, Train loss:  0.041 Test loss:  2.893 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3420, Train loss:  0.296 Test loss:  3.306 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3430, Train loss: -0.031 Test loss:  4.448 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3440, Train loss: -0.065 Test loss:  3.142 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3450, Train loss: -0.002 Test loss:  3.361 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3460, Train loss: -0.039 Test loss:  3.195 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3470, Train loss:  0.077 Test loss:  3.079 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3480, Train loss: -0.055 Test loss:  3.296 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3490, Train loss: -0.109 Test loss:  1.882 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3500, Train loss:  0.042 Test loss:  1.674 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3510, Train loss: -0.050 Test loss:  1.786 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3520, Train loss: -0.089 Test loss:  1.940 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3530, Train loss: -0.037 Test loss:  2.711 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3540, Train loss: -0.100 Test loss:  2.997 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3550, Train loss: -0.099 Test loss:  2.338 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3560, Train loss: -0.126 Test loss:  2.283 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3570, Train loss:  0.159 Test loss:  2.103 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3580, Train loss: -0.136 Test loss:  2.241 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3590, Train loss: -0.079 Test loss:  2.700 Ensemble loss:  0.262 RMSE: 0.840 Num. networks: 10\n",
            "Epoch: 3600, Train loss: -0.008 Test loss:  2.443 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3610, Train loss: -0.058 Test loss:  2.243 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3620, Train loss: -0.119 Test loss:  2.031 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3630, Train loss: -0.121 Test loss:  1.952 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3640, Train loss:  0.000 Test loss:  1.181 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3650, Train loss: -0.084 Test loss:  2.212 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3660, Train loss: -0.012 Test loss:  1.933 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3670, Train loss: -0.038 Test loss:  1.280 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3680, Train loss:  0.139 Test loss:  1.179 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3690, Train loss:  0.004 Test loss:  1.450 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3700, Train loss:  0.093 Test loss:  1.781 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3710, Train loss: -0.119 Test loss:  2.362 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3720, Train loss: -0.112 Test loss:  4.511 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3730, Train loss: -0.167 Test loss:  4.813 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3740, Train loss: -0.046 Test loss:  2.683 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3750, Train loss: -0.115 Test loss:  2.780 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3760, Train loss: -0.148 Test loss:  3.577 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3770, Train loss: -0.071 Test loss:  2.065 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3780, Train loss: -0.096 Test loss:  2.681 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3790, Train loss:  0.073 Test loss:  4.635 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3800, Train loss:  0.288 Test loss:  2.310 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3810, Train loss: -0.118 Test loss:  3.123 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3820, Train loss: -0.154 Test loss:  4.465 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3830, Train loss: -0.133 Test loss:  4.648 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3840, Train loss: -0.001 Test loss:  2.637 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3850, Train loss: -0.051 Test loss:  2.916 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3860, Train loss: -0.059 Test loss:  2.842 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3870, Train loss: -0.001 Test loss:  2.150 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3880, Train loss: -0.080 Test loss:  2.922 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3890, Train loss: -0.021 Test loss:  2.854 Ensemble loss:  0.269 RMSE: 0.825 Num. networks: 11\n",
            "Epoch: 3900, Train loss: -0.110 Test loss:  3.891 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3910, Train loss: -0.172 Test loss:  5.151 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3920, Train loss: -0.153 Test loss:  4.013 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3930, Train loss:  0.148 Test loss:  1.712 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3940, Train loss: -0.125 Test loss:  2.447 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3950, Train loss: -0.185 Test loss:  2.959 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3960, Train loss: -0.175 Test loss:  3.095 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3970, Train loss: -0.185 Test loss:  3.391 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3980, Train loss: -0.121 Test loss:  3.798 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 3990, Train loss:  0.126 Test loss:  2.783 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4000, Train loss: -0.093 Test loss:  3.768 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4010, Train loss:  0.109 Test loss:  3.800 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4020, Train loss: -0.055 Test loss:  2.241 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4030, Train loss:  0.028 Test loss:  1.493 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4040, Train loss: -0.134 Test loss:  2.837 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4050, Train loss:  0.006 Test loss:  2.371 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4060, Train loss: -0.024 Test loss:  2.619 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4070, Train loss: -0.071 Test loss:  2.994 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4080, Train loss: -0.174 Test loss:  4.404 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4090, Train loss: -0.125 Test loss:  2.873 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4100, Train loss: -0.116 Test loss:  4.534 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4110, Train loss:  0.064 Test loss:  4.248 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4120, Train loss:  0.032 Test loss:  4.421 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4130, Train loss:  0.294 Test loss:  3.005 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4140, Train loss: -0.055 Test loss:  6.621 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4150, Train loss:  0.045 Test loss:  6.964 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4160, Train loss:  0.419 Test loss:  3.320 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4170, Train loss: -0.102 Test loss:  7.597 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4180, Train loss: -0.159 Test loss:  6.258 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4190, Train loss:  0.089 Test loss:  3.263 Ensemble loss:  0.281 RMSE: 0.827 Num. networks: 12\n",
            "Epoch: 4200, Train loss: -0.115 Test loss:  2.954 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4210, Train loss: -0.109 Test loss:  3.283 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4220, Train loss:  0.119 Test loss:  3.181 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4230, Train loss:  0.109 Test loss:  2.249 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4240, Train loss:  0.157 Test loss:  1.748 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4250, Train loss:  0.168 Test loss:  2.127 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4260, Train loss:  0.051 Test loss:  5.737 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4270, Train loss: -0.070 Test loss:  6.407 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4280, Train loss:  0.279 Test loss:  2.816 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4290, Train loss: -0.123 Test loss:  4.803 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4300, Train loss: -0.067 Test loss:  4.714 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4310, Train loss: -0.067 Test loss:  5.145 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4320, Train loss:  0.097 Test loss:  2.901 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4330, Train loss:  0.462 Test loss:  1.717 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4340, Train loss:  0.018 Test loss:  3.837 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4350, Train loss: -0.098 Test loss:  4.707 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4360, Train loss: -0.036 Test loss:  5.985 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4370, Train loss: -0.140 Test loss:  4.640 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4380, Train loss: -0.161 Test loss:  4.522 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4390, Train loss: -0.053 Test loss:  2.464 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4400, Train loss: -0.063 Test loss:  2.833 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4410, Train loss:  0.045 Test loss:  2.955 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4420, Train loss: -0.030 Test loss:  3.718 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4430, Train loss: -0.121 Test loss:  3.546 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4440, Train loss: -0.028 Test loss:  3.926 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4450, Train loss: -0.141 Test loss:  4.368 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4460, Train loss: -0.098 Test loss:  4.114 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4470, Train loss: -0.166 Test loss:  3.106 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4480, Train loss: -0.175 Test loss:  3.367 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4490, Train loss: -0.104 Test loss:  3.329 Ensemble loss:  0.283 RMSE: 0.827 Num. networks: 13\n",
            "Epoch: 4500, Train loss: -0.145 Test loss:  3.141 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4510, Train loss: -0.149 Test loss:  3.498 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4520, Train loss: -0.109 Test loss:  2.942 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4530, Train loss: -0.063 Test loss:  3.987 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4540, Train loss: -0.137 Test loss:  2.198 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4550, Train loss: -0.107 Test loss:  1.436 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4560, Train loss: -0.116 Test loss:  1.694 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4570, Train loss: -0.070 Test loss:  2.367 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4580, Train loss: -0.097 Test loss:  1.728 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4590, Train loss: -0.057 Test loss:  1.480 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4600, Train loss: -0.120 Test loss:  2.040 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4610, Train loss: -0.137 Test loss:  2.037 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4620, Train loss:  0.108 Test loss:  1.254 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4630, Train loss:  0.051 Test loss:  1.891 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4640, Train loss: -0.034 Test loss:  1.671 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4650, Train loss: -0.049 Test loss:  4.075 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4660, Train loss:  0.047 Test loss:  2.274 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4670, Train loss:  0.018 Test loss:  2.476 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4680, Train loss: -0.094 Test loss:  2.320 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4690, Train loss: -0.074 Test loss:  2.274 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4700, Train loss:  0.024 Test loss:  2.296 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4710, Train loss: -0.076 Test loss:  3.583 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4720, Train loss: -0.116 Test loss:  2.715 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4730, Train loss: -0.035 Test loss:  2.236 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4740, Train loss: -0.110 Test loss:  2.179 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4750, Train loss:  0.116 Test loss:  1.711 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4760, Train loss: -0.119 Test loss:  1.702 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4770, Train loss: -0.128 Test loss:  2.310 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4780, Train loss: -0.003 Test loss:  3.088 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4790, Train loss: -0.053 Test loss:  3.387 Ensemble loss:  0.283 RMSE: 0.821 Num. networks: 14\n",
            "Epoch: 4800, Train loss:  0.039 Test loss:  2.793 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4810, Train loss: -0.074 Test loss:  3.338 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4820, Train loss:  0.007 Test loss:  3.376 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4830, Train loss: -0.063 Test loss:  3.135 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4840, Train loss:  0.068 Test loss:  1.910 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4850, Train loss:  0.021 Test loss:  3.816 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4860, Train loss: -0.058 Test loss:  3.373 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4870, Train loss: -0.103 Test loss:  4.445 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4880, Train loss: -0.031 Test loss:  3.149 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4890, Train loss:  0.148 Test loss:  2.733 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4900, Train loss: -0.142 Test loss:  4.745 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4910, Train loss:  0.198 Test loss:  2.316 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4920, Train loss: -0.010 Test loss:  2.386 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4930, Train loss: -0.166 Test loss:  2.292 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4940, Train loss: -0.043 Test loss:  1.779 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4950, Train loss:  0.170 Test loss:  1.404 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4960, Train loss: -0.023 Test loss:  1.386 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4970, Train loss: -0.020 Test loss:  1.712 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4980, Train loss:  0.038 Test loss:  4.020 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 4990, Train loss: -0.051 Test loss:  3.078 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5000, Train loss: -0.121 Test loss:  2.982 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5010, Train loss: -0.132 Test loss:  3.222 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5020, Train loss: -0.030 Test loss:  3.755 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5030, Train loss: -0.042 Test loss:  2.822 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5040, Train loss: -0.032 Test loss:  3.453 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5050, Train loss: -0.086 Test loss:  2.600 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5060, Train loss: -0.127 Test loss:  2.040 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5070, Train loss: -0.128 Test loss:  2.282 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5080, Train loss: -0.095 Test loss:  3.356 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5090, Train loss: -0.177 Test loss:  7.125 Ensemble loss:  0.273 RMSE: 0.819 Num. networks: 15\n",
            "Epoch: 5100, Train loss:  0.130 Test loss:  3.902 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5110, Train loss: -0.145 Test loss:  3.848 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5120, Train loss: -0.189 Test loss:  5.189 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5130, Train loss: -0.056 Test loss:  3.311 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5140, Train loss: -0.030 Test loss:  2.816 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5150, Train loss: -0.115 Test loss:  3.244 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5160, Train loss:  0.113 Test loss:  2.344 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5170, Train loss: -0.040 Test loss:  3.674 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5180, Train loss: -0.091 Test loss:  4.761 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5190, Train loss: -0.176 Test loss:  5.741 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5200, Train loss: -0.182 Test loss:  6.089 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5210, Train loss: -0.039 Test loss:  4.419 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5220, Train loss: -0.053 Test loss:  4.763 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5230, Train loss: -0.043 Test loss:  2.594 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5240, Train loss: -0.107 Test loss:  3.338 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5250, Train loss: -0.163 Test loss:  4.386 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5260, Train loss: -0.131 Test loss:  5.834 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5270, Train loss: -0.109 Test loss:  4.492 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5280, Train loss:  0.037 Test loss:  5.438 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5290, Train loss: -0.065 Test loss:  6.497 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5300, Train loss: -0.126 Test loss:  5.077 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5310, Train loss: -0.099 Test loss:  4.555 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5320, Train loss: -0.125 Test loss:  3.173 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5330, Train loss: -0.156 Test loss:  2.981 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5340, Train loss: -0.088 Test loss:  2.903 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5350, Train loss: -0.009 Test loss:  5.262 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5360, Train loss:  0.044 Test loss:  3.534 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5370, Train loss:  0.078 Test loss:  2.829 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5380, Train loss: -0.003 Test loss:  3.158 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5390, Train loss: -0.115 Test loss:  6.793 Ensemble loss:  0.265 RMSE: 0.820 Num. networks: 16\n",
            "Epoch: 5400, Train loss: -0.174 Test loss:  5.539 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5410, Train loss: -0.179 Test loss:  4.666 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5420, Train loss:  0.325 Test loss:  3.460 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5430, Train loss: -0.198 Test loss:  2.508 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5440, Train loss: -0.183 Test loss:  2.532 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5450, Train loss:  0.002 Test loss:  3.266 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5460, Train loss:  0.343 Test loss:  1.013 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5470, Train loss: -0.030 Test loss:  1.384 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5480, Train loss: -0.078 Test loss:  2.276 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5490, Train loss: -0.174 Test loss:  2.863 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5500, Train loss: -0.190 Test loss:  2.948 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5510, Train loss:  0.156 Test loss:  1.699 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5520, Train loss:  0.052 Test loss:  1.252 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5530, Train loss: -0.052 Test loss:  1.040 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5540, Train loss: -0.105 Test loss:  1.484 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5550, Train loss:  0.176 Test loss:  1.127 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5560, Train loss:  0.189 Test loss:  1.326 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5570, Train loss: -0.035 Test loss:  1.531 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5580, Train loss:  0.251 Test loss:  1.964 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5590, Train loss:  0.154 Test loss:  1.762 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5600, Train loss: -0.025 Test loss:  2.535 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5610, Train loss: -0.143 Test loss:  1.768 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5620, Train loss: -0.114 Test loss:  2.043 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5630, Train loss: -0.120 Test loss:  2.083 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5640, Train loss: -0.078 Test loss:  2.439 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5650, Train loss: -0.137 Test loss:  2.303 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5660, Train loss: -0.137 Test loss:  2.980 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5670, Train loss: -0.162 Test loss:  2.620 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5680, Train loss:  0.014 Test loss:  2.133 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5690, Train loss: -0.077 Test loss:  1.482 Ensemble loss:  0.264 RMSE: 0.825 Num. networks: 17\n",
            "Epoch: 5700, Train loss: -0.030 Test loss:  1.247 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5710, Train loss: -0.158 Test loss:  1.321 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5720, Train loss: -0.207 Test loss:  1.673 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5730, Train loss: -0.126 Test loss:  1.057 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5740, Train loss:  0.179 Test loss:  0.679 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5750, Train loss: -0.172 Test loss:  1.222 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5760, Train loss: -0.193 Test loss:  2.182 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5770, Train loss: -0.074 Test loss:  2.552 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5780, Train loss: -0.004 Test loss:  0.989 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5790, Train loss: -0.098 Test loss:  2.159 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5800, Train loss: -0.209 Test loss:  1.681 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5810, Train loss: -0.133 Test loss:  2.101 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5820, Train loss:  0.267 Test loss:  0.871 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5830, Train loss: -0.199 Test loss:  2.258 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5840, Train loss: -0.128 Test loss:  1.930 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5850, Train loss:  0.117 Test loss:  1.034 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5860, Train loss:  0.061 Test loss:  2.036 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5870, Train loss: -0.002 Test loss:  2.183 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5880, Train loss: -0.021 Test loss:  4.735 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5890, Train loss: -0.135 Test loss:  5.828 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5900, Train loss: -0.064 Test loss:  3.296 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5910, Train loss: -0.127 Test loss:  3.230 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5920, Train loss: -0.017 Test loss:  2.858 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5930, Train loss:  0.124 Test loss:  5.882 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5940, Train loss:  0.144 Test loss:  2.413 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5950, Train loss: -0.152 Test loss:  9.639 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5960, Train loss: -0.153 Test loss:  4.945 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5970, Train loss: -0.103 Test loss:  1.988 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5980, Train loss: -0.128 Test loss:  1.954 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 5990, Train loss: -0.049 Test loss:  1.211 Ensemble loss:  0.271 RMSE: 0.829 Num. networks: 18\n",
            "Epoch: 6000, Train loss: -0.143 Test loss:  1.462 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6010, Train loss: -0.136 Test loss:  1.391 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6020, Train loss: -0.165 Test loss:  1.451 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6030, Train loss: -0.015 Test loss:  1.438 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6040, Train loss: -0.030 Test loss:  1.283 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6050, Train loss: -0.047 Test loss:  1.384 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6060, Train loss: -0.014 Test loss:  1.298 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6070, Train loss:  0.049 Test loss:  1.160 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6080, Train loss: -0.162 Test loss:  1.754 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6090, Train loss: -0.189 Test loss:  1.592 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6100, Train loss:  0.023 Test loss:  1.431 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6110, Train loss: -0.173 Test loss:  2.868 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6120, Train loss: -0.198 Test loss:  5.947 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6130, Train loss: -0.019 Test loss:  3.427 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6140, Train loss:  0.200 Test loss:  1.481 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6150, Train loss:  0.083 Test loss:  1.799 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6160, Train loss: -0.107 Test loss:  2.094 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6170, Train loss: -0.108 Test loss:  2.961 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6180, Train loss: -0.107 Test loss:  2.512 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6190, Train loss:  0.030 Test loss:  2.204 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6200, Train loss: -0.122 Test loss:  3.260 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6210, Train loss: -0.009 Test loss:  2.898 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6220, Train loss:  0.189 Test loss:  3.180 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6230, Train loss: -0.153 Test loss:  6.100 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6240, Train loss: -0.135 Test loss:  6.789 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6250, Train loss: -0.073 Test loss:  6.800 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6260, Train loss: -0.197 Test loss:  6.394 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6270, Train loss: -0.135 Test loss:  5.389 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6280, Train loss: -0.052 Test loss:  2.742 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6290, Train loss: -0.210 Test loss:  5.160 Ensemble loss:  0.271 RMSE: 0.826 Num. networks: 19\n",
            "Epoch: 6300, Train loss:  0.057 Test loss:  4.309 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6310, Train loss:  0.213 Test loss:  2.315 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6320, Train loss: -0.193 Test loss:  5.837 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6330, Train loss: -0.013 Test loss:  3.240 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6340, Train loss: -0.189 Test loss:  4.666 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6350, Train loss: -0.057 Test loss:  6.061 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6360, Train loss: -0.005 Test loss:  6.406 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6370, Train loss:  0.018 Test loss:  2.386 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6380, Train loss: -0.035 Test loss:  6.101 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6390, Train loss: -0.171 Test loss:  6.162 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6400, Train loss:  0.043 Test loss:  4.769 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6410, Train loss:  0.666 Test loss:  1.135 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6420, Train loss: -0.065 Test loss:  2.389 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6430, Train loss: -0.170 Test loss:  3.348 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6440, Train loss: -0.093 Test loss:  3.111 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6450, Train loss: -0.097 Test loss:  4.308 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6460, Train loss: -0.078 Test loss:  4.029 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6470, Train loss: -0.063 Test loss:  3.717 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6480, Train loss: -0.196 Test loss:  3.535 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6490, Train loss: -0.068 Test loss:  3.018 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6500, Train loss:  0.075 Test loss:  2.118 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6510, Train loss:  0.069 Test loss:  2.133 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6520, Train loss:  0.139 Test loss:  2.163 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6530, Train loss: -0.146 Test loss:  5.756 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6540, Train loss:  0.070 Test loss:  7.233 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6550, Train loss:  0.132 Test loss:  4.630 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6560, Train loss: -0.102 Test loss:  5.768 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6570, Train loss:  0.055 Test loss:  3.112 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6580, Train loss: -0.129 Test loss:  5.233 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6590, Train loss: -0.220 Test loss:  9.030 Ensemble loss:  0.277 RMSE: 0.827 Num. networks: 20\n",
            "Epoch: 6600, Train loss: -0.230 Test loss:  9.643 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6610, Train loss: -0.232 Test loss: 11.353 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6620, Train loss: -0.240 Test loss: 13.065 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6630, Train loss: -0.154 Test loss: 12.291 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6640, Train loss: -0.260 Test loss: 13.856 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6650, Train loss: -0.243 Test loss:  8.798 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6660, Train loss: -0.223 Test loss:  9.778 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6670, Train loss:  0.034 Test loss:  6.778 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6680, Train loss: -0.245 Test loss:  8.250 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6690, Train loss: -0.182 Test loss:  7.400 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6700, Train loss:  0.030 Test loss:  5.265 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6710, Train loss: -0.183 Test loss:  6.811 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6720, Train loss: -0.132 Test loss:  4.615 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6730, Train loss: -0.185 Test loss:  6.248 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6740, Train loss:  0.007 Test loss:  3.485 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6750, Train loss:  0.231 Test loss:  2.018 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6760, Train loss: -0.061 Test loss:  3.909 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6770, Train loss: -0.244 Test loss:  7.977 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6780, Train loss: -0.211 Test loss:  7.222 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6790, Train loss: -0.077 Test loss:  3.129 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6800, Train loss: -0.196 Test loss:  4.228 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6810, Train loss: -0.171 Test loss:  3.556 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6820, Train loss: -0.210 Test loss:  4.418 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6830, Train loss: -0.194 Test loss:  3.463 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6840, Train loss: -0.024 Test loss:  3.108 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6850, Train loss: -0.043 Test loss:  3.114 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6860, Train loss: -0.179 Test loss:  3.169 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6870, Train loss: -0.142 Test loss:  2.982 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6880, Train loss: -0.176 Test loss:  2.803 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6890, Train loss: -0.018 Test loss:  1.578 Ensemble loss:  0.269 RMSE: 0.828 Num. networks: 21\n",
            "Epoch: 6900, Train loss: -0.151 Test loss:  2.263 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6910, Train loss: -0.129 Test loss:  2.224 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6920, Train loss: -0.068 Test loss:  3.387 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6930, Train loss:  0.008 Test loss:  1.715 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6940, Train loss: -0.186 Test loss:  2.495 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6950, Train loss: -0.204 Test loss:  2.913 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6960, Train loss: -0.216 Test loss:  2.313 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6970, Train loss: -0.171 Test loss:  1.690 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6980, Train loss: -0.129 Test loss:  1.995 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 6990, Train loss: -0.128 Test loss:  2.178 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7000, Train loss: -0.164 Test loss:  2.348 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7010, Train loss: -0.194 Test loss:  2.953 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7020, Train loss:  0.084 Test loss:  1.567 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7030, Train loss:  0.102 Test loss:  1.574 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7040, Train loss: -0.084 Test loss:  2.076 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7050, Train loss: -0.122 Test loss:  2.826 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7060, Train loss: -0.113 Test loss:  1.844 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7070, Train loss: -0.199 Test loss:  2.413 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7080, Train loss: -0.029 Test loss:  1.635 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7090, Train loss:  0.146 Test loss:  1.448 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7100, Train loss: -0.162 Test loss:  1.958 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7110, Train loss: -0.189 Test loss:  2.595 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7120, Train loss: -0.089 Test loss:  1.765 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7130, Train loss: -0.117 Test loss:  1.613 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7140, Train loss: -0.005 Test loss:  1.530 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7150, Train loss:  0.059 Test loss:  1.341 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7160, Train loss:  0.161 Test loss:  1.610 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7170, Train loss: -0.040 Test loss:  2.025 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7180, Train loss: -0.037 Test loss:  2.212 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7190, Train loss: -0.065 Test loss:  1.786 Ensemble loss:  0.264 RMSE: 0.823 Num. networks: 22\n",
            "Epoch: 7200, Train loss: -0.137 Test loss:  2.852 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7210, Train loss: -0.029 Test loss:  3.234 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7220, Train loss:  0.045 Test loss:  3.212 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7230, Train loss: -0.075 Test loss:  2.922 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7240, Train loss:  0.077 Test loss:  2.378 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7250, Train loss:  0.104 Test loss:  1.802 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7260, Train loss: -0.116 Test loss:  1.875 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7270, Train loss: -0.130 Test loss:  2.271 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7280, Train loss: -0.065 Test loss:  2.180 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7290, Train loss:  0.131 Test loss:  1.561 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7300, Train loss: -0.022 Test loss:  1.480 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7310, Train loss: -0.097 Test loss:  1.403 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7320, Train loss: -0.173 Test loss:  1.259 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7330, Train loss: -0.167 Test loss:  1.536 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7340, Train loss: -0.141 Test loss:  1.691 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7350, Train loss: -0.094 Test loss:  1.656 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7360, Train loss: -0.048 Test loss:  1.584 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7370, Train loss: -0.041 Test loss:  1.436 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7380, Train loss: -0.189 Test loss:  2.133 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7390, Train loss: -0.155 Test loss:  1.865 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7400, Train loss: -0.165 Test loss:  2.911 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7410, Train loss: -0.159 Test loss:  2.463 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7420, Train loss:  0.120 Test loss:  1.619 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7430, Train loss: -0.136 Test loss:  3.626 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7440, Train loss:  0.211 Test loss:  1.835 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7450, Train loss: -0.022 Test loss:  1.655 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7460, Train loss: -0.099 Test loss:  2.184 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7470, Train loss: -0.129 Test loss:  2.319 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7480, Train loss: -0.146 Test loss:  3.987 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7490, Train loss:  0.071 Test loss:  2.982 Ensemble loss:  0.265 RMSE: 0.823 Num. networks: 23\n",
            "Epoch: 7500, Train loss: -0.161 Test loss:  2.626 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7510, Train loss: -0.106 Test loss:  2.395 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7520, Train loss: -0.185 Test loss:  3.756 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7530, Train loss:  0.147 Test loss:  1.659 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7540, Train loss: -0.126 Test loss:  3.688 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7550, Train loss: -0.065 Test loss:  3.235 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7560, Train loss:  0.199 Test loss:  1.389 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7570, Train loss: -0.100 Test loss:  4.453 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7580, Train loss:  0.131 Test loss:  2.254 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7590, Train loss:  0.252 Test loss:  1.965 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7600, Train loss:  0.198 Test loss:  3.117 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7610, Train loss:  0.130 Test loss:  1.506 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7620, Train loss: -0.107 Test loss:  2.298 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7630, Train loss: -0.150 Test loss:  2.835 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7640, Train loss:  0.050 Test loss:  2.215 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7650, Train loss: -0.058 Test loss:  2.810 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7660, Train loss: -0.083 Test loss:  2.623 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7670, Train loss: -0.079 Test loss:  3.480 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7680, Train loss: -0.036 Test loss:  3.955 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7690, Train loss: -0.095 Test loss:  6.008 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7700, Train loss: -0.047 Test loss:  2.685 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7710, Train loss:  0.471 Test loss:  1.235 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7720, Train loss: -0.104 Test loss:  2.869 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7730, Train loss: -0.234 Test loss:  4.520 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7740, Train loss: -0.175 Test loss:  4.192 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7750, Train loss: -0.226 Test loss:  3.515 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7760, Train loss:  0.335 Test loss:  1.912 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7770, Train loss:  0.098 Test loss:  1.510 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7780, Train loss: -0.128 Test loss:  2.517 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7790, Train loss: -0.135 Test loss:  3.473 Ensemble loss:  0.268 RMSE: 0.825 Num. networks: 24\n",
            "Epoch: 7800, Train loss:  0.057 Test loss:  4.684 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7810, Train loss:  0.647 Test loss:  1.284 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7820, Train loss:  0.003 Test loss:  3.213 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7830, Train loss: -0.192 Test loss:  5.073 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7840, Train loss: -0.060 Test loss:  2.929 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7850, Train loss: -0.237 Test loss:  4.314 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7860, Train loss: -0.199 Test loss:  4.904 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7870, Train loss: -0.233 Test loss:  4.662 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7880, Train loss: -0.074 Test loss:  2.980 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7890, Train loss:  0.028 Test loss:  2.486 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7900, Train loss: -0.108 Test loss:  2.431 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7910, Train loss:  0.181 Test loss:  2.118 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7920, Train loss:  0.199 Test loss:  2.868 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7930, Train loss: -0.010 Test loss:  1.776 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7940, Train loss: -0.163 Test loss:  2.700 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7950, Train loss: -0.220 Test loss:  2.628 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7960, Train loss: -0.195 Test loss:  2.829 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7970, Train loss: -0.158 Test loss:  3.133 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7980, Train loss:  0.682 Test loss:  0.940 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 7990, Train loss:  0.614 Test loss:  0.933 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8000, Train loss:  0.006 Test loss:  1.810 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8010, Train loss: -0.038 Test loss:  2.742 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8020, Train loss: -0.145 Test loss:  2.735 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8030, Train loss: -0.240 Test loss:  3.694 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8040, Train loss: -0.214 Test loss:  2.865 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8050, Train loss: -0.216 Test loss:  2.667 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8060, Train loss: -0.192 Test loss:  2.850 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8070, Train loss: -0.187 Test loss:  2.696 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8080, Train loss: -0.205 Test loss:  2.848 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8090, Train loss: -0.218 Test loss:  3.289 Ensemble loss:  0.276 RMSE: 0.828 Num. networks: 25\n",
            "Epoch: 8100, Train loss: -0.128 Test loss:  3.127 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8110, Train loss:  0.059 Test loss:  1.787 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8120, Train loss:  0.026 Test loss:  2.498 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8130, Train loss: -0.195 Test loss:  2.412 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8140, Train loss:  0.411 Test loss:  0.961 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8150, Train loss:  0.007 Test loss:  1.450 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8160, Train loss: -0.206 Test loss:  2.743 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8170, Train loss: -0.144 Test loss:  2.738 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8180, Train loss: -0.007 Test loss:  2.040 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8190, Train loss: -0.177 Test loss:  2.336 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8200, Train loss: -0.163 Test loss:  2.633 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8210, Train loss: -0.194 Test loss:  2.390 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8220, Train loss: -0.041 Test loss:  2.994 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8230, Train loss: -0.148 Test loss:  1.997 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8240, Train loss: -0.111 Test loss:  1.875 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8250, Train loss: -0.063 Test loss:  1.873 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8260, Train loss: -0.185 Test loss:  3.358 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8270, Train loss: -0.120 Test loss:  3.884 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8280, Train loss:  0.128 Test loss:  2.089 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8290, Train loss: -0.159 Test loss:  3.227 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8300, Train loss:  0.050 Test loss:  1.659 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8310, Train loss:  0.038 Test loss:  1.797 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8320, Train loss: -0.191 Test loss:  2.680 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8330, Train loss: -0.194 Test loss:  3.041 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8340, Train loss: -0.193 Test loss:  3.079 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8350, Train loss:  0.123 Test loss:  1.935 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8360, Train loss: -0.185 Test loss:  3.663 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8370, Train loss: -0.082 Test loss:  3.737 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8380, Train loss:  0.066 Test loss:  2.821 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8390, Train loss: -0.012 Test loss:  3.778 Ensemble loss:  0.278 RMSE: 0.832 Num. networks: 26\n",
            "Epoch: 8400, Train loss: -0.066 Test loss:  2.875 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8410, Train loss: -0.095 Test loss:  1.810 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8420, Train loss: -0.033 Test loss:  1.103 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8430, Train loss: -0.082 Test loss:  2.027 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8440, Train loss: -0.208 Test loss:  2.793 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8450, Train loss: -0.197 Test loss:  2.173 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8460, Train loss: -0.202 Test loss:  2.594 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8470, Train loss: -0.117 Test loss:  2.206 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8480, Train loss: -0.198 Test loss:  2.112 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8490, Train loss: -0.076 Test loss:  2.133 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8500, Train loss: -0.226 Test loss:  2.262 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8510, Train loss: -0.217 Test loss:  2.064 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8520, Train loss: -0.170 Test loss:  2.316 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8530, Train loss:  0.012 Test loss:  2.481 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8540, Train loss: -0.108 Test loss:  2.035 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8550, Train loss: -0.099 Test loss:  2.764 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8560, Train loss: -0.043 Test loss:  4.089 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8570, Train loss: -0.074 Test loss:  3.381 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8580, Train loss: -0.222 Test loss:  2.604 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8590, Train loss: -0.211 Test loss:  2.198 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8600, Train loss: -0.197 Test loss:  2.379 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8610, Train loss: -0.177 Test loss:  2.163 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8620, Train loss: -0.238 Test loss:  2.487 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8630, Train loss: -0.208 Test loss:  3.462 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8640, Train loss: -0.259 Test loss:  2.475 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8650, Train loss: -0.107 Test loss:  3.055 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8660, Train loss:  0.001 Test loss:  1.097 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8670, Train loss: -0.193 Test loss:  1.454 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8680, Train loss: -0.108 Test loss:  1.072 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8690, Train loss: -0.219 Test loss:  1.489 Ensemble loss:  0.279 RMSE: 0.834 Num. networks: 27\n",
            "Epoch: 8700, Train loss: -0.135 Test loss:  1.198 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8710, Train loss: -0.281 Test loss:  1.476 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8720, Train loss: -0.252 Test loss:  1.679 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8730, Train loss: -0.242 Test loss:  2.064 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8740, Train loss: -0.088 Test loss:  1.934 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8750, Train loss: -0.172 Test loss:  3.214 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8760, Train loss:  0.025 Test loss:  1.327 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8770, Train loss: -0.101 Test loss:  1.877 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8780, Train loss: -0.171 Test loss:  1.754 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8790, Train loss: -0.191 Test loss:  2.240 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8800, Train loss: -0.242 Test loss:  2.077 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8810, Train loss: -0.244 Test loss:  1.938 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8820, Train loss: -0.184 Test loss:  1.495 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8830, Train loss: -0.014 Test loss:  1.190 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8840, Train loss: -0.135 Test loss:  1.745 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8850, Train loss: -0.053 Test loss:  1.548 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8860, Train loss:  0.006 Test loss:  1.522 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8870, Train loss: -0.093 Test loss:  1.842 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8880, Train loss:  0.146 Test loss:  1.116 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8890, Train loss: -0.176 Test loss:  3.064 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8900, Train loss: -0.220 Test loss:  2.459 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8910, Train loss: -0.095 Test loss:  2.840 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8920, Train loss: -0.080 Test loss:  2.292 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8930, Train loss: -0.190 Test loss:  2.872 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8940, Train loss: -0.165 Test loss:  1.795 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8950, Train loss: -0.226 Test loss:  1.878 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8960, Train loss: -0.140 Test loss:  1.085 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8970, Train loss: -0.204 Test loss:  1.373 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8980, Train loss: -0.221 Test loss:  2.072 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 8990, Train loss: -0.200 Test loss:  1.188 Ensemble loss:  0.277 RMSE: 0.832 Num. networks: 28\n",
            "Epoch: 9000, Train loss: -0.176 Test loss:  1.552 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9010, Train loss: -0.115 Test loss:  1.102 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9020, Train loss: -0.206 Test loss:  1.686 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9030, Train loss: -0.239 Test loss:  1.444 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9040, Train loss: -0.200 Test loss:  1.429 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9050, Train loss: -0.200 Test loss:  1.444 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9060, Train loss: -0.212 Test loss:  1.613 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9070, Train loss: -0.191 Test loss:  2.080 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9080, Train loss: -0.202 Test loss:  1.574 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9090, Train loss: -0.153 Test loss:  1.630 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9100, Train loss: -0.100 Test loss:  1.671 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9110, Train loss: -0.170 Test loss:  2.321 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9120, Train loss: -0.101 Test loss:  1.395 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9130, Train loss: -0.107 Test loss:  1.571 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9140, Train loss:  0.045 Test loss:  0.860 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9150, Train loss: -0.089 Test loss:  1.151 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9160, Train loss: -0.120 Test loss:  1.212 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9170, Train loss: -0.202 Test loss:  1.231 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9180, Train loss:  0.200 Test loss:  1.360 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9190, Train loss: -0.141 Test loss:  1.337 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9200, Train loss: -0.063 Test loss:  1.058 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9210, Train loss: -0.073 Test loss:  0.928 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9220, Train loss: -0.121 Test loss:  1.356 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9230, Train loss: -0.201 Test loss:  1.458 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9240, Train loss: -0.199 Test loss:  1.557 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9250, Train loss: -0.022 Test loss:  1.043 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9260, Train loss: -0.203 Test loss:  1.559 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9270, Train loss: -0.008 Test loss:  0.787 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9280, Train loss:  0.054 Test loss:  0.755 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9290, Train loss: -0.073 Test loss:  0.842 Ensemble loss:  0.276 RMSE: 0.830 Num. networks: 29\n",
            "Epoch: 9300, Train loss: -0.186 Test loss:  1.068 Ensemble loss:  0.278 RMSE: 0.829 Num. networks: 30\n",
            "Epoch: 9310, Train loss: -0.172 Test loss:  1.307 Ensemble loss:  0.278 RMSE: 0.829 Num. networks: 30\n",
            "Epoch: 9320, Train loss: -0.135 Test loss:  1.392 Ensemble loss:  0.278 RMSE: 0.829 Num. networks: 30\n",
            "Epoch: 9330, Train loss: -0.249 Test loss:  1.588 Ensemble loss:  0.278 RMSE: 0.829 Num. networks: 30\n",
            "Epoch: 9340, Train loss: -0.167 Test loss:  1.199 Ensemble loss:  0.278 RMSE: 0.829 Num. networks: 30\n",
            "Epoch: 9350, Train loss: -0.165 Test loss:  1.036 Ensemble loss:  0.278 RMSE: 0.829 Num. networks: 30\n",
            "FOLD 8:\n",
            "Epoch:    0, Train loss: 18.518 Test loss: 12.946 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   10, Train loss:  4.877 Test loss:  4.494 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   20, Train loss:  3.416 Test loss:  3.246 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   30, Train loss:  2.867 Test loss:  2.771 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   40, Train loss:  2.623 Test loss:  2.553 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   50, Train loss:  2.479 Test loss:  2.426 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   60, Train loss:  2.384 Test loss:  2.344 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   70, Train loss:  2.321 Test loss:  2.286 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   80, Train loss:  2.273 Test loss:  2.244 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   90, Train loss:  2.257 Test loss:  2.235 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  100, Train loss:  2.251 Test loss:  2.231 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  110, Train loss:  2.241 Test loss:  2.220 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  120, Train loss:  2.239 Test loss:  2.219 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  130, Train loss:  2.235 Test loss:  2.219 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  140, Train loss:  2.233 Test loss:  2.218 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  150, Train loss:  2.229 Test loss:  2.215 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  160, Train loss:  2.227 Test loss:  2.212 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  170, Train loss:  2.221 Test loss:  2.209 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  180, Train loss:  2.216 Test loss:  2.200 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  190, Train loss:  2.215 Test loss:  2.199 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  200, Train loss:  2.207 Test loss:  2.193 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  210, Train loss:  2.204 Test loss:  2.190 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  220, Train loss:  2.200 Test loss:  2.184 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  230, Train loss:  2.191 Test loss:  2.174 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  240, Train loss:  2.187 Test loss:  2.176 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  250, Train loss:  2.176 Test loss:  2.169 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  260, Train loss:  2.169 Test loss:  2.161 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  270, Train loss:  2.149 Test loss:  2.141 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  280, Train loss:  2.137 Test loss:  2.128 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  290, Train loss:  2.134 Test loss:  2.118 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  300, Train loss:  2.127 Test loss:  2.107 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  310, Train loss:  2.110 Test loss:  2.086 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  320, Train loss:  2.096 Test loss:  2.070 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  330, Train loss:  2.086 Test loss:  2.049 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  340, Train loss:  2.063 Test loss:  2.027 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  350, Train loss:  2.035 Test loss:  1.995 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  360, Train loss:  2.007 Test loss:  1.964 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  370, Train loss:  1.983 Test loss:  1.941 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  380, Train loss:  1.935 Test loss:  1.888 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  390, Train loss:  1.914 Test loss:  1.871 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  400, Train loss:  1.866 Test loss:  1.818 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  410, Train loss:  1.807 Test loss:  1.754 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  420, Train loss:  1.728 Test loss:  1.652 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  430, Train loss:  1.614 Test loss:  1.522 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  440, Train loss:  1.468 Test loss:  1.386 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  450, Train loss:  1.124 Test loss:  1.148 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  460, Train loss:  0.864 Test loss:  1.617 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  470, Train loss:  0.781 Test loss:  2.091 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  480, Train loss:  0.731 Test loss:  2.384 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  490, Train loss:  0.689 Test loss:  2.159 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  500, Train loss:  0.626 Test loss:  2.025 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  510, Train loss:  0.595 Test loss:  2.237 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  520, Train loss:  0.559 Test loss:  2.276 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  530, Train loss:  0.520 Test loss:  1.709 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  540, Train loss:  0.488 Test loss:  1.677 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  550, Train loss:  0.460 Test loss:  1.816 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  560, Train loss:  0.440 Test loss:  1.701 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  570, Train loss:  0.419 Test loss:  1.648 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  580, Train loss:  0.405 Test loss:  1.620 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  590, Train loss:  0.383 Test loss:  1.547 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  600, Train loss:  0.380 Test loss:  1.564 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  610, Train loss:  0.367 Test loss:  1.312 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  620, Train loss:  0.356 Test loss:  1.224 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  630, Train loss:  0.348 Test loss:  1.441 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  640, Train loss:  0.343 Test loss:  1.326 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  650, Train loss:  0.339 Test loss:  1.167 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  660, Train loss:  0.322 Test loss:  1.292 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  670, Train loss:  0.323 Test loss:  1.182 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  680, Train loss:  0.318 Test loss:  1.175 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  690, Train loss:  0.319 Test loss:  1.153 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  700, Train loss:  0.300 Test loss:  1.242 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  710, Train loss:  0.302 Test loss:  1.061 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  720, Train loss:  0.293 Test loss:  0.908 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  730, Train loss:  0.299 Test loss:  0.988 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  740, Train loss:  0.299 Test loss:  1.021 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  750, Train loss:  0.299 Test loss:  0.863 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  760, Train loss:  0.290 Test loss:  0.910 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  770, Train loss:  0.281 Test loss:  0.921 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  780, Train loss:  0.272 Test loss:  1.049 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  790, Train loss:  0.259 Test loss:  1.068 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  800, Train loss:  0.262 Test loss:  1.209 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  810, Train loss:  0.250 Test loss:  1.309 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  820, Train loss:  0.246 Test loss:  1.416 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  830, Train loss:  0.241 Test loss:  2.047 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  840, Train loss:  0.238 Test loss:  1.729 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  850, Train loss:  0.230 Test loss:  2.242 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  860, Train loss:  0.221 Test loss:  1.665 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  870, Train loss:  0.216 Test loss:  1.951 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  880, Train loss:  0.208 Test loss:  1.799 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  890, Train loss:  0.205 Test loss:  1.885 Ensemble loss:    nan RMSE: 1.278 Num. networks:  1\n",
            "Epoch:  900, Train loss:  0.205 Test loss:  1.780 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  910, Train loss:  0.194 Test loss:  1.957 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  920, Train loss:  0.187 Test loss:  1.706 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  930, Train loss:  0.174 Test loss:  2.301 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  940, Train loss:  0.158 Test loss:  2.950 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  950, Train loss:  0.146 Test loss:  2.225 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  960, Train loss:  0.130 Test loss:  3.637 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  970, Train loss:  0.130 Test loss:  3.703 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  980, Train loss:  0.126 Test loss:  2.492 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch:  990, Train loss:  0.129 Test loss:  2.664 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1000, Train loss:  0.125 Test loss:  2.969 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1010, Train loss:  0.116 Test loss:  2.427 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1020, Train loss:  0.103 Test loss:  2.478 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1030, Train loss:  0.110 Test loss:  3.354 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1040, Train loss:  0.096 Test loss:  3.357 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1050, Train loss:  0.083 Test loss:  3.119 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1060, Train loss:  0.077 Test loss:  4.701 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1070, Train loss:  0.073 Test loss:  4.439 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1080, Train loss:  0.084 Test loss:  3.530 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1090, Train loss:  0.099 Test loss:  4.071 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1100, Train loss:  0.081 Test loss:  3.287 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1110, Train loss:  0.067 Test loss:  2.962 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1120, Train loss:  0.071 Test loss:  2.497 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1130, Train loss:  0.048 Test loss:  1.861 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1140, Train loss:  0.063 Test loss:  3.544 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1150, Train loss:  0.053 Test loss:  2.893 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1160, Train loss:  0.045 Test loss:  3.990 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1170, Train loss:  0.060 Test loss:  3.828 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1180, Train loss:  0.060 Test loss:  2.338 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1190, Train loss:  0.064 Test loss:  2.093 Ensemble loss:  1.520 RMSE: 1.237 Num. networks:  2\n",
            "Epoch: 1200, Train loss:  0.053 Test loss:  1.757 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1210, Train loss:  0.029 Test loss:  1.719 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1220, Train loss:  0.035 Test loss:  2.039 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1230, Train loss:  0.022 Test loss:  2.817 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1240, Train loss:  0.018 Test loss:  2.236 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1250, Train loss:  0.025 Test loss:  2.009 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1260, Train loss:  0.020 Test loss:  3.028 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1270, Train loss:  0.003 Test loss:  1.680 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1280, Train loss: -0.016 Test loss:  3.387 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1290, Train loss:  0.029 Test loss:  2.625 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1300, Train loss:  0.027 Test loss:  5.312 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1310, Train loss: -0.030 Test loss:  3.712 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1320, Train loss:  0.007 Test loss:  2.485 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1330, Train loss:  0.032 Test loss:  2.658 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1340, Train loss:  0.014 Test loss:  2.792 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1350, Train loss: -0.018 Test loss:  3.190 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1360, Train loss: -0.043 Test loss:  4.670 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1370, Train loss: -0.007 Test loss:  3.886 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1380, Train loss:  0.080 Test loss:  3.591 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1390, Train loss:  0.120 Test loss:  3.477 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1400, Train loss: -0.030 Test loss:  3.600 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1410, Train loss: -0.027 Test loss:  4.718 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1420, Train loss:  0.061 Test loss:  4.413 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1430, Train loss:  0.001 Test loss:  3.270 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1440, Train loss: -0.013 Test loss:  3.442 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1450, Train loss: -0.019 Test loss:  2.402 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1460, Train loss:  0.005 Test loss:  2.780 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1470, Train loss:  0.136 Test loss:  2.786 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1480, Train loss:  0.049 Test loss:  2.618 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1490, Train loss:  0.035 Test loss:  3.568 Ensemble loss:  0.844 RMSE: 1.146 Num. networks:  3\n",
            "Epoch: 1500, Train loss: -0.026 Test loss:  3.612 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1510, Train loss:  0.135 Test loss:  2.191 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1520, Train loss:  0.010 Test loss:  2.533 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1530, Train loss: -0.038 Test loss:  2.623 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1540, Train loss: -0.050 Test loss:  3.066 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1550, Train loss: -0.047 Test loss:  2.461 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1560, Train loss: -0.001 Test loss:  2.451 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1570, Train loss:  0.032 Test loss:  2.559 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1580, Train loss:  0.018 Test loss:  2.863 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1590, Train loss: -0.001 Test loss:  2.861 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1600, Train loss: -0.049 Test loss:  5.352 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1610, Train loss:  0.025 Test loss:  2.957 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1620, Train loss: -0.023 Test loss:  4.684 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1630, Train loss: -0.050 Test loss:  5.916 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1640, Train loss:  0.075 Test loss:  3.789 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1650, Train loss: -0.014 Test loss:  3.139 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1660, Train loss: -0.038 Test loss:  5.592 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1670, Train loss:  0.013 Test loss:  2.634 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1680, Train loss: -0.023 Test loss:  2.613 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1690, Train loss: -0.028 Test loss:  3.236 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1700, Train loss: -0.065 Test loss:  3.119 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1710, Train loss: -0.033 Test loss:  4.159 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1720, Train loss:  0.030 Test loss:  3.654 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1730, Train loss: -0.040 Test loss:  3.309 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1740, Train loss: -0.055 Test loss:  2.688 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1750, Train loss: -0.022 Test loss:  2.351 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1760, Train loss: -0.042 Test loss:  2.039 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1770, Train loss: -0.080 Test loss:  2.638 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1780, Train loss: -0.025 Test loss:  2.419 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1790, Train loss: -0.055 Test loss:  2.086 Ensemble loss:  0.949 RMSE: 1.124 Num. networks:  4\n",
            "Epoch: 1800, Train loss:  0.101 Test loss:  1.651 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1810, Train loss: -0.028 Test loss:  2.574 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1820, Train loss: -0.069 Test loss:  3.160 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1830, Train loss:  0.048 Test loss:  1.743 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1840, Train loss: -0.125 Test loss:  3.282 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1850, Train loss:  0.116 Test loss:  1.307 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1860, Train loss: -0.084 Test loss:  3.275 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1870, Train loss: -0.056 Test loss:  3.314 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1880, Train loss: -0.064 Test loss:  2.865 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1890, Train loss: -0.020 Test loss:  2.855 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1900, Train loss: -0.039 Test loss:  3.320 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1910, Train loss:  0.024 Test loss:  2.199 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1920, Train loss: -0.093 Test loss:  2.940 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1930, Train loss: -0.043 Test loss:  2.380 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1940, Train loss:  0.021 Test loss:  2.203 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1950, Train loss: -0.074 Test loss:  4.370 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1960, Train loss: -0.135 Test loss:  7.956 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1970, Train loss: -0.102 Test loss:  6.776 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1980, Train loss: -0.082 Test loss: 11.522 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 1990, Train loss: -0.015 Test loss: 12.346 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2000, Train loss:  0.134 Test loss:  1.895 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2010, Train loss:  0.051 Test loss:  2.313 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2020, Train loss: -0.072 Test loss:  4.360 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2030, Train loss: -0.077 Test loss:  6.496 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2040, Train loss: -0.104 Test loss:  5.685 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2050, Train loss:  0.080 Test loss:  3.523 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2060, Train loss: -0.108 Test loss: 13.615 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2070, Train loss: -0.045 Test loss:  5.856 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2080, Train loss: -0.002 Test loss:  3.237 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2090, Train loss:  0.059 Test loss:  2.144 Ensemble loss:  0.540 RMSE: 1.063 Num. networks:  5\n",
            "Epoch: 2100, Train loss: -0.038 Test loss:  2.991 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2110, Train loss: -0.133 Test loss:  4.152 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2120, Train loss: -0.121 Test loss:  6.230 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2130, Train loss: -0.111 Test loss:  5.880 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2140, Train loss:  0.025 Test loss:  5.214 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2150, Train loss: -0.017 Test loss:  4.631 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2160, Train loss: -0.010 Test loss:  4.896 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2170, Train loss: -0.042 Test loss:  6.281 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2180, Train loss: -0.002 Test loss:  5.310 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2190, Train loss:  0.069 Test loss:  4.178 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2200, Train loss:  0.004 Test loss: 10.145 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2210, Train loss: -0.091 Test loss: 13.301 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2220, Train loss:  0.081 Test loss:  5.819 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2230, Train loss:  0.184 Test loss:  6.820 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2240, Train loss:  0.017 Test loss:  2.902 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2250, Train loss: -0.031 Test loss:  2.281 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2260, Train loss: -0.055 Test loss:  3.594 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2270, Train loss: -0.061 Test loss:  6.118 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2280, Train loss: -0.065 Test loss:  7.629 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2290, Train loss:  0.033 Test loss:  5.859 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2300, Train loss: -0.148 Test loss: 11.728 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2310, Train loss: -0.021 Test loss:  6.527 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2320, Train loss:  0.040 Test loss:  3.836 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2330, Train loss:  0.027 Test loss:  4.795 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2340, Train loss: -0.103 Test loss:  6.012 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2350, Train loss:  0.224 Test loss:  1.457 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2360, Train loss: -0.122 Test loss:  9.336 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2370, Train loss: -0.084 Test loss:  6.790 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2380, Train loss:  0.149 Test loss:  2.916 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2390, Train loss: -0.067 Test loss:  8.879 Ensemble loss:  0.428 RMSE: 1.018 Num. networks:  6\n",
            "Epoch: 2400, Train loss: -0.115 Test loss: 10.873 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2410, Train loss: -0.052 Test loss:  6.115 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2420, Train loss: -0.043 Test loss:  6.227 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2430, Train loss:  0.045 Test loss:  4.746 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2440, Train loss: -0.052 Test loss:  5.440 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2450, Train loss: -0.019 Test loss:  5.768 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2460, Train loss:  0.254 Test loss:  2.132 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2470, Train loss:  0.045 Test loss:  4.212 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2480, Train loss: -0.061 Test loss:  3.563 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2490, Train loss: -0.061 Test loss:  2.614 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2500, Train loss: -0.075 Test loss:  3.556 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2510, Train loss: -0.061 Test loss:  3.649 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2520, Train loss:  0.069 Test loss:  1.679 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2530, Train loss: -0.110 Test loss:  4.702 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2540, Train loss: -0.103 Test loss:  3.164 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2550, Train loss:  0.095 Test loss:  1.461 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2560, Train loss:  0.008 Test loss:  1.651 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2570, Train loss:  0.097 Test loss:  1.563 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2580, Train loss:  0.261 Test loss:  1.358 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2590, Train loss: -0.069 Test loss:  3.786 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2600, Train loss: -0.038 Test loss:  4.036 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2610, Train loss: -0.129 Test loss:  6.894 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2620, Train loss:  0.208 Test loss:  5.039 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2630, Train loss:  0.100 Test loss:  3.654 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2640, Train loss: -0.093 Test loss:  4.084 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2650, Train loss: -0.002 Test loss:  2.958 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2660, Train loss:  0.265 Test loss:  1.288 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2670, Train loss: -0.070 Test loss:  3.016 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2680, Train loss:  0.014 Test loss:  1.712 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2690, Train loss: -0.114 Test loss:  2.167 Ensemble loss:  0.406 RMSE: 0.995 Num. networks:  7\n",
            "Epoch: 2700, Train loss: -0.002 Test loss:  1.107 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2710, Train loss:  0.120 Test loss:  0.934 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2720, Train loss:  0.047 Test loss:  1.018 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2730, Train loss: -0.190 Test loss:  2.657 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2740, Train loss: -0.155 Test loss:  2.953 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2750, Train loss: -0.153 Test loss:  6.534 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2760, Train loss: -0.075 Test loss:  8.910 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2770, Train loss:  0.315 Test loss:  2.046 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2780, Train loss:  0.013 Test loss:  2.136 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2790, Train loss:  0.108 Test loss:  1.814 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2800, Train loss: -0.045 Test loss:  2.709 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2810, Train loss:  0.088 Test loss:  1.369 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2820, Train loss: -0.093 Test loss:  1.605 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2830, Train loss: -0.099 Test loss:  2.678 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2840, Train loss: -0.144 Test loss:  2.260 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2850, Train loss: -0.018 Test loss:  1.906 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2860, Train loss: -0.030 Test loss:  1.660 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2870, Train loss:  0.057 Test loss:  2.021 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2880, Train loss: -0.069 Test loss:  4.955 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2890, Train loss: -0.089 Test loss:  3.329 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2900, Train loss: -0.130 Test loss:  4.816 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2910, Train loss: -0.023 Test loss:  4.162 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2920, Train loss:  0.033 Test loss:  2.645 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2930, Train loss: -0.145 Test loss:  4.800 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2940, Train loss: -0.148 Test loss:  4.179 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2950, Train loss: -0.178 Test loss:  5.171 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2960, Train loss: -0.126 Test loss:  6.912 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2970, Train loss: -0.198 Test loss:  7.328 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2980, Train loss: -0.193 Test loss:  5.645 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 2990, Train loss: -0.102 Test loss:  6.949 Ensemble loss:  0.413 RMSE: 0.992 Num. networks:  8\n",
            "Epoch: 3000, Train loss:  0.191 Test loss:  3.931 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3010, Train loss:  0.206 Test loss:  1.727 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3020, Train loss: -0.124 Test loss:  3.081 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3030, Train loss: -0.126 Test loss:  3.760 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3040, Train loss:  0.145 Test loss:  4.052 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3050, Train loss: -0.185 Test loss:  3.301 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3060, Train loss: -0.158 Test loss:  2.842 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3070, Train loss: -0.177 Test loss:  4.278 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3080, Train loss: -0.156 Test loss:  3.482 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3090, Train loss:  0.189 Test loss:  2.528 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3100, Train loss:  0.211 Test loss:  1.645 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3110, Train loss:  0.177 Test loss:  1.918 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3120, Train loss: -0.099 Test loss:  2.424 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3130, Train loss: -0.097 Test loss:  2.134 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3140, Train loss: -0.125 Test loss:  1.769 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3150, Train loss: -0.058 Test loss:  1.847 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3160, Train loss:  0.139 Test loss:  1.361 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3170, Train loss: -0.105 Test loss:  1.566 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3180, Train loss: -0.139 Test loss:  2.231 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3190, Train loss: -0.149 Test loss:  2.060 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3200, Train loss:  0.260 Test loss:  0.935 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3210, Train loss:  0.462 Test loss:  0.621 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3220, Train loss:  0.179 Test loss:  0.679 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3230, Train loss: -0.105 Test loss:  1.067 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3240, Train loss: -0.061 Test loss:  0.937 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3250, Train loss: -0.122 Test loss:  1.324 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3260, Train loss:  0.018 Test loss:  0.795 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3270, Train loss: -0.154 Test loss:  1.563 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3280, Train loss: -0.051 Test loss:  1.707 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3290, Train loss: -0.152 Test loss:  2.604 Ensemble loss:  0.403 RMSE: 0.987 Num. networks:  9\n",
            "Epoch: 3300, Train loss:  0.020 Test loss:  2.142 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3310, Train loss: -0.141 Test loss:  3.272 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3320, Train loss: -0.023 Test loss:  3.324 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3330, Train loss:  0.285 Test loss:  2.170 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3340, Train loss: -0.079 Test loss:  2.653 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3350, Train loss: -0.134 Test loss:  2.687 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3360, Train loss: -0.088 Test loss:  2.463 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3370, Train loss:  0.011 Test loss:  2.322 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3380, Train loss: -0.099 Test loss:  2.759 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3390, Train loss: -0.076 Test loss:  1.840 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3400, Train loss: -0.065 Test loss:  1.772 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3410, Train loss: -0.187 Test loss:  2.163 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3420, Train loss: -0.135 Test loss:  2.229 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3430, Train loss: -0.176 Test loss:  2.676 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3440, Train loss: -0.076 Test loss:  2.905 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3450, Train loss: -0.173 Test loss:  2.597 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3460, Train loss: -0.167 Test loss:  4.989 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3470, Train loss: -0.178 Test loss:  3.846 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3480, Train loss: -0.154 Test loss:  4.458 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3490, Train loss:  0.054 Test loss:  1.992 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3500, Train loss: -0.137 Test loss:  4.692 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3510, Train loss: -0.023 Test loss:  8.051 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3520, Train loss:  0.111 Test loss:  1.388 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3530, Train loss:  0.349 Test loss:  0.978 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3540, Train loss:  0.511 Test loss:  0.839 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3550, Train loss:  0.040 Test loss:  1.607 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3560, Train loss: -0.122 Test loss:  2.106 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3570, Train loss: -0.160 Test loss:  2.948 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3580, Train loss: -0.021 Test loss:  2.429 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3590, Train loss:  0.023 Test loss:  1.483 Ensemble loss:  0.399 RMSE: 0.973 Num. networks: 10\n",
            "Epoch: 3600, Train loss: -0.143 Test loss:  2.954 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3610, Train loss: -0.079 Test loss:  2.694 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3620, Train loss: -0.064 Test loss:  3.256 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3630, Train loss: -0.079 Test loss:  2.202 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3640, Train loss: -0.106 Test loss:  2.314 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3650, Train loss:  0.020 Test loss:  2.318 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3660, Train loss: -0.075 Test loss:  4.129 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3670, Train loss: -0.075 Test loss:  3.792 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3680, Train loss:  0.184 Test loss:  2.430 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3690, Train loss:  0.135 Test loss:  3.238 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3700, Train loss: -0.160 Test loss:  8.955 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3710, Train loss: -0.170 Test loss:  9.887 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3720, Train loss: -0.009 Test loss: 14.555 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3730, Train loss:  0.296 Test loss:  5.440 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3740, Train loss: -0.034 Test loss:  6.128 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3750, Train loss: -0.057 Test loss:  6.591 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3760, Train loss:  0.153 Test loss:  3.345 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3770, Train loss:  0.031 Test loss:  5.298 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3780, Train loss: -0.128 Test loss:  5.180 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3790, Train loss: -0.100 Test loss:  6.939 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3800, Train loss: -0.192 Test loss:  4.468 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3810, Train loss: -0.144 Test loss:  5.281 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3820, Train loss:  0.173 Test loss:  1.887 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3830, Train loss:  0.287 Test loss:  1.614 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3840, Train loss: -0.023 Test loss:  3.998 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3850, Train loss:  0.396 Test loss:  2.127 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3860, Train loss:  0.121 Test loss:  1.497 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3870, Train loss:  0.061 Test loss:  1.990 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3880, Train loss: -0.051 Test loss:  4.027 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3890, Train loss:  0.103 Test loss:  1.161 Ensemble loss:  0.380 RMSE: 0.948 Num. networks: 11\n",
            "Epoch: 3900, Train loss: -0.100 Test loss:  5.653 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3910, Train loss: -0.092 Test loss:  4.043 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3920, Train loss: -0.086 Test loss:  6.194 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3930, Train loss:  0.023 Test loss: 11.085 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3940, Train loss:  0.008 Test loss: 14.194 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3950, Train loss: -0.166 Test loss: 16.577 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3960, Train loss: -0.087 Test loss: 15.850 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3970, Train loss: -0.086 Test loss: 28.767 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3980, Train loss: -0.121 Test loss: 40.603 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 3990, Train loss: -0.112 Test loss: 30.570 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4000, Train loss: -0.194 Test loss: 42.510 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4010, Train loss: -0.195 Test loss: 35.906 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4020, Train loss: -0.149 Test loss: 20.785 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4030, Train loss: -0.198 Test loss: 19.173 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4040, Train loss: -0.190 Test loss: 34.125 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4050, Train loss: -0.133 Test loss: 30.170 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4060, Train loss: -0.073 Test loss: 29.503 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4070, Train loss: -0.187 Test loss: 28.821 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4080, Train loss: -0.230 Test loss: 32.834 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4090, Train loss: -0.186 Test loss: 25.692 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4100, Train loss: -0.150 Test loss: 23.295 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4110, Train loss: -0.171 Test loss: 39.701 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4120, Train loss: -0.150 Test loss: 41.495 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4130, Train loss: -0.192 Test loss: 89.727 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4140, Train loss: -0.100 Test loss: 65.229 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4150, Train loss: -0.178 Test loss: 119.784 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4160, Train loss: -0.158 Test loss: 83.458 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4170, Train loss: -0.173 Test loss: 92.010 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4180, Train loss: -0.191 Test loss: 367.186 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4190, Train loss: -0.098 Test loss: 70.141 Ensemble loss:  0.368 RMSE: 0.934 Num. networks: 12\n",
            "Epoch: 4200, Train loss: -0.106 Test loss: 43.327 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4210, Train loss: -0.121 Test loss: 43.372 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4220, Train loss: -0.181 Test loss: 48.209 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4230, Train loss:  0.019 Test loss: 37.992 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4240, Train loss: -0.133 Test loss: 45.808 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4250, Train loss: -0.129 Test loss: 74.722 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4260, Train loss: -0.081 Test loss: 64.000 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4270, Train loss:  0.209 Test loss: 22.626 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4280, Train loss:  0.005 Test loss: 11.194 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4290, Train loss: -0.099 Test loss: 22.463 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4300, Train loss: -0.007 Test loss: 30.253 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4310, Train loss: -0.130 Test loss: 33.571 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4320, Train loss: -0.125 Test loss: 25.864 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4330, Train loss: -0.014 Test loss: 24.864 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4340, Train loss:  0.012 Test loss: 24.902 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4350, Train loss:  0.001 Test loss: 26.141 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4360, Train loss:  0.034 Test loss: 22.549 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4370, Train loss: -0.110 Test loss: 24.455 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4380, Train loss: -0.085 Test loss: 23.678 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4390, Train loss: -0.090 Test loss: 22.374 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4400, Train loss:  0.353 Test loss:  7.419 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4410, Train loss: -0.155 Test loss: 20.391 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4420, Train loss: -0.013 Test loss: 18.672 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4430, Train loss:  0.016 Test loss: 18.926 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4440, Train loss: -0.143 Test loss: 19.626 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4450, Train loss: -0.115 Test loss: 24.187 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4460, Train loss: -0.178 Test loss: 37.691 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4470, Train loss: -0.172 Test loss: 32.766 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4480, Train loss: -0.123 Test loss: 21.153 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4490, Train loss: -0.149 Test loss: 16.715 Ensemble loss:  0.376 RMSE: 0.928 Num. networks: 13\n",
            "Epoch: 4500, Train loss: -0.167 Test loss: 24.620 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4510, Train loss: -0.036 Test loss: 13.435 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4520, Train loss:  0.027 Test loss:  9.445 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4530, Train loss: -0.131 Test loss: 23.622 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4540, Train loss: -0.103 Test loss: 15.139 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4550, Train loss:  0.163 Test loss: 11.906 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4560, Train loss: -0.105 Test loss: 25.597 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4570, Train loss:  0.195 Test loss: 11.981 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4580, Train loss: -0.081 Test loss: 16.672 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4590, Train loss: -0.186 Test loss: 16.039 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4600, Train loss: -0.167 Test loss: 15.750 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4610, Train loss: -0.199 Test loss: 22.269 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4620, Train loss: -0.209 Test loss: 29.423 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4630, Train loss: -0.145 Test loss: 19.097 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4640, Train loss: -0.149 Test loss: 22.009 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4650, Train loss:  0.316 Test loss:  9.260 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4660, Train loss:  0.024 Test loss: 15.967 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4670, Train loss: -0.120 Test loss: 15.076 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4680, Train loss:  0.074 Test loss:  8.108 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4690, Train loss:  0.059 Test loss: 10.733 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4700, Train loss: -0.171 Test loss: 22.646 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4710, Train loss: -0.022 Test loss: 11.908 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4720, Train loss: -0.182 Test loss: 18.738 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4730, Train loss: -0.173 Test loss:  9.168 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4740, Train loss: -0.180 Test loss: 13.121 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4750, Train loss: -0.046 Test loss:  8.314 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4760, Train loss: -0.113 Test loss:  7.486 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4770, Train loss:  0.162 Test loss:  3.627 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4780, Train loss: -0.128 Test loss: 10.008 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4790, Train loss: -0.014 Test loss: 18.345 Ensemble loss:  0.384 RMSE: 0.934 Num. networks: 14\n",
            "Epoch: 4800, Train loss: -0.054 Test loss:  8.945 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4810, Train loss: -0.143 Test loss: 10.668 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4820, Train loss:  0.130 Test loss:  4.507 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4830, Train loss: -0.157 Test loss:  9.984 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4840, Train loss:  0.327 Test loss:  2.703 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4850, Train loss:  0.004 Test loss:  6.414 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4860, Train loss: -0.005 Test loss:  5.097 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4870, Train loss:  0.255 Test loss:  2.900 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4880, Train loss:  0.160 Test loss:  4.692 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4890, Train loss:  0.182 Test loss:  6.501 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4900, Train loss:  0.783 Test loss:  2.695 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4910, Train loss:  0.493 Test loss:  2.358 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4920, Train loss: -0.034 Test loss:  9.192 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4930, Train loss: -0.019 Test loss: 14.552 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4940, Train loss:  0.111 Test loss:  5.164 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4950, Train loss:  0.379 Test loss:  3.339 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4960, Train loss: -0.082 Test loss:  4.587 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4970, Train loss:  0.041 Test loss:  5.686 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4980, Train loss:  0.070 Test loss:  2.086 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 4990, Train loss: -0.106 Test loss:  7.445 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5000, Train loss:  0.610 Test loss:  1.723 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5010, Train loss: -0.168 Test loss:  5.179 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5020, Train loss:  0.089 Test loss:  2.777 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5030, Train loss: -0.162 Test loss:  5.532 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5040, Train loss: -0.194 Test loss:  5.528 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5050, Train loss:  0.128 Test loss:  1.814 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5060, Train loss:  0.124 Test loss:  2.178 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5070, Train loss: -0.209 Test loss:  4.853 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5080, Train loss: -0.191 Test loss:  3.453 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5090, Train loss: -0.134 Test loss:  3.590 Ensemble loss:  0.399 RMSE: 0.938 Num. networks: 15\n",
            "Epoch: 5100, Train loss:  0.173 Test loss:  1.950 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5110, Train loss: -0.036 Test loss:  2.813 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5120, Train loss:  0.054 Test loss:  2.415 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5130, Train loss: -0.066 Test loss:  3.371 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5140, Train loss: -0.177 Test loss:  4.710 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5150, Train loss: -0.216 Test loss:  4.988 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5160, Train loss: -0.150 Test loss:  3.516 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5170, Train loss: -0.144 Test loss:  4.875 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5180, Train loss: -0.222 Test loss:  4.079 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5190, Train loss: -0.156 Test loss:  4.266 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5200, Train loss: -0.183 Test loss:  3.976 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5210, Train loss: -0.186 Test loss:  2.884 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5220, Train loss: -0.166 Test loss:  3.081 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5230, Train loss: -0.069 Test loss:  2.817 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5240, Train loss: -0.086 Test loss:  3.049 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5250, Train loss: -0.080 Test loss:  2.367 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5260, Train loss: -0.186 Test loss:  3.228 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5270, Train loss: -0.194 Test loss:  4.464 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5280, Train loss: -0.156 Test loss:  3.939 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5290, Train loss: -0.108 Test loss:  3.337 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5300, Train loss:  0.070 Test loss:  2.628 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5310, Train loss: -0.208 Test loss:  3.477 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5320, Train loss: -0.191 Test loss:  2.408 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5330, Train loss: -0.217 Test loss:  2.114 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5340, Train loss:  0.135 Test loss:  1.178 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5350, Train loss:  0.102 Test loss:  1.206 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5360, Train loss:  0.019 Test loss:  1.551 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5370, Train loss: -0.211 Test loss:  2.716 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5380, Train loss: -0.213 Test loss:  2.739 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5390, Train loss: -0.188 Test loss:  2.392 Ensemble loss:  0.408 RMSE: 0.933 Num. networks: 16\n",
            "Epoch: 5400, Train loss:  0.031 Test loss:  1.586 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5410, Train loss:  0.002 Test loss:  1.234 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5420, Train loss: -0.188 Test loss:  2.453 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5430, Train loss: -0.202 Test loss:  2.422 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5440, Train loss: -0.192 Test loss:  2.062 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5450, Train loss: -0.185 Test loss:  1.538 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5460, Train loss: -0.203 Test loss:  1.885 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5470, Train loss: -0.129 Test loss:  2.011 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5480, Train loss: -0.144 Test loss:  1.666 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5490, Train loss: -0.053 Test loss:  1.582 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5500, Train loss: -0.132 Test loss:  2.591 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5510, Train loss: -0.129 Test loss:  2.075 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5520, Train loss: -0.012 Test loss:  1.560 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5530, Train loss: -0.231 Test loss:  2.701 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5540, Train loss: -0.258 Test loss:  3.040 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5550, Train loss: -0.215 Test loss:  2.986 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5560, Train loss:  0.174 Test loss:  1.496 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5570, Train loss:  0.223 Test loss:  1.214 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5580, Train loss: -0.215 Test loss:  2.249 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5590, Train loss: -0.137 Test loss:  1.713 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5600, Train loss: -0.257 Test loss:  2.865 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5610, Train loss:  0.214 Test loss:  0.996 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5620, Train loss:  0.098 Test loss:  1.315 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5630, Train loss: -0.205 Test loss:  3.107 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5640, Train loss: -0.236 Test loss:  2.590 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5650, Train loss: -0.090 Test loss:  2.290 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5660, Train loss: -0.221 Test loss:  3.985 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5670, Train loss: -0.225 Test loss:  3.639 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5680, Train loss: -0.050 Test loss:  1.554 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5690, Train loss:  0.028 Test loss:  1.189 Ensemble loss:  0.398 RMSE: 0.933 Num. networks: 17\n",
            "Epoch: 5700, Train loss: -0.166 Test loss:  1.582 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5710, Train loss: -0.060 Test loss:  1.191 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5720, Train loss: -0.163 Test loss:  1.714 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5730, Train loss: -0.022 Test loss:  1.467 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5740, Train loss: -0.068 Test loss:  1.672 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5750, Train loss: -0.162 Test loss:  2.427 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5760, Train loss: -0.114 Test loss:  1.962 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5770, Train loss: -0.206 Test loss:  4.401 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5780, Train loss: -0.127 Test loss:  2.453 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5790, Train loss: -0.031 Test loss:  1.732 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5800, Train loss: -0.175 Test loss:  3.497 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5810, Train loss: -0.160 Test loss:  2.700 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5820, Train loss: -0.134 Test loss:  3.191 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5830, Train loss: -0.216 Test loss:  4.025 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5840, Train loss: -0.132 Test loss:  2.221 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5850, Train loss: -0.112 Test loss:  2.220 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5860, Train loss: -0.212 Test loss:  3.044 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5870, Train loss:  0.156 Test loss:  2.050 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5880, Train loss: -0.184 Test loss:  2.549 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5890, Train loss: -0.229 Test loss:  1.806 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5900, Train loss: -0.242 Test loss:  3.171 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5910, Train loss: -0.236 Test loss:  6.143 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5920, Train loss:  0.061 Test loss:  1.793 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5930, Train loss:  0.151 Test loss:  4.804 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5940, Train loss:  0.205 Test loss:  1.857 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5950, Train loss:  0.086 Test loss:  1.113 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5960, Train loss: -0.190 Test loss:  0.882 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5970, Train loss: -0.066 Test loss:  0.823 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5980, Train loss:  0.028 Test loss:  0.464 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 5990, Train loss: -0.197 Test loss:  0.787 Ensemble loss:  0.394 RMSE: 0.930 Num. networks: 18\n",
            "Epoch: 6000, Train loss: -0.128 Test loss:  0.917 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6010, Train loss: -0.219 Test loss:  0.971 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6020, Train loss:  0.022 Test loss:  0.680 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6030, Train loss:  0.105 Test loss:  0.941 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6040, Train loss: -0.061 Test loss:  1.870 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6050, Train loss:  0.257 Test loss:  0.805 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6060, Train loss: -0.196 Test loss:  1.275 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6070, Train loss: -0.209 Test loss:  1.774 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6080, Train loss: -0.174 Test loss:  1.575 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6090, Train loss: -0.164 Test loss:  1.241 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6100, Train loss:  0.074 Test loss:  0.748 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6110, Train loss: -0.112 Test loss:  1.741 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6120, Train loss: -0.097 Test loss:  1.279 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6130, Train loss:  0.014 Test loss:  1.323 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6140, Train loss: -0.136 Test loss:  1.557 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6150, Train loss: -0.135 Test loss:  1.673 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6160, Train loss: -0.227 Test loss:  2.466 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6170, Train loss:  0.007 Test loss:  1.371 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6180, Train loss: -0.109 Test loss:  2.511 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6190, Train loss:  0.161 Test loss:  1.213 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6200, Train loss:  0.560 Test loss:  1.251 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6210, Train loss:  0.050 Test loss:  1.762 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6220, Train loss:  0.059 Test loss:  1.087 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6230, Train loss: -0.250 Test loss:  2.604 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6240, Train loss: -0.256 Test loss:  1.972 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6250, Train loss:  0.333 Test loss:  1.075 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6260, Train loss: -0.183 Test loss:  3.928 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6270, Train loss:  0.049 Test loss:  2.173 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6280, Train loss:  0.248 Test loss:  0.871 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6290, Train loss: -0.199 Test loss:  2.789 Ensemble loss:  0.387 RMSE: 0.928 Num. networks: 19\n",
            "Epoch: 6300, Train loss: -0.241 Test loss:  1.987 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6310, Train loss: -0.194 Test loss:  1.663 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6320, Train loss:  0.497 Test loss:  0.603 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6330, Train loss:  0.184 Test loss:  0.964 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6340, Train loss:  0.452 Test loss:  0.658 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6350, Train loss: -0.144 Test loss:  2.323 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6360, Train loss: -0.230 Test loss:  3.779 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6370, Train loss: -0.242 Test loss:  6.221 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6380, Train loss: -0.233 Test loss:  5.076 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6390, Train loss: -0.242 Test loss:  3.012 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6400, Train loss:  0.010 Test loss:  2.003 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6410, Train loss: -0.018 Test loss:  3.584 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6420, Train loss: -0.107 Test loss:  5.583 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6430, Train loss: -0.168 Test loss:  6.278 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6440, Train loss: -0.146 Test loss:  9.216 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6450, Train loss:  0.600 Test loss:  1.927 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6460, Train loss: -0.243 Test loss:  4.757 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6470, Train loss: -0.215 Test loss:  3.830 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6480, Train loss: -0.207 Test loss:  3.902 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6490, Train loss: -0.179 Test loss:  5.085 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6500, Train loss:  0.359 Test loss:  2.385 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6510, Train loss: -0.001 Test loss:  1.968 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6520, Train loss: -0.184 Test loss:  3.120 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6530, Train loss: -0.210 Test loss:  3.124 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6540, Train loss: -0.156 Test loss:  2.879 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6550, Train loss:  0.046 Test loss:  1.650 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6560, Train loss:  0.340 Test loss:  1.276 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6570, Train loss:  0.091 Test loss:  1.453 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6580, Train loss: -0.166 Test loss:  2.475 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6590, Train loss: -0.191 Test loss:  3.036 Ensemble loss:  0.378 RMSE: 0.925 Num. networks: 20\n",
            "Epoch: 6600, Train loss: -0.188 Test loss:  2.364 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6610, Train loss: -0.105 Test loss:  1.424 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6620, Train loss:  0.254 Test loss:  0.929 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6630, Train loss: -0.223 Test loss:  2.611 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6640, Train loss: -0.221 Test loss:  2.621 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6650, Train loss: -0.009 Test loss:  1.052 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6660, Train loss:  0.003 Test loss:  3.132 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6670, Train loss: -0.213 Test loss:  3.474 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6680, Train loss: -0.195 Test loss:  2.219 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6690, Train loss: -0.027 Test loss:  1.963 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6700, Train loss:  0.551 Test loss:  1.185 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6710, Train loss: -0.236 Test loss:  1.968 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6720, Train loss: -0.229 Test loss:  2.628 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6730, Train loss: -0.220 Test loss:  3.246 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6740, Train loss: -0.236 Test loss:  2.838 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6750, Train loss: -0.196 Test loss:  2.078 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6760, Train loss: -0.167 Test loss:  1.818 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6770, Train loss:  0.065 Test loss:  2.844 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6780, Train loss: -0.175 Test loss:  4.017 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6790, Train loss: -0.163 Test loss:  3.699 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6800, Train loss: -0.226 Test loss:  4.077 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6810, Train loss: -0.134 Test loss:  3.234 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6820, Train loss: -0.164 Test loss:  5.742 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6830, Train loss: -0.169 Test loss:  5.309 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6840, Train loss: -0.216 Test loss:  3.792 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6850, Train loss: -0.217 Test loss:  6.426 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6860, Train loss: -0.164 Test loss:  5.860 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6870, Train loss: -0.104 Test loss:  4.901 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6880, Train loss:  0.077 Test loss:  2.877 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6890, Train loss: -0.195 Test loss:  3.548 Ensemble loss:  0.371 RMSE: 0.919 Num. networks: 21\n",
            "Epoch: 6900, Train loss:  0.053 Test loss:  2.366 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6910, Train loss:  0.070 Test loss:  3.711 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6920, Train loss:  0.071 Test loss:  4.043 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6930, Train loss:  0.038 Test loss:  3.693 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6940, Train loss: -0.067 Test loss:  4.161 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6950, Train loss: -0.129 Test loss:  4.742 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6960, Train loss: -0.124 Test loss:  4.379 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6970, Train loss: -0.200 Test loss:  5.074 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6980, Train loss: -0.209 Test loss:  4.452 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 6990, Train loss: -0.215 Test loss:  3.937 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7000, Train loss: -0.129 Test loss:  2.968 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7010, Train loss:  0.123 Test loss:  2.280 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7020, Train loss: -0.076 Test loss:  3.400 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7030, Train loss:  0.125 Test loss:  3.843 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7040, Train loss: -0.209 Test loss:  6.402 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7050, Train loss: -0.201 Test loss:  7.952 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7060, Train loss: -0.159 Test loss: 14.817 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7070, Train loss:  0.402 Test loss:  4.347 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7080, Train loss:  0.158 Test loss:  1.302 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7090, Train loss: -0.233 Test loss:  3.903 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7100, Train loss: -0.171 Test loss:  3.019 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7110, Train loss: -0.170 Test loss:  2.910 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7120, Train loss: -0.241 Test loss:  3.519 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7130, Train loss: -0.220 Test loss:  3.399 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7140, Train loss:  0.088 Test loss:  1.965 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7150, Train loss: -0.021 Test loss:  2.261 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7160, Train loss: -0.265 Test loss:  7.330 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7170, Train loss: -0.265 Test loss:  6.744 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7180, Train loss: -0.271 Test loss:  6.980 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7190, Train loss:  0.602 Test loss:  0.991 Ensemble loss:  0.370 RMSE: 0.915 Num. networks: 22\n",
            "Epoch: 7200, Train loss:  0.046 Test loss:  2.682 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7210, Train loss:  0.046 Test loss:  4.621 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7220, Train loss: -0.134 Test loss:  4.438 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7230, Train loss: -0.266 Test loss:  9.821 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7240, Train loss: -0.215 Test loss: 29.439 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7250, Train loss: -0.264 Test loss: 20.782 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7260, Train loss: -0.235 Test loss: 23.699 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7270, Train loss:  0.003 Test loss:  4.630 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7280, Train loss:  0.125 Test loss:  4.088 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7290, Train loss:  0.110 Test loss:  2.081 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7300, Train loss:  0.263 Test loss:  3.174 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7310, Train loss:  0.050 Test loss:  5.038 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7320, Train loss: -0.234 Test loss:  9.568 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7330, Train loss:  0.002 Test loss:  6.878 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7340, Train loss: -0.208 Test loss: 14.880 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7350, Train loss: -0.257 Test loss: 14.001 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7360, Train loss: -0.164 Test loss: 12.207 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7370, Train loss: -0.226 Test loss: 16.545 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7380, Train loss: -0.189 Test loss: 12.221 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7390, Train loss: -0.222 Test loss: 16.468 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7400, Train loss: -0.030 Test loss:  4.543 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7410, Train loss: -0.222 Test loss:  6.166 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7420, Train loss: -0.221 Test loss:  5.116 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7430, Train loss: -0.211 Test loss:  8.450 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7440, Train loss: -0.228 Test loss:  7.063 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7450, Train loss: -0.018 Test loss:  5.930 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7460, Train loss: -0.162 Test loss:  7.152 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7470, Train loss: -0.061 Test loss:  6.138 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7480, Train loss: -0.211 Test loss: 10.831 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7490, Train loss: -0.211 Test loss:  6.529 Ensemble loss:  0.373 RMSE: 0.912 Num. networks: 23\n",
            "Epoch: 7500, Train loss: -0.174 Test loss:  4.358 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7510, Train loss: -0.151 Test loss:  2.194 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7520, Train loss:  0.057 Test loss:  1.638 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7530, Train loss: -0.108 Test loss:  2.271 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7540, Train loss: -0.175 Test loss:  2.846 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7550, Train loss: -0.227 Test loss:  4.943 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7560, Train loss: -0.185 Test loss:  6.229 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7570, Train loss: -0.156 Test loss:  8.255 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7580, Train loss: -0.231 Test loss:  4.586 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7590, Train loss: -0.044 Test loss:  2.037 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7600, Train loss: -0.010 Test loss:  2.253 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7610, Train loss:  0.003 Test loss:  1.883 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7620, Train loss: -0.218 Test loss:  3.940 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7630, Train loss:  0.098 Test loss:  2.427 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7640, Train loss: -0.239 Test loss:  2.373 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7650, Train loss: -0.138 Test loss:  3.695 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7660, Train loss:  0.096 Test loss:  3.792 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7670, Train loss: -0.163 Test loss:  3.801 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7680, Train loss:  0.248 Test loss:  3.010 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7690, Train loss: -0.063 Test loss:  2.716 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7700, Train loss: -0.208 Test loss:  3.285 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7710, Train loss: -0.139 Test loss:  2.993 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7720, Train loss:  0.034 Test loss:  2.280 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7730, Train loss: -0.040 Test loss:  1.953 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7740, Train loss: -0.245 Test loss:  4.806 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7750, Train loss: -0.042 Test loss:  3.507 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7760, Train loss:  0.313 Test loss:  2.159 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7770, Train loss:  0.080 Test loss:  1.942 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7780, Train loss: -0.198 Test loss:  4.079 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7790, Train loss: -0.232 Test loss:  6.123 Ensemble loss:  0.370 RMSE: 0.911 Num. networks: 24\n",
            "Epoch: 7800, Train loss: -0.254 Test loss:  7.139 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7810, Train loss: -0.248 Test loss:  5.389 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7820, Train loss: -0.198 Test loss:  3.209 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7830, Train loss: -0.225 Test loss:  4.756 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7840, Train loss: -0.183 Test loss:  2.724 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7850, Train loss: -0.199 Test loss:  2.552 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7860, Train loss: -0.218 Test loss:  2.575 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7870, Train loss: -0.198 Test loss:  1.966 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7880, Train loss: -0.023 Test loss:  1.750 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7890, Train loss: -0.103 Test loss:  2.147 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7900, Train loss: -0.204 Test loss:  2.614 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7910, Train loss: -0.218 Test loss:  2.454 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7920, Train loss: -0.214 Test loss:  2.662 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7930, Train loss:  0.042 Test loss:  1.564 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7940, Train loss: -0.252 Test loss:  3.373 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7950, Train loss: -0.091 Test loss:  3.387 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7960, Train loss: -0.030 Test loss:  1.762 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7970, Train loss:  0.406 Test loss:  1.001 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7980, Train loss: -0.030 Test loss:  2.091 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 7990, Train loss:  0.206 Test loss:  1.840 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8000, Train loss: -0.035 Test loss:  1.390 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8010, Train loss: -0.224 Test loss:  3.094 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8020, Train loss: -0.189 Test loss:  2.626 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8030, Train loss: -0.153 Test loss:  1.952 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8040, Train loss: -0.091 Test loss:  1.854 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8050, Train loss: -0.063 Test loss:  1.330 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8060, Train loss: -0.244 Test loss:  2.009 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8070, Train loss: -0.072 Test loss:  1.441 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8080, Train loss: -0.231 Test loss:  1.840 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8090, Train loss: -0.255 Test loss:  1.940 Ensemble loss:  0.377 RMSE: 0.913 Num. networks: 25\n",
            "Epoch: 8100, Train loss: -0.270 Test loss:  2.012 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8110, Train loss: -0.138 Test loss:  1.910 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8120, Train loss:  0.301 Test loss:  1.095 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8130, Train loss: -0.050 Test loss:  1.014 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8140, Train loss: -0.105 Test loss:  1.481 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8150, Train loss: -0.073 Test loss:  2.360 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8160, Train loss: -0.266 Test loss:  1.934 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8170, Train loss: -0.282 Test loss:  2.906 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8180, Train loss: -0.241 Test loss:  2.601 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8190, Train loss: -0.263 Test loss:  3.042 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8200, Train loss: -0.165 Test loss:  1.672 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8210, Train loss: -0.042 Test loss:  1.446 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8220, Train loss: -0.250 Test loss:  3.194 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8230, Train loss: -0.266 Test loss:  3.763 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8240, Train loss: -0.133 Test loss:  1.651 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8250, Train loss: -0.263 Test loss:  3.233 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8260, Train loss: -0.266 Test loss:  3.502 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8270, Train loss: -0.276 Test loss:  3.420 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8280, Train loss: -0.229 Test loss:  3.119 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8290, Train loss:  0.063 Test loss:  4.491 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8300, Train loss: -0.025 Test loss:  8.562 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8310, Train loss:  0.281 Test loss:  2.284 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8320, Train loss:  0.019 Test loss:  4.256 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8330, Train loss:  0.081 Test loss:  3.517 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8340, Train loss:  0.295 Test loss:  3.515 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8350, Train loss: -0.259 Test loss:  3.628 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8360, Train loss: -0.238 Test loss:  2.583 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8370, Train loss: -0.098 Test loss:  1.803 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8380, Train loss: -0.055 Test loss:  1.574 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8390, Train loss: -0.041 Test loss:  1.934 Ensemble loss:  0.369 RMSE: 0.911 Num. networks: 26\n",
            "Epoch: 8400, Train loss: -0.232 Test loss:  3.920 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8410, Train loss: -0.156 Test loss:  4.486 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8420, Train loss: -0.233 Test loss:  5.054 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8430, Train loss: -0.110 Test loss:  3.609 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8440, Train loss: -0.099 Test loss:  3.715 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8450, Train loss: -0.162 Test loss:  2.594 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8460, Train loss: -0.216 Test loss:  3.627 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8470, Train loss: -0.023 Test loss:  3.364 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8480, Train loss: -0.023 Test loss:  2.923 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8490, Train loss:  0.105 Test loss:  1.940 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8500, Train loss:  0.091 Test loss:  2.765 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8510, Train loss:  0.244 Test loss:  1.466 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8520, Train loss: -0.117 Test loss:  2.503 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8530, Train loss: -0.156 Test loss:  4.152 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8540, Train loss:  0.343 Test loss:  1.717 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8550, Train loss: -0.106 Test loss:  3.080 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8560, Train loss: -0.015 Test loss:  2.177 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8570, Train loss: -0.190 Test loss:  3.575 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8580, Train loss: -0.222 Test loss:  4.896 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8590, Train loss: -0.082 Test loss:  3.361 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8600, Train loss:  0.075 Test loss:  1.859 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8610, Train loss: -0.114 Test loss:  2.523 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8620, Train loss:  0.015 Test loss:  2.723 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8630, Train loss:  0.023 Test loss:  2.751 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8640, Train loss: -0.098 Test loss:  3.592 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8650, Train loss:  0.144 Test loss:  1.361 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8660, Train loss: -0.206 Test loss:  5.093 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8670, Train loss: -0.160 Test loss:  4.618 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8680, Train loss: -0.209 Test loss:  4.157 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8690, Train loss: -0.221 Test loss:  4.455 Ensemble loss:  0.344 RMSE: 0.909 Num. networks: 27\n",
            "Epoch: 8700, Train loss: -0.265 Test loss:  3.873 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8710, Train loss: -0.256 Test loss:  3.097 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8720, Train loss: -0.231 Test loss:  2.642 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8730, Train loss: -0.244 Test loss:  2.594 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8740, Train loss:  0.074 Test loss:  3.210 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8750, Train loss:  0.121 Test loss:  2.517 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8760, Train loss:  0.070 Test loss:  1.470 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8770, Train loss: -0.108 Test loss:  2.055 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8780, Train loss: -0.209 Test loss:  2.548 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8790, Train loss: -0.089 Test loss:  2.317 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8800, Train loss: -0.216 Test loss:  2.609 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8810, Train loss: -0.047 Test loss:  1.031 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8820, Train loss: -0.040 Test loss:  0.888 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8830, Train loss:  0.052 Test loss:  1.976 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8840, Train loss: -0.211 Test loss:  1.844 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8850, Train loss: -0.209 Test loss:  1.573 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8860, Train loss: -0.176 Test loss:  1.581 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8870, Train loss: -0.078 Test loss:  1.291 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8880, Train loss: -0.092 Test loss:  1.068 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8890, Train loss: -0.223 Test loss:  1.419 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8900, Train loss: -0.183 Test loss:  1.466 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8910, Train loss: -0.209 Test loss:  1.654 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8920, Train loss: -0.040 Test loss:  1.873 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8930, Train loss:  0.512 Test loss:  1.026 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8940, Train loss:  0.008 Test loss:  0.886 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8950, Train loss: -0.158 Test loss:  0.964 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8960, Train loss: -0.041 Test loss:  1.541 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8970, Train loss:  0.059 Test loss:  0.893 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8980, Train loss: -0.163 Test loss:  1.162 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 8990, Train loss: -0.274 Test loss:  1.119 Ensemble loss:  0.316 RMSE: 0.907 Num. networks: 28\n",
            "Epoch: 9000, Train loss: -0.222 Test loss:  1.564 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9010, Train loss: -0.261 Test loss:  1.266 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9020, Train loss: -0.243 Test loss:  1.220 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9030, Train loss: -0.194 Test loss:  1.625 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9040, Train loss:  0.024 Test loss:  1.097 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9050, Train loss: -0.205 Test loss:  1.157 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9060, Train loss: -0.234 Test loss:  1.476 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9070, Train loss: -0.250 Test loss:  1.583 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9080, Train loss: -0.202 Test loss:  2.137 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9090, Train loss:  0.183 Test loss:  0.857 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9100, Train loss:  0.048 Test loss:  0.797 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9110, Train loss: -0.223 Test loss:  1.175 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9120, Train loss: -0.242 Test loss:  1.485 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9130, Train loss: -0.251 Test loss:  1.178 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9140, Train loss: -0.225 Test loss:  1.410 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9150, Train loss: -0.220 Test loss:  1.312 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9160, Train loss: -0.232 Test loss:  1.552 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9170, Train loss: -0.192 Test loss:  1.667 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9180, Train loss: -0.163 Test loss:  1.707 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9190, Train loss: -0.140 Test loss:  1.959 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9200, Train loss: -0.060 Test loss:  1.533 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9210, Train loss: -0.166 Test loss:  1.476 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9220, Train loss: -0.226 Test loss:  1.823 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9230, Train loss: -0.145 Test loss:  1.746 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9240, Train loss:  0.240 Test loss:  0.799 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9250, Train loss: -0.204 Test loss:  0.968 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9260, Train loss: -0.032 Test loss:  0.698 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9270, Train loss:  0.279 Test loss:  0.698 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9280, Train loss: -0.221 Test loss:  1.348 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9290, Train loss: -0.143 Test loss:  1.746 Ensemble loss:  0.295 RMSE: 0.902 Num. networks: 29\n",
            "Epoch: 9300, Train loss:  0.014 Test loss:  1.485 Ensemble loss:  0.275 RMSE: 0.896 Num. networks: 30\n",
            "Epoch: 9310, Train loss: -0.016 Test loss:  0.618 Ensemble loss:  0.275 RMSE: 0.896 Num. networks: 30\n",
            "Epoch: 9320, Train loss: -0.188 Test loss:  0.981 Ensemble loss:  0.275 RMSE: 0.896 Num. networks: 30\n",
            "Epoch: 9330, Train loss: -0.185 Test loss:  0.900 Ensemble loss:  0.275 RMSE: 0.896 Num. networks: 30\n",
            "Epoch: 9340, Train loss: -0.170 Test loss:  1.758 Ensemble loss:  0.275 RMSE: 0.896 Num. networks: 30\n",
            "Epoch: 9350, Train loss: -0.176 Test loss:  1.317 Ensemble loss:  0.275 RMSE: 0.896 Num. networks: 30\n",
            "FOLD 9:\n",
            "Epoch:    0, Train loss: 18.451 Test loss: 12.320 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   10, Train loss:  4.875 Test loss:  4.332 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   20, Train loss:  3.412 Test loss:  3.170 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   30, Train loss:  2.875 Test loss:  2.721 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   40, Train loss:  2.616 Test loss:  2.488 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   50, Train loss:  2.477 Test loss:  2.371 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   60, Train loss:  2.378 Test loss:  2.296 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   70, Train loss:  2.325 Test loss:  2.250 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   80, Train loss:  2.294 Test loss:  2.227 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:   90, Train loss:  2.269 Test loss:  2.215 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  100, Train loss:  2.268 Test loss:  2.213 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  110, Train loss:  2.252 Test loss:  2.201 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  120, Train loss:  2.246 Test loss:  2.194 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  130, Train loss:  2.242 Test loss:  2.189 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  140, Train loss:  2.238 Test loss:  2.189 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  150, Train loss:  2.230 Test loss:  2.182 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  160, Train loss:  2.224 Test loss:  2.181 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  170, Train loss:  2.220 Test loss:  2.176 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  180, Train loss:  2.210 Test loss:  2.168 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  190, Train loss:  2.208 Test loss:  2.163 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  200, Train loss:  2.201 Test loss:  2.152 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  210, Train loss:  2.189 Test loss:  2.141 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  220, Train loss:  2.184 Test loss:  2.138 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  230, Train loss:  2.175 Test loss:  2.129 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  240, Train loss:  2.165 Test loss:  2.119 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  250, Train loss:  2.148 Test loss:  2.102 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  260, Train loss:  2.144 Test loss:  2.099 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  270, Train loss:  2.131 Test loss:  2.083 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  280, Train loss:  2.118 Test loss:  2.069 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  290, Train loss:  2.123 Test loss:  2.072 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  300, Train loss:  2.104 Test loss:  2.053 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  310, Train loss:  2.082 Test loss:  2.033 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  320, Train loss:  2.063 Test loss:  2.011 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  330, Train loss:  2.059 Test loss:  2.009 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  340, Train loss:  2.040 Test loss:  1.987 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  350, Train loss:  2.010 Test loss:  1.956 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  360, Train loss:  1.976 Test loss:  1.923 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  370, Train loss:  1.935 Test loss:  1.876 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  380, Train loss:  1.885 Test loss:  1.829 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  390, Train loss:  1.827 Test loss:  1.760 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  400, Train loss:  1.739 Test loss:  1.668 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  410, Train loss:  1.635 Test loss:  1.551 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  420, Train loss:  1.442 Test loss:  1.344 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  430, Train loss:  1.157 Test loss:  1.010 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  440, Train loss:  0.985 Test loss:  0.782 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  450, Train loss:  0.899 Test loss:  0.735 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  460, Train loss:  0.832 Test loss:  0.667 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  470, Train loss:  0.775 Test loss:  0.662 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  480, Train loss:  0.726 Test loss:  0.654 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  490, Train loss:  0.679 Test loss:  0.666 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  500, Train loss:  0.636 Test loss:  0.628 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  510, Train loss:  0.596 Test loss:  0.627 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  520, Train loss:  0.572 Test loss:  0.589 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  530, Train loss:  0.535 Test loss:  0.575 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  540, Train loss:  0.503 Test loss:  0.596 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  550, Train loss:  0.492 Test loss:  0.639 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  560, Train loss:  0.470 Test loss:  0.598 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  570, Train loss:  0.441 Test loss:  0.567 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  580, Train loss:  0.422 Test loss:  0.565 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  590, Train loss:  0.406 Test loss:  0.594 Ensemble loss:    nan RMSE: nan Num. networks:  0\n",
            "Epoch:  600, Train loss:  0.395 Test loss:  0.533 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  610, Train loss:  0.377 Test loss:  0.493 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  620, Train loss:  0.368 Test loss:  0.497 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  630, Train loss:  0.345 Test loss:  0.502 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  640, Train loss:  0.342 Test loss:  0.501 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  650, Train loss:  0.329 Test loss:  0.581 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  660, Train loss:  0.322 Test loss:  0.528 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  670, Train loss:  0.306 Test loss:  0.505 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  680, Train loss:  0.306 Test loss:  0.531 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  690, Train loss:  0.302 Test loss:  0.549 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  700, Train loss:  0.296 Test loss:  0.564 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  710, Train loss:  0.298 Test loss:  0.597 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  720, Train loss:  0.287 Test loss:  0.518 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  730, Train loss:  0.272 Test loss:  0.617 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  740, Train loss:  0.270 Test loss:  0.607 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  750, Train loss:  0.268 Test loss:  0.616 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  760, Train loss:  0.249 Test loss:  0.540 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  770, Train loss:  0.246 Test loss:  0.531 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  780, Train loss:  0.241 Test loss:  0.666 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  790, Train loss:  0.239 Test loss:  0.674 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  800, Train loss:  0.230 Test loss:  0.641 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  810, Train loss:  0.216 Test loss:  0.607 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  820, Train loss:  0.216 Test loss:  0.709 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  830, Train loss:  0.211 Test loss:  0.882 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  840, Train loss:  0.207 Test loss:  0.983 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  850, Train loss:  0.198 Test loss:  0.809 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  860, Train loss:  0.189 Test loss:  0.908 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  870, Train loss:  0.170 Test loss:  0.704 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  880, Train loss:  0.168 Test loss:  0.721 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  890, Train loss:  0.164 Test loss:  0.930 Ensemble loss:    nan RMSE: 1.161 Num. networks:  1\n",
            "Epoch:  900, Train loss:  0.173 Test loss:  0.969 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  910, Train loss:  0.173 Test loss:  0.657 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  920, Train loss:  0.158 Test loss:  1.131 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  930, Train loss:  0.159 Test loss:  0.910 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  940, Train loss:  0.151 Test loss:  0.759 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  950, Train loss:  0.157 Test loss:  0.720 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  960, Train loss:  0.141 Test loss:  0.922 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  970, Train loss:  0.129 Test loss:  0.868 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  980, Train loss:  0.133 Test loss:  1.035 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch:  990, Train loss:  0.122 Test loss:  0.927 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1000, Train loss:  0.131 Test loss:  0.906 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1010, Train loss:  0.140 Test loss:  0.854 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1020, Train loss:  0.135 Test loss:  0.866 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1030, Train loss:  0.127 Test loss:  0.792 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1040, Train loss:  0.111 Test loss:  0.853 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1050, Train loss:  0.117 Test loss:  0.875 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1060, Train loss:  0.116 Test loss:  0.882 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1070, Train loss:  0.100 Test loss:  0.736 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1080, Train loss:  0.109 Test loss:  0.884 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1090, Train loss:  0.114 Test loss:  0.720 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1100, Train loss:  0.106 Test loss:  0.648 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1110, Train loss:  0.113 Test loss:  1.055 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1120, Train loss:  0.109 Test loss:  0.748 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1130, Train loss:  0.100 Test loss:  0.996 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1140, Train loss:  0.101 Test loss:  0.899 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1150, Train loss:  0.096 Test loss:  1.122 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1160, Train loss:  0.096 Test loss:  0.997 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1170, Train loss:  0.115 Test loss:  0.673 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1180, Train loss:  0.114 Test loss:  0.609 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1190, Train loss:  0.095 Test loss:  0.636 Ensemble loss:  0.434 RMSE: 1.041 Num. networks:  2\n",
            "Epoch: 1200, Train loss:  0.097 Test loss:  0.810 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1210, Train loss:  0.095 Test loss:  0.918 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1220, Train loss:  0.117 Test loss:  0.731 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1230, Train loss:  0.092 Test loss:  0.903 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1240, Train loss:  0.091 Test loss:  0.770 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1250, Train loss:  0.085 Test loss:  0.720 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1260, Train loss:  0.147 Test loss:  0.816 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1270, Train loss:  0.079 Test loss:  0.751 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1280, Train loss:  0.153 Test loss:  0.994 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1290, Train loss:  0.090 Test loss:  1.114 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1300, Train loss:  0.089 Test loss:  0.690 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1310, Train loss:  0.090 Test loss:  0.645 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1320, Train loss:  0.082 Test loss:  0.681 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1330, Train loss:  0.147 Test loss:  0.714 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1340, Train loss:  0.134 Test loss:  0.599 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1350, Train loss:  0.076 Test loss:  0.629 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1360, Train loss:  0.104 Test loss:  0.558 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1370, Train loss:  0.081 Test loss:  0.654 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1380, Train loss:  0.116 Test loss:  0.985 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1390, Train loss:  0.066 Test loss:  0.770 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1400, Train loss:  0.099 Test loss:  1.273 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1410, Train loss:  0.132 Test loss:  1.127 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1420, Train loss:  0.168 Test loss:  0.818 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1430, Train loss:  0.077 Test loss:  0.826 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1440, Train loss:  0.079 Test loss:  0.792 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1450, Train loss:  0.124 Test loss:  0.679 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1460, Train loss:  0.127 Test loss:  0.868 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1470, Train loss:  0.078 Test loss:  0.762 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1480, Train loss:  0.118 Test loss:  0.752 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1490, Train loss:  0.045 Test loss:  0.784 Ensemble loss:  0.396 RMSE: 1.012 Num. networks:  3\n",
            "Epoch: 1500, Train loss:  0.084 Test loss:  1.020 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1510, Train loss:  0.122 Test loss:  0.945 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1520, Train loss:  0.053 Test loss:  0.604 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1530, Train loss:  0.062 Test loss:  0.611 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1540, Train loss:  0.052 Test loss:  0.554 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1550, Train loss:  0.032 Test loss:  0.612 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1560, Train loss:  0.170 Test loss:  0.358 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1570, Train loss:  0.030 Test loss:  0.479 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1580, Train loss:  0.255 Test loss:  0.613 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1590, Train loss:  0.113 Test loss:  0.521 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1600, Train loss:  0.063 Test loss:  0.834 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1610, Train loss:  0.074 Test loss:  0.749 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1620, Train loss:  0.121 Test loss:  0.728 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1630, Train loss:  0.059 Test loss:  0.798 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1640, Train loss:  0.053 Test loss:  0.697 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1650, Train loss: -0.008 Test loss:  0.628 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1660, Train loss:  0.225 Test loss:  0.386 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1670, Train loss:  0.056 Test loss:  0.429 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1680, Train loss:  0.202 Test loss:  0.349 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1690, Train loss:  0.067 Test loss:  0.499 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1700, Train loss:  0.136 Test loss:  0.561 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1710, Train loss:  0.121 Test loss:  0.489 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1720, Train loss:  0.109 Test loss:  0.428 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1730, Train loss:  0.159 Test loss:  0.456 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1740, Train loss:  0.088 Test loss:  0.493 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1750, Train loss:  0.042 Test loss:  0.742 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1760, Train loss:  0.079 Test loss:  0.779 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1770, Train loss:  0.056 Test loss:  0.641 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1780, Train loss:  0.193 Test loss:  0.603 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1790, Train loss:  0.171 Test loss:  0.894 Ensemble loss:  0.390 RMSE: 0.997 Num. networks:  4\n",
            "Epoch: 1800, Train loss:  0.042 Test loss:  0.857 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1810, Train loss:  0.065 Test loss:  0.802 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1820, Train loss:  0.039 Test loss:  0.958 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1830, Train loss:  0.051 Test loss:  0.908 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1840, Train loss:  0.002 Test loss:  0.710 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1850, Train loss:  0.342 Test loss:  0.494 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1860, Train loss:  0.057 Test loss:  0.695 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1870, Train loss:  0.060 Test loss:  0.673 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1880, Train loss: -0.034 Test loss:  0.839 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1890, Train loss:  0.012 Test loss:  0.869 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1900, Train loss:  0.022 Test loss:  0.658 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1910, Train loss:  0.075 Test loss:  0.893 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1920, Train loss:  0.006 Test loss:  0.659 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1930, Train loss:  0.001 Test loss:  0.539 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1940, Train loss:  0.102 Test loss:  0.592 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1950, Train loss:  0.061 Test loss:  0.545 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1960, Train loss: -0.043 Test loss:  0.764 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1970, Train loss:  0.005 Test loss:  0.601 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1980, Train loss:  0.121 Test loss:  0.545 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 1990, Train loss:  0.087 Test loss:  0.618 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2000, Train loss: -0.021 Test loss:  0.691 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2010, Train loss: -0.033 Test loss:  0.894 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2020, Train loss:  0.297 Test loss:  0.999 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2030, Train loss:  0.244 Test loss:  0.539 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2040, Train loss:  0.073 Test loss:  0.677 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2050, Train loss:  0.028 Test loss:  0.950 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2060, Train loss:  0.176 Test loss:  0.746 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2070, Train loss:  0.107 Test loss:  0.908 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2080, Train loss:  0.211 Test loss:  0.984 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2090, Train loss:  0.140 Test loss:  0.807 Ensemble loss:  0.378 RMSE: 0.994 Num. networks:  5\n",
            "Epoch: 2100, Train loss: -0.017 Test loss:  1.067 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2110, Train loss:  0.315 Test loss:  0.590 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2120, Train loss:  0.244 Test loss:  0.695 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2130, Train loss:  0.083 Test loss:  1.143 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2140, Train loss: -0.039 Test loss:  0.972 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2150, Train loss:  0.025 Test loss:  1.098 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2160, Train loss:  0.209 Test loss:  0.822 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2170, Train loss:  0.013 Test loss:  0.879 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2180, Train loss:  0.208 Test loss:  0.654 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2190, Train loss:  0.040 Test loss:  0.811 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2200, Train loss:  0.040 Test loss:  0.883 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2210, Train loss:  0.163 Test loss:  0.755 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2220, Train loss: -0.029 Test loss:  1.344 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2230, Train loss: -0.024 Test loss:  1.128 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2240, Train loss:  0.184 Test loss:  0.760 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2250, Train loss:  0.101 Test loss:  0.856 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2260, Train loss: -0.006 Test loss:  1.340 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2270, Train loss:  0.143 Test loss:  1.274 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2280, Train loss: -0.032 Test loss:  1.059 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2290, Train loss:  0.073 Test loss:  1.143 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2300, Train loss:  0.126 Test loss:  1.046 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2310, Train loss:  0.053 Test loss:  0.832 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2320, Train loss: -0.065 Test loss:  1.413 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2330, Train loss:  0.079 Test loss:  1.031 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2340, Train loss:  0.076 Test loss:  1.041 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2350, Train loss:  0.220 Test loss:  1.118 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2360, Train loss:  0.252 Test loss:  1.067 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2370, Train loss:  0.054 Test loss:  1.346 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2380, Train loss: -0.005 Test loss:  1.421 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2390, Train loss:  0.134 Test loss:  1.018 Ensemble loss:  0.338 RMSE: 0.976 Num. networks:  6\n",
            "Epoch: 2400, Train loss:  0.095 Test loss:  0.707 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2410, Train loss: -0.015 Test loss:  1.049 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2420, Train loss:  0.262 Test loss:  0.739 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2430, Train loss: -0.064 Test loss:  0.786 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2440, Train loss: -0.060 Test loss:  0.716 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2450, Train loss: -0.069 Test loss:  0.609 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2460, Train loss: -0.050 Test loss:  0.522 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2470, Train loss: -0.052 Test loss:  0.455 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2480, Train loss:  0.304 Test loss:  0.336 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2490, Train loss: -0.012 Test loss:  0.834 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2500, Train loss:  0.064 Test loss:  0.891 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2510, Train loss:  0.542 Test loss:  0.496 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2520, Train loss: -0.060 Test loss:  0.630 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2530, Train loss: -0.010 Test loss:  1.198 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2540, Train loss:  0.077 Test loss:  0.441 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2550, Train loss: -0.054 Test loss:  0.586 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2560, Train loss:  0.196 Test loss:  0.357 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2570, Train loss: -0.027 Test loss:  0.544 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2580, Train loss:  0.164 Test loss:  0.398 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2590, Train loss:  0.004 Test loss:  0.562 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2600, Train loss:  0.016 Test loss:  0.559 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2610, Train loss: -0.075 Test loss:  1.193 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2620, Train loss:  0.137 Test loss:  0.627 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2630, Train loss:  0.017 Test loss:  0.695 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2640, Train loss: -0.020 Test loss:  1.220 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2650, Train loss: -0.033 Test loss:  1.227 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2660, Train loss:  0.034 Test loss:  1.634 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2670, Train loss: -0.015 Test loss:  1.023 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2680, Train loss: -0.082 Test loss:  1.338 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2690, Train loss: -0.084 Test loss:  1.850 Ensemble loss:  0.314 RMSE: 0.969 Num. networks:  7\n",
            "Epoch: 2700, Train loss:  0.308 Test loss:  0.883 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2710, Train loss: -0.057 Test loss:  1.653 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2720, Train loss:  0.226 Test loss:  1.180 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2730, Train loss: -0.006 Test loss:  1.907 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2740, Train loss: -0.047 Test loss:  2.088 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2750, Train loss:  0.158 Test loss:  1.471 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2760, Train loss:  0.014 Test loss:  1.964 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2770, Train loss:  0.121 Test loss:  1.077 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2780, Train loss:  0.049 Test loss:  2.013 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2790, Train loss:  0.269 Test loss:  1.368 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2800, Train loss:  0.071 Test loss:  1.770 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2810, Train loss: -0.058 Test loss:  1.478 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2820, Train loss:  0.201 Test loss:  1.691 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2830, Train loss:  0.145 Test loss:  1.201 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2840, Train loss: -0.048 Test loss:  1.473 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2850, Train loss: -0.084 Test loss:  1.735 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2860, Train loss: -0.049 Test loss:  1.475 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2870, Train loss: -0.079 Test loss:  2.343 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2880, Train loss: -0.026 Test loss:  3.215 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2890, Train loss:  0.231 Test loss:  1.305 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2900, Train loss:  0.067 Test loss:  2.046 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2910, Train loss: -0.046 Test loss:  1.912 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2920, Train loss: -0.064 Test loss:  2.382 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2930, Train loss:  0.002 Test loss:  1.626 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2940, Train loss: -0.016 Test loss:  1.364 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2950, Train loss: -0.032 Test loss:  1.952 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2960, Train loss: -0.072 Test loss:  1.966 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2970, Train loss:  0.100 Test loss:  2.278 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2980, Train loss: -0.022 Test loss:  2.752 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 2990, Train loss: -0.041 Test loss:  3.171 Ensemble loss:  0.315 RMSE: 0.975 Num. networks:  8\n",
            "Epoch: 3000, Train loss: -0.049 Test loss:  3.278 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3010, Train loss:  0.091 Test loss:  2.586 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3020, Train loss: -0.045 Test loss:  2.930 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3030, Train loss: -0.050 Test loss:  3.602 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3040, Train loss: -0.042 Test loss:  3.631 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3050, Train loss:  0.066 Test loss:  3.127 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3060, Train loss:  0.172 Test loss:  2.156 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3070, Train loss:  0.199 Test loss:  2.284 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3080, Train loss: -0.020 Test loss:  3.154 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3090, Train loss: -0.061 Test loss:  3.897 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3100, Train loss:  0.081 Test loss:  3.252 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3110, Train loss: -0.065 Test loss:  3.217 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3120, Train loss:  0.072 Test loss:  2.421 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3130, Train loss:  0.023 Test loss:  2.853 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3140, Train loss: -0.028 Test loss:  3.370 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3150, Train loss: -0.013 Test loss:  3.720 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3160, Train loss:  0.232 Test loss:  1.936 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3170, Train loss:  0.340 Test loss:  1.962 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3180, Train loss:  0.135 Test loss:  2.606 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3190, Train loss:  0.129 Test loss:  2.990 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3200, Train loss:  0.194 Test loss:  2.916 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3210, Train loss:  0.035 Test loss:  2.895 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3220, Train loss:  0.093 Test loss:  2.620 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3230, Train loss: -0.112 Test loss:  3.335 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3240, Train loss: -0.111 Test loss:  3.703 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3250, Train loss: -0.010 Test loss:  2.865 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3260, Train loss: -0.033 Test loss:  3.321 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3270, Train loss:  0.006 Test loss:  2.131 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3280, Train loss:  0.091 Test loss:  2.547 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3290, Train loss: -0.070 Test loss:  2.837 Ensemble loss:  0.335 RMSE: 0.996 Num. networks:  9\n",
            "Epoch: 3300, Train loss:  0.256 Test loss:  1.156 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3310, Train loss:  0.123 Test loss:  1.217 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3320, Train loss: -0.079 Test loss:  2.074 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3330, Train loss: -0.072 Test loss:  1.995 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3340, Train loss:  0.444 Test loss:  0.800 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3350, Train loss:  0.007 Test loss:  1.211 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3360, Train loss:  0.119 Test loss:  1.051 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3370, Train loss: -0.064 Test loss:  1.612 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3380, Train loss: -0.052 Test loss:  2.227 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3390, Train loss: -0.101 Test loss:  2.831 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3400, Train loss: -0.107 Test loss:  2.428 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3410, Train loss: -0.059 Test loss:  2.055 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3420, Train loss:  0.096 Test loss:  1.860 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3430, Train loss: -0.039 Test loss:  1.355 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3440, Train loss: -0.083 Test loss:  1.821 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3450, Train loss: -0.012 Test loss:  2.175 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3460, Train loss:  0.069 Test loss:  1.740 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3470, Train loss:  0.039 Test loss:  1.980 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3480, Train loss:  0.180 Test loss:  1.547 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3490, Train loss:  0.106 Test loss:  1.548 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3500, Train loss:  0.037 Test loss:  1.699 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3510, Train loss:  0.217 Test loss:  1.834 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3520, Train loss:  0.108 Test loss:  1.095 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3530, Train loss: -0.089 Test loss:  2.411 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3540, Train loss:  0.146 Test loss:  2.377 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3550, Train loss:  0.214 Test loss:  1.516 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3560, Train loss:  0.108 Test loss:  1.917 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3570, Train loss:  0.371 Test loss:  1.285 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3580, Train loss:  0.020 Test loss:  1.686 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3590, Train loss: -0.107 Test loss:  2.129 Ensemble loss:  0.340 RMSE: 1.007 Num. networks: 10\n",
            "Epoch: 3600, Train loss: -0.121 Test loss:  2.395 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3610, Train loss: -0.135 Test loss:  2.086 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3620, Train loss: -0.106 Test loss:  2.922 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3630, Train loss:  0.300 Test loss:  2.122 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3640, Train loss: -0.038 Test loss:  2.388 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3650, Train loss:  0.209 Test loss:  1.277 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3660, Train loss: -0.114 Test loss:  1.978 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3670, Train loss: -0.119 Test loss:  2.411 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3680, Train loss: -0.065 Test loss:  2.137 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3690, Train loss: -0.051 Test loss:  2.337 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3700, Train loss: -0.100 Test loss:  1.797 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3710, Train loss:  0.016 Test loss:  1.837 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3720, Train loss: -0.040 Test loss:  1.357 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3730, Train loss: -0.097 Test loss:  1.889 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3740, Train loss: -0.078 Test loss:  1.994 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3750, Train loss:  0.271 Test loss:  0.720 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3760, Train loss: -0.157 Test loss:  1.593 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3770, Train loss:  0.263 Test loss:  0.769 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3780, Train loss: -0.004 Test loss:  1.147 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3790, Train loss: -0.133 Test loss:  1.916 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3800, Train loss: -0.128 Test loss:  1.635 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3810, Train loss: -0.031 Test loss:  1.501 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3820, Train loss: -0.046 Test loss:  1.301 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3830, Train loss: -0.157 Test loss:  1.334 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3840, Train loss: -0.099 Test loss:  2.327 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3850, Train loss:  0.084 Test loss:  1.781 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3860, Train loss:  0.003 Test loss:  2.000 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3870, Train loss: -0.020 Test loss:  2.262 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3880, Train loss: -0.019 Test loss:  3.290 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3890, Train loss:  0.094 Test loss:  1.447 Ensemble loss:  0.332 RMSE: 1.003 Num. networks: 11\n",
            "Epoch: 3900, Train loss: -0.113 Test loss:  2.667 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3910, Train loss: -0.153 Test loss:  2.184 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3920, Train loss:  0.223 Test loss:  1.161 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3930, Train loss:  0.221 Test loss:  1.228 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3940, Train loss: -0.047 Test loss:  1.857 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3950, Train loss: -0.156 Test loss:  2.195 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3960, Train loss: -0.107 Test loss:  1.718 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3970, Train loss: -0.037 Test loss:  2.144 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3980, Train loss: -0.157 Test loss:  4.224 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 3990, Train loss: -0.142 Test loss:  6.679 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4000, Train loss: -0.145 Test loss:  3.500 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4010, Train loss: -0.157 Test loss:  3.857 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4020, Train loss: -0.010 Test loss:  4.207 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4030, Train loss: -0.137 Test loss:  4.386 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4040, Train loss: -0.039 Test loss:  5.400 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4050, Train loss:  0.039 Test loss:  3.583 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4060, Train loss:  0.193 Test loss:  2.470 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4070, Train loss:  0.036 Test loss:  1.810 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4080, Train loss: -0.126 Test loss:  2.122 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4090, Train loss: -0.054 Test loss:  1.815 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4100, Train loss: -0.094 Test loss:  1.942 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4110, Train loss: -0.081 Test loss:  1.910 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4120, Train loss: -0.061 Test loss:  1.875 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4130, Train loss: -0.058 Test loss:  2.402 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4140, Train loss: -0.019 Test loss:  1.834 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4150, Train loss:  0.051 Test loss:  1.252 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4160, Train loss: -0.124 Test loss:  1.871 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4170, Train loss: -0.055 Test loss:  1.592 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4180, Train loss: -0.094 Test loss:  1.795 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4190, Train loss: -0.064 Test loss:  1.524 Ensemble loss:  0.331 RMSE: 0.998 Num. networks: 12\n",
            "Epoch: 4200, Train loss: -0.129 Test loss:  1.988 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4210, Train loss: -0.017 Test loss:  1.710 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4220, Train loss: -0.005 Test loss:  1.487 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4230, Train loss: -0.086 Test loss:  1.832 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4240, Train loss: -0.085 Test loss:  1.876 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4250, Train loss: -0.148 Test loss:  2.378 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4260, Train loss: -0.120 Test loss:  2.117 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4270, Train loss:  0.270 Test loss:  1.753 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4280, Train loss:  0.018 Test loss:  2.111 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4290, Train loss: -0.033 Test loss:  2.702 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4300, Train loss: -0.063 Test loss:  2.692 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4310, Train loss:  0.009 Test loss:  3.020 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4320, Train loss: -0.106 Test loss:  1.958 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4330, Train loss:  0.000 Test loss:  2.038 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4340, Train loss: -0.045 Test loss:  1.726 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4350, Train loss: -0.006 Test loss:  1.512 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4360, Train loss:  0.013 Test loss:  2.369 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4370, Train loss:  0.010 Test loss:  1.906 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4380, Train loss: -0.096 Test loss:  1.994 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4390, Train loss:  0.053 Test loss:  1.630 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4400, Train loss: -0.064 Test loss:  1.635 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4410, Train loss:  0.023 Test loss:  1.414 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4420, Train loss: -0.123 Test loss:  1.330 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4430, Train loss: -0.075 Test loss:  0.802 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4440, Train loss:  0.000 Test loss:  0.796 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4450, Train loss:  0.092 Test loss:  0.843 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4460, Train loss:  0.068 Test loss:  1.350 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4470, Train loss: -0.099 Test loss:  1.123 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4480, Train loss: -0.092 Test loss:  1.080 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4490, Train loss: -0.111 Test loss:  1.267 Ensemble loss:  0.321 RMSE: 0.988 Num. networks: 13\n",
            "Epoch: 4500, Train loss: -0.108 Test loss:  1.209 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4510, Train loss: -0.021 Test loss:  1.030 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4520, Train loss: -0.105 Test loss:  1.304 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4530, Train loss: -0.024 Test loss:  1.340 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4540, Train loss: -0.053 Test loss:  1.513 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4550, Train loss: -0.111 Test loss:  1.770 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4560, Train loss: -0.162 Test loss:  2.290 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4570, Train loss:  0.232 Test loss:  1.015 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4580, Train loss: -0.108 Test loss:  1.768 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4590, Train loss:  0.088 Test loss:  1.809 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4600, Train loss: -0.090 Test loss:  1.879 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4610, Train loss:  0.083 Test loss:  1.255 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4620, Train loss: -0.166 Test loss:  2.085 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4630, Train loss: -0.010 Test loss:  1.358 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4640, Train loss: -0.121 Test loss:  1.460 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4650, Train loss: -0.053 Test loss:  2.354 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4660, Train loss:  0.057 Test loss:  1.465 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4670, Train loss: -0.188 Test loss:  2.273 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4680, Train loss:  0.127 Test loss:  1.807 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4690, Train loss: -0.088 Test loss:  1.631 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4700, Train loss: -0.160 Test loss:  2.554 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4710, Train loss: -0.176 Test loss:  3.587 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4720, Train loss: -0.182 Test loss:  3.308 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4730, Train loss:  0.138 Test loss:  1.314 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4740, Train loss:  0.079 Test loss:  1.153 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4750, Train loss:  0.205 Test loss:  1.536 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4760, Train loss: -0.179 Test loss:  2.034 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4770, Train loss: -0.119 Test loss:  1.546 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4780, Train loss: -0.139 Test loss:  1.345 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4790, Train loss: -0.156 Test loss:  1.433 Ensemble loss:  0.316 RMSE: 0.987 Num. networks: 14\n",
            "Epoch: 4800, Train loss: -0.021 Test loss:  1.770 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4810, Train loss:  0.228 Test loss:  1.337 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4820, Train loss:  0.103 Test loss:  1.008 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4830, Train loss: -0.037 Test loss:  1.151 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4840, Train loss: -0.138 Test loss:  2.359 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4850, Train loss: -0.191 Test loss:  2.024 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4860, Train loss: -0.195 Test loss:  1.891 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4870, Train loss: -0.188 Test loss:  1.687 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4880, Train loss: -0.157 Test loss:  2.425 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4890, Train loss:  0.292 Test loss:  0.940 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4900, Train loss: -0.029 Test loss:  1.641 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4910, Train loss:  0.164 Test loss:  1.137 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4920, Train loss:  0.029 Test loss:  1.636 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4930, Train loss:  0.219 Test loss:  1.414 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4940, Train loss:  0.190 Test loss:  1.264 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4950, Train loss: -0.018 Test loss:  2.379 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4960, Train loss:  0.000 Test loss:  1.516 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4970, Train loss:  0.100 Test loss:  1.430 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4980, Train loss:  0.069 Test loss:  1.385 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 4990, Train loss: -0.134 Test loss:  1.993 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5000, Train loss:  0.104 Test loss:  1.214 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5010, Train loss:  0.092 Test loss:  0.925 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5020, Train loss: -0.149 Test loss:  1.533 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5030, Train loss: -0.166 Test loss:  2.278 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5040, Train loss: -0.090 Test loss:  1.489 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5050, Train loss:  0.008 Test loss:  1.527 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5060, Train loss:  0.031 Test loss:  1.408 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5070, Train loss:  0.067 Test loss:  1.905 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5080, Train loss: -0.135 Test loss:  1.605 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5090, Train loss: -0.056 Test loss:  1.223 Ensemble loss:  0.310 RMSE: 0.979 Num. networks: 15\n",
            "Epoch: 5100, Train loss: -0.080 Test loss:  1.081 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5110, Train loss: -0.141 Test loss:  1.170 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5120, Train loss: -0.148 Test loss:  1.323 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5130, Train loss:  0.029 Test loss:  1.151 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5140, Train loss:  0.110 Test loss:  0.947 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5150, Train loss: -0.114 Test loss:  1.111 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5160, Train loss: -0.130 Test loss:  0.990 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5170, Train loss: -0.110 Test loss:  1.127 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5180, Train loss: -0.146 Test loss:  1.461 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5190, Train loss: -0.179 Test loss:  1.946 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5200, Train loss: -0.076 Test loss:  2.196 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5210, Train loss: -0.001 Test loss:  2.951 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5220, Train loss: -0.173 Test loss:  2.757 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5230, Train loss:  0.002 Test loss:  2.538 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5240, Train loss:  0.388 Test loss:  1.260 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5250, Train loss: -0.119 Test loss:  2.638 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5260, Train loss:  0.172 Test loss:  1.920 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5270, Train loss:  0.139 Test loss:  1.392 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5280, Train loss: -0.151 Test loss:  2.383 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5290, Train loss: -0.214 Test loss:  2.585 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5300, Train loss: -0.189 Test loss:  2.570 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5310, Train loss:  0.004 Test loss:  2.260 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5320, Train loss: -0.087 Test loss:  1.785 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5330, Train loss: -0.070 Test loss:  1.921 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5340, Train loss: -0.063 Test loss:  2.799 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5350, Train loss: -0.147 Test loss:  2.421 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5360, Train loss: -0.004 Test loss:  1.585 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5370, Train loss: -0.145 Test loss:  2.415 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5380, Train loss:  0.047 Test loss:  2.314 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5390, Train loss: -0.080 Test loss:  1.585 Ensemble loss:  0.298 RMSE: 0.958 Num. networks: 16\n",
            "Epoch: 5400, Train loss: -0.012 Test loss:  1.870 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5410, Train loss: -0.169 Test loss:  2.436 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5420, Train loss:  0.006 Test loss:  2.085 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5430, Train loss:  0.181 Test loss:  1.857 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5440, Train loss: -0.110 Test loss:  1.387 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5450, Train loss:  0.050 Test loss:  1.144 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5460, Train loss:  0.134 Test loss:  1.229 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5470, Train loss: -0.172 Test loss:  1.932 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5480, Train loss: -0.072 Test loss:  2.448 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5490, Train loss:  0.166 Test loss:  2.497 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5500, Train loss:  0.102 Test loss:  1.717 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5510, Train loss:  0.099 Test loss:  1.879 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5520, Train loss: -0.139 Test loss:  2.555 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5530, Train loss: -0.037 Test loss:  2.223 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5540, Train loss: -0.147 Test loss:  3.122 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5550, Train loss:  0.053 Test loss:  1.638 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5560, Train loss: -0.146 Test loss:  3.115 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5570, Train loss:  0.225 Test loss:  1.662 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5580, Train loss: -0.139 Test loss:  1.892 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5590, Train loss: -0.142 Test loss:  2.302 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5600, Train loss:  0.165 Test loss:  2.166 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5610, Train loss:  0.266 Test loss:  1.397 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5620, Train loss: -0.135 Test loss:  2.179 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5630, Train loss: -0.049 Test loss:  1.955 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5640, Train loss: -0.079 Test loss:  2.176 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5650, Train loss:  0.281 Test loss:  1.237 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5660, Train loss:  0.097 Test loss:  1.280 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5670, Train loss: -0.137 Test loss:  2.093 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5680, Train loss: -0.086 Test loss:  1.643 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5690, Train loss: -0.022 Test loss:  1.546 Ensemble loss:  0.302 RMSE: 0.956 Num. networks: 17\n",
            "Epoch: 5700, Train loss: -0.104 Test loss:  1.900 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5710, Train loss:  0.128 Test loss:  1.317 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5720, Train loss: -0.068 Test loss:  1.817 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5730, Train loss: -0.014 Test loss:  1.746 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5740, Train loss: -0.074 Test loss:  1.536 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5750, Train loss: -0.066 Test loss:  1.631 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5760, Train loss:  0.044 Test loss:  1.627 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5770, Train loss: -0.063 Test loss:  1.877 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5780, Train loss: -0.084 Test loss:  2.072 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5790, Train loss:  0.112 Test loss:  1.169 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5800, Train loss:  0.096 Test loss:  1.130 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5810, Train loss:  0.036 Test loss:  1.412 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5820, Train loss:  0.098 Test loss:  1.092 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5830, Train loss: -0.057 Test loss:  1.763 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5840, Train loss: -0.097 Test loss:  2.341 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5850, Train loss: -0.127 Test loss:  2.951 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5860, Train loss:  0.017 Test loss:  2.306 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5870, Train loss:  0.088 Test loss:  1.865 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5880, Train loss:  0.202 Test loss:  1.732 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5890, Train loss:  0.268 Test loss:  1.131 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5900, Train loss:  0.004 Test loss:  2.726 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5910, Train loss: -0.044 Test loss:  2.619 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5920, Train loss:  0.027 Test loss:  1.311 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5930, Train loss: -0.034 Test loss:  1.486 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5940, Train loss: -0.115 Test loss:  2.089 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5950, Train loss: -0.116 Test loss:  1.447 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5960, Train loss:  0.245 Test loss:  1.854 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5970, Train loss: -0.105 Test loss:  3.104 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5980, Train loss: -0.161 Test loss:  1.856 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 5990, Train loss:  0.040 Test loss:  3.296 Ensemble loss:  0.309 RMSE: 0.962 Num. networks: 18\n",
            "Epoch: 6000, Train loss: -0.088 Test loss:  2.576 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6010, Train loss: -0.062 Test loss:  2.312 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6020, Train loss: -0.131 Test loss:  2.562 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6030, Train loss: -0.056 Test loss:  2.087 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6040, Train loss: -0.114 Test loss:  2.514 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6050, Train loss: -0.150 Test loss:  3.019 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6060, Train loss: -0.133 Test loss:  3.506 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6070, Train loss: -0.105 Test loss:  3.209 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6080, Train loss:  0.052 Test loss:  2.883 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6090, Train loss:  0.025 Test loss:  2.275 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6100, Train loss: -0.018 Test loss:  1.780 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6110, Train loss: -0.023 Test loss:  2.688 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6120, Train loss: -0.127 Test loss:  1.667 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6130, Train loss:  0.181 Test loss:  1.020 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6140, Train loss: -0.108 Test loss:  3.008 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6150, Train loss: -0.147 Test loss:  2.252 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6160, Train loss: -0.148 Test loss:  1.907 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6170, Train loss: -0.156 Test loss:  2.432 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6180, Train loss: -0.152 Test loss:  2.531 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6190, Train loss: -0.158 Test loss:  2.765 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6200, Train loss: -0.093 Test loss:  2.899 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6210, Train loss: -0.110 Test loss:  2.401 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6220, Train loss: -0.162 Test loss:  2.123 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6230, Train loss: -0.147 Test loss:  1.864 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6240, Train loss:  0.018 Test loss:  1.519 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6250, Train loss: -0.053 Test loss:  1.387 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6260, Train loss: -0.158 Test loss:  2.037 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6270, Train loss:  0.156 Test loss:  1.073 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6280, Train loss: -0.150 Test loss:  2.093 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6290, Train loss: -0.119 Test loss:  3.774 Ensemble loss:  0.314 RMSE: 0.965 Num. networks: 19\n",
            "Epoch: 6300, Train loss:  0.017 Test loss:  1.450 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6310, Train loss: -0.019 Test loss:  3.076 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6320, Train loss: -0.135 Test loss:  3.182 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6330, Train loss: -0.177 Test loss:  2.458 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6340, Train loss: -0.171 Test loss:  2.047 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6350, Train loss:  0.023 Test loss:  1.192 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6360, Train loss: -0.132 Test loss:  1.779 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6370, Train loss: -0.157 Test loss:  1.999 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6380, Train loss: -0.182 Test loss:  2.528 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6390, Train loss: -0.087 Test loss:  1.409 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6400, Train loss: -0.196 Test loss:  3.712 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6410, Train loss: -0.193 Test loss:  2.247 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6420, Train loss: -0.139 Test loss:  1.611 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6430, Train loss: -0.124 Test loss:  3.201 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6440, Train loss:  0.020 Test loss:  3.249 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6450, Train loss:  0.761 Test loss:  0.669 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6460, Train loss:  0.132 Test loss:  0.980 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6470, Train loss: -0.027 Test loss:  1.593 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6480, Train loss: -0.132 Test loss:  3.039 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6490, Train loss: -0.006 Test loss:  1.910 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6500, Train loss: -0.067 Test loss:  2.083 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6510, Train loss: -0.099 Test loss:  2.001 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6520, Train loss:  0.008 Test loss:  2.771 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6530, Train loss:  0.029 Test loss:  2.187 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6540, Train loss:  0.158 Test loss:  2.672 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6550, Train loss:  0.050 Test loss:  1.419 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6560, Train loss: -0.124 Test loss:  2.052 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6570, Train loss: -0.171 Test loss:  2.574 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6580, Train loss: -0.139 Test loss:  2.436 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6590, Train loss:  0.064 Test loss:  3.025 Ensemble loss:  0.322 RMSE: 0.959 Num. networks: 20\n",
            "Epoch: 6600, Train loss:  0.142 Test loss:  0.976 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6610, Train loss:  0.085 Test loss:  1.534 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6620, Train loss: -0.112 Test loss:  1.871 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6630, Train loss:  0.103 Test loss:  2.902 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6640, Train loss: -0.166 Test loss:  2.812 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6650, Train loss: -0.163 Test loss:  3.155 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6660, Train loss: -0.144 Test loss:  2.127 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6670, Train loss: -0.146 Test loss:  2.664 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6680, Train loss:  0.103 Test loss:  1.237 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6690, Train loss:  0.045 Test loss:  2.973 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6700, Train loss: -0.066 Test loss:  2.562 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6710, Train loss: -0.150 Test loss:  2.942 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6720, Train loss: -0.035 Test loss:  1.835 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6730, Train loss: -0.151 Test loss:  3.276 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6740, Train loss: -0.081 Test loss:  2.362 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6750, Train loss:  0.505 Test loss:  2.369 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6760, Train loss:  0.413 Test loss:  2.387 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6770, Train loss:  0.066 Test loss:  1.519 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6780, Train loss:  0.103 Test loss:  1.730 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6790, Train loss:  0.008 Test loss:  3.229 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6800, Train loss:  0.264 Test loss:  2.984 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6810, Train loss: -0.050 Test loss:  1.841 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6820, Train loss: -0.131 Test loss:  2.758 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6830, Train loss: -0.115 Test loss:  2.808 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6840, Train loss: -0.089 Test loss:  2.004 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6850, Train loss: -0.142 Test loss:  2.567 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6860, Train loss: -0.050 Test loss:  3.426 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6870, Train loss:  0.289 Test loss:  2.136 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6880, Train loss:  0.005 Test loss:  1.555 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6890, Train loss:  0.109 Test loss:  3.136 Ensemble loss:  0.324 RMSE: 0.954 Num. networks: 21\n",
            "Epoch: 6900, Train loss: -0.124 Test loss:  3.666 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6910, Train loss: -0.124 Test loss:  4.241 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6920, Train loss: -0.133 Test loss:  3.908 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6930, Train loss: -0.046 Test loss:  2.919 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6940, Train loss:  0.034 Test loss:  2.778 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6950, Train loss:  0.155 Test loss:  1.979 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6960, Train loss: -0.163 Test loss:  3.270 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6970, Train loss: -0.032 Test loss:  2.996 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6980, Train loss: -0.096 Test loss:  4.351 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 6990, Train loss:  0.480 Test loss:  1.181 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7000, Train loss:  0.092 Test loss:  1.554 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7010, Train loss: -0.170 Test loss:  3.987 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7020, Train loss: -0.176 Test loss:  3.984 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7030, Train loss:  0.153 Test loss:  1.752 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7040, Train loss: -0.104 Test loss:  2.664 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7050, Train loss: -0.181 Test loss:  3.986 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7060, Train loss: -0.121 Test loss:  3.073 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7070, Train loss: -0.160 Test loss:  2.850 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7080, Train loss: -0.188 Test loss:  3.203 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7090, Train loss: -0.165 Test loss:  2.952 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7100, Train loss: -0.125 Test loss:  2.672 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7110, Train loss:  0.041 Test loss:  1.573 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7120, Train loss: -0.054 Test loss:  1.542 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7130, Train loss: -0.117 Test loss:  1.809 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7140, Train loss:  0.047 Test loss:  1.308 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7150, Train loss: -0.114 Test loss:  1.916 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7160, Train loss: -0.088 Test loss:  1.441 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7170, Train loss: -0.137 Test loss:  1.723 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7180, Train loss:  0.039 Test loss:  1.359 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7190, Train loss:  0.267 Test loss:  1.110 Ensemble loss:  0.322 RMSE: 0.946 Num. networks: 22\n",
            "Epoch: 7200, Train loss:  0.172 Test loss:  1.099 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7210, Train loss:  0.371 Test loss:  0.763 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7220, Train loss: -0.077 Test loss:  1.223 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7230, Train loss: -0.047 Test loss:  1.718 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7240, Train loss:  0.080 Test loss:  1.348 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7250, Train loss: -0.112 Test loss:  1.212 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7260, Train loss: -0.130 Test loss:  1.157 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7270, Train loss: -0.022 Test loss:  1.030 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7280, Train loss:  0.063 Test loss:  1.558 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7290, Train loss:  0.141 Test loss:  0.687 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7300, Train loss: -0.104 Test loss:  1.836 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7310, Train loss:  0.144 Test loss:  0.995 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7320, Train loss: -0.094 Test loss:  1.416 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7330, Train loss: -0.119 Test loss:  1.693 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7340, Train loss: -0.076 Test loss:  1.269 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7350, Train loss: -0.177 Test loss:  1.597 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7360, Train loss:  0.233 Test loss:  1.573 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7370, Train loss: -0.051 Test loss:  1.351 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7380, Train loss: -0.039 Test loss:  1.627 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7390, Train loss: -0.147 Test loss:  1.707 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7400, Train loss: -0.008 Test loss:  1.243 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7410, Train loss: -0.148 Test loss:  2.021 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7420, Train loss: -0.136 Test loss:  1.738 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7430, Train loss:  0.143 Test loss:  0.882 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7440, Train loss: -0.096 Test loss:  1.450 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7450, Train loss:  0.048 Test loss:  1.018 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7460, Train loss:  0.056 Test loss:  0.999 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7470, Train loss: -0.138 Test loss:  1.116 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7480, Train loss:  0.309 Test loss:  0.589 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7490, Train loss:  0.086 Test loss:  1.149 Ensemble loss:  0.319 RMSE: 0.941 Num. networks: 23\n",
            "Epoch: 7500, Train loss: -0.187 Test loss:  2.849 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7510, Train loss: -0.054 Test loss:  1.197 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7520, Train loss:  0.264 Test loss:  0.579 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7530, Train loss:  0.413 Test loss:  0.551 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7540, Train loss:  0.091 Test loss:  0.957 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7550, Train loss: -0.008 Test loss:  0.898 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7560, Train loss: -0.129 Test loss:  1.199 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7570, Train loss: -0.101 Test loss:  1.174 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7580, Train loss: -0.177 Test loss:  1.039 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7590, Train loss: -0.187 Test loss:  1.082 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7600, Train loss:  0.161 Test loss:  0.449 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7610, Train loss: -0.131 Test loss:  1.340 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7620, Train loss: -0.175 Test loss:  0.925 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7630, Train loss: -0.199 Test loss:  0.954 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7640, Train loss: -0.161 Test loss:  0.933 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7650, Train loss: -0.177 Test loss:  1.353 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7660, Train loss: -0.138 Test loss:  0.970 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7670, Train loss: -0.176 Test loss:  1.272 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7680, Train loss: -0.071 Test loss:  0.718 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7690, Train loss: -0.141 Test loss:  0.890 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7700, Train loss:  0.039 Test loss:  0.742 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7710, Train loss: -0.151 Test loss:  1.077 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7720, Train loss: -0.158 Test loss:  1.531 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7730, Train loss: -0.170 Test loss:  2.153 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7740, Train loss: -0.144 Test loss:  1.638 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7750, Train loss:  0.411 Test loss:  0.515 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7760, Train loss:  0.186 Test loss:  2.217 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7770, Train loss: -0.039 Test loss:  0.920 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7780, Train loss: -0.172 Test loss:  1.063 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7790, Train loss: -0.149 Test loss:  0.956 Ensemble loss:  0.316 RMSE: 0.941 Num. networks: 24\n",
            "Epoch: 7800, Train loss:  0.245 Test loss:  0.648 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7810, Train loss: -0.069 Test loss:  1.751 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7820, Train loss: -0.159 Test loss:  1.319 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7830, Train loss: -0.124 Test loss:  1.312 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7840, Train loss:  0.010 Test loss:  0.738 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7850, Train loss:  0.389 Test loss:  0.733 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7860, Train loss: -0.019 Test loss:  2.163 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7870, Train loss: -0.034 Test loss:  0.785 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7880, Train loss:  0.249 Test loss:  0.581 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7890, Train loss:  0.546 Test loss:  0.556 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7900, Train loss: -0.082 Test loss:  1.448 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7910, Train loss:  0.188 Test loss:  2.217 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7920, Train loss: -0.124 Test loss:  1.544 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7930, Train loss:  0.086 Test loss:  1.519 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7940, Train loss: -0.113 Test loss:  0.802 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7950, Train loss: -0.025 Test loss:  1.292 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7960, Train loss:  0.130 Test loss:  0.711 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7970, Train loss:  0.203 Test loss:  0.896 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7980, Train loss: -0.052 Test loss:  4.222 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 7990, Train loss:  0.143 Test loss:  0.589 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8000, Train loss:  0.204 Test loss:  1.123 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8010, Train loss: -0.121 Test loss:  2.021 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8020, Train loss: -0.158 Test loss:  2.016 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8030, Train loss:  0.015 Test loss:  2.824 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8040, Train loss:  0.143 Test loss:  0.753 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8050, Train loss: -0.146 Test loss:  1.392 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8060, Train loss:  0.502 Test loss:  0.822 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8070, Train loss: -0.044 Test loss:  1.423 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8080, Train loss: -0.111 Test loss:  0.787 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8090, Train loss:  0.010 Test loss:  0.984 Ensemble loss:  0.318 RMSE: 0.943 Num. networks: 25\n",
            "Epoch: 8100, Train loss: -0.160 Test loss:  2.470 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8110, Train loss:  0.112 Test loss:  0.893 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8120, Train loss: -0.159 Test loss:  1.929 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8130, Train loss:  0.216 Test loss:  0.863 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8140, Train loss:  0.644 Test loss:  1.009 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8150, Train loss:  0.047 Test loss:  2.816 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8160, Train loss: -0.124 Test loss:  4.245 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8170, Train loss: -0.065 Test loss:  5.200 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8180, Train loss:  0.147 Test loss:  2.943 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8190, Train loss:  0.124 Test loss:  1.761 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8200, Train loss: -0.005 Test loss:  2.585 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8210, Train loss: -0.024 Test loss:  1.234 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8220, Train loss: -0.112 Test loss:  1.554 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8230, Train loss:  0.053 Test loss:  1.078 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8240, Train loss: -0.022 Test loss:  1.483 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8250, Train loss: -0.073 Test loss:  2.313 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8260, Train loss: -0.110 Test loss:  1.740 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8270, Train loss: -0.112 Test loss:  1.883 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8280, Train loss:  0.049 Test loss:  1.140 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8290, Train loss:  0.159 Test loss:  0.873 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8300, Train loss: -0.052 Test loss:  1.919 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8310, Train loss: -0.087 Test loss:  1.669 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8320, Train loss: -0.026 Test loss:  1.702 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8330, Train loss: -0.123 Test loss:  3.188 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8340, Train loss: -0.074 Test loss:  1.783 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8350, Train loss: -0.064 Test loss:  7.210 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8360, Train loss:  0.236 Test loss:  1.571 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8370, Train loss:  0.497 Test loss:  1.506 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8380, Train loss:  0.018 Test loss:  5.286 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8390, Train loss:  0.218 Test loss:  4.194 Ensemble loss:  0.313 RMSE: 0.936 Num. networks: 26\n",
            "Epoch: 8400, Train loss: -0.011 Test loss:  2.946 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8410, Train loss: -0.105 Test loss:  5.489 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8420, Train loss: -0.106 Test loss:  7.452 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8430, Train loss: -0.033 Test loss:  6.329 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8440, Train loss: -0.078 Test loss:  5.573 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8450, Train loss: -0.048 Test loss:  7.611 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8460, Train loss:  0.029 Test loss:  3.807 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8470, Train loss: -0.105 Test loss:  4.355 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8480, Train loss: -0.092 Test loss:  2.768 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8490, Train loss: -0.011 Test loss:  2.260 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8500, Train loss: -0.087 Test loss:  2.893 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8510, Train loss:  0.032 Test loss:  2.496 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8520, Train loss: -0.001 Test loss:  2.299 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8530, Train loss:  0.016 Test loss:  2.915 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8540, Train loss: -0.052 Test loss:  2.290 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8550, Train loss: -0.084 Test loss:  3.720 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8560, Train loss:  0.210 Test loss:  1.595 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8570, Train loss: -0.130 Test loss:  2.796 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8580, Train loss: -0.096 Test loss:  3.637 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8590, Train loss:  0.062 Test loss:  2.226 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8600, Train loss: -0.120 Test loss:  2.199 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8610, Train loss:  0.127 Test loss:  2.604 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8620, Train loss: -0.029 Test loss:  4.085 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8630, Train loss:  0.196 Test loss:  2.731 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8640, Train loss: -0.116 Test loss:  2.188 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8650, Train loss:  0.251 Test loss:  1.371 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8660, Train loss: -0.020 Test loss:  1.815 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8670, Train loss:  0.029 Test loss:  1.989 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8680, Train loss: -0.132 Test loss:  3.064 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8690, Train loss: -0.125 Test loss:  2.645 Ensemble loss:  0.312 RMSE: 0.930 Num. networks: 27\n",
            "Epoch: 8700, Train loss: -0.059 Test loss:  8.587 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8710, Train loss: -0.067 Test loss:  2.494 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8720, Train loss: -0.081 Test loss:  2.995 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8730, Train loss: -0.124 Test loss:  2.573 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8740, Train loss: -0.065 Test loss:  5.691 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8750, Train loss:  0.145 Test loss:  2.147 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8760, Train loss: -0.093 Test loss:  3.235 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8770, Train loss: -0.026 Test loss:  1.487 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8780, Train loss:  0.180 Test loss: 10.477 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8790, Train loss: -0.104 Test loss: 71.499 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8800, Train loss:  0.274 Test loss:  8.539 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8810, Train loss: -0.115 Test loss:  8.691 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8820, Train loss: -0.076 Test loss: 11.158 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8830, Train loss: -0.039 Test loss: 22.257 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8840, Train loss:  0.057 Test loss: 15.639 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8850, Train loss:  0.188 Test loss:  1.413 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8860, Train loss: -0.114 Test loss:  7.298 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8870, Train loss: -0.086 Test loss: 17.382 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8880, Train loss:  0.244 Test loss:  4.738 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8890, Train loss: -0.090 Test loss: 10.179 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8900, Train loss:  0.253 Test loss:  6.975 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8910, Train loss:  0.172 Test loss:  1.361 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8920, Train loss: -0.033 Test loss:  1.607 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8930, Train loss: -0.104 Test loss:  2.919 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8940, Train loss: -0.101 Test loss:  2.687 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8950, Train loss: -0.045 Test loss:  3.851 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8960, Train loss: -0.115 Test loss:  3.027 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8970, Train loss: -0.101 Test loss:  3.469 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8980, Train loss:  0.166 Test loss: 42.540 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 8990, Train loss: -0.036 Test loss:  3.532 Ensemble loss:  0.306 RMSE: 0.923 Num. networks: 28\n",
            "Epoch: 9000, Train loss: -0.145 Test loss:  3.232 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9010, Train loss: -0.107 Test loss: 22.419 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9020, Train loss: -0.065 Test loss: 10.133 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9030, Train loss:  0.031 Test loss:  4.125 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9040, Train loss:  0.015 Test loss:  6.031 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9050, Train loss: -0.091 Test loss: 26.127 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9060, Train loss: -0.036 Test loss: 14.453 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9070, Train loss: -0.039 Test loss: 206.464 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9080, Train loss: -0.051 Test loss: 102.998 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9090, Train loss: -0.107 Test loss: 20.033 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9100, Train loss: -0.088 Test loss: 28.440 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9110, Train loss:  0.200 Test loss: 92.479 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9120, Train loss: -0.075 Test loss: 81.232 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9130, Train loss:  0.202 Test loss: 28.977 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9140, Train loss: -0.078 Test loss: 21.836 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9150, Train loss: -0.035 Test loss: 11.186 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9160, Train loss: -0.014 Test loss: 22.932 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9170, Train loss: -0.081 Test loss: 25.008 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9180, Train loss:  0.027 Test loss: 82.186 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9190, Train loss: -0.065 Test loss: 34.536 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9200, Train loss: -0.084 Test loss:  6.842 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9210, Train loss: -0.069 Test loss:  2.603 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9220, Train loss:  0.064 Test loss: 66.881 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9230, Train loss: -0.046 Test loss: 55.348 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9240, Train loss: -0.049 Test loss: 114.964 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9250, Train loss: -0.118 Test loss: 60.511 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9260, Train loss: -0.099 Test loss: 32.635 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9270, Train loss:  0.314 Test loss: 11.819 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9280, Train loss:  0.278 Test loss:  6.547 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9290, Train loss: -0.020 Test loss:  6.378 Ensemble loss:  0.300 RMSE: 0.918 Num. networks: 29\n",
            "Epoch: 9300, Train loss:  0.070 Test loss: 16.769 Ensemble loss:  0.297 RMSE: 0.911 Num. networks: 30\n",
            "Epoch: 9310, Train loss: -0.002 Test loss:  5.216 Ensemble loss:  0.297 RMSE: 0.911 Num. networks: 30\n",
            "Epoch: 9320, Train loss: -0.155 Test loss:  2.009 Ensemble loss:  0.297 RMSE: 0.911 Num. networks: 30\n",
            "Epoch: 9330, Train loss:  0.212 Test loss:  0.967 Ensemble loss:  0.297 RMSE: 0.911 Num. networks: 30\n",
            "Epoch: 9340, Train loss:  0.165 Test loss:  1.899 Ensemble loss:  0.297 RMSE: 0.911 Num. networks: 30\n",
            "Epoch: 9350, Train loss: -0.066 Test loss:  2.294 Ensemble loss:  0.297 RMSE: 0.911 Num. networks: 30\n",
            "Train log. lik. =  -0.003 +/-  0.027\n",
            "Test  log. lik. =  -0.469 +/-  0.123\n",
            "Train RMSE      =   0.524 +/-  0.020\n",
            "Test  RMSE      =   0.958 +/-  0.112\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "data = pd.read_csv('/content/drive/MyDrive/bayesian-deep-learning-master/data/3_256_datsets.csv').values\n",
        "ensemble = train_mc_dropout(data=data, n_splits=10, burn_in=350, mix_time=300, num_nets=30,\n",
        "                            num_units=110, learn_rate=1e-2/len(data), weight_decay=0.9, log_every=10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}